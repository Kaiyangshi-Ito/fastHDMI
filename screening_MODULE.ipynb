{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cc105c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:36.323166Z",
     "start_time": "2023-04-16T15:44:35.330591Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocess as _mp\n",
    "import ctypes as _ctypes\n",
    "from sklearn.preprocessing import RobustScaler as _scaler\n",
    "from sklearn.feature_selection import mutual_info_regression as _mutual_info_regression\n",
    "from sklearn.feature_selection import mutual_info_classif as _mutual_info_classif\n",
    "from dask import dataframe as _dd\n",
    "import pandas as _pd\n",
    "# from KDEpy import FFTKDE as _FFTKDE\n",
    "# from bed_reader import open_bed as _open_bed\n",
    "from numba import njit as _njit\n",
    "from numba import jit as _jit\n",
    "import numpy as _np\n",
    "from tqdm import tqdm as _tqdm\n",
    "import warnings as _warnings\n",
    "\n",
    "_warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6146a",
   "metadata": {},
   "source": [
    "# basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2326f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:36.555456Z",
     "start_time": "2023-04-16T15:44:36.325351Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe3a614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:36.706572Z",
     "start_time": "2023-04-16T15:44:36.556396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<!-- Generated by Cython 0.29.34 -->\n",
       "<html>\n",
       "<head>\n",
       "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
       "    <title>Cython: _cython_magic_fb653f3f00a0b0d040a3af1124789652.pyx</title>\n",
       "    <style type=\"text/css\">\n",
       "    \n",
       "body.cython { font-family: courier; font-size: 12; }\n",
       "\n",
       ".cython.tag  {  }\n",
       ".cython.line { margin: 0em }\n",
       ".cython.code { font-size: 9; color: #444444; display: none; margin: 0px 0px 0px 8px; border-left: 8px none; }\n",
       "\n",
       ".cython.line .run { background-color: #B0FFB0; }\n",
       ".cython.line .mis { background-color: #FFB0B0; }\n",
       ".cython.code.run  { border-left: 8px solid #B0FFB0; }\n",
       ".cython.code.mis  { border-left: 8px solid #FFB0B0; }\n",
       "\n",
       ".cython.code .py_c_api  { color: red; }\n",
       ".cython.code .py_macro_api  { color: #FF7000; }\n",
       ".cython.code .pyx_c_api  { color: #FF3000; }\n",
       ".cython.code .pyx_macro_api  { color: #FF7000; }\n",
       ".cython.code .refnanny  { color: #FFA000; }\n",
       ".cython.code .trace  { color: #FFA000; }\n",
       ".cython.code .error_goto  { color: #FFA000; }\n",
       "\n",
       ".cython.code .coerce  { color: #008000; border: 1px dotted #008000 }\n",
       ".cython.code .py_attr { color: #FF0000; font-weight: bold; }\n",
       ".cython.code .c_attr  { color: #0000FF; }\n",
       ".cython.code .py_call { color: #FF0000; font-weight: bold; }\n",
       ".cython.code .c_call  { color: #0000FF; }\n",
       "\n",
       ".cython.score-0 {background-color: #FFFFff;}\n",
       ".cython.score-1 {background-color: #FFFFe7;}\n",
       ".cython.score-2 {background-color: #FFFFd4;}\n",
       ".cython.score-3 {background-color: #FFFFc4;}\n",
       ".cython.score-4 {background-color: #FFFFb6;}\n",
       ".cython.score-5 {background-color: #FFFFaa;}\n",
       ".cython.score-6 {background-color: #FFFF9f;}\n",
       ".cython.score-7 {background-color: #FFFF96;}\n",
       ".cython.score-8 {background-color: #FFFF8d;}\n",
       ".cython.score-9 {background-color: #FFFF86;}\n",
       ".cython.score-10 {background-color: #FFFF7f;}\n",
       ".cython.score-11 {background-color: #FFFF79;}\n",
       ".cython.score-12 {background-color: #FFFF73;}\n",
       ".cython.score-13 {background-color: #FFFF6e;}\n",
       ".cython.score-14 {background-color: #FFFF6a;}\n",
       ".cython.score-15 {background-color: #FFFF66;}\n",
       ".cython.score-16 {background-color: #FFFF62;}\n",
       ".cython.score-17 {background-color: #FFFF5e;}\n",
       ".cython.score-18 {background-color: #FFFF5b;}\n",
       ".cython.score-19 {background-color: #FFFF57;}\n",
       ".cython.score-20 {background-color: #FFFF55;}\n",
       ".cython.score-21 {background-color: #FFFF52;}\n",
       ".cython.score-22 {background-color: #FFFF4f;}\n",
       ".cython.score-23 {background-color: #FFFF4d;}\n",
       ".cython.score-24 {background-color: #FFFF4b;}\n",
       ".cython.score-25 {background-color: #FFFF48;}\n",
       ".cython.score-26 {background-color: #FFFF46;}\n",
       ".cython.score-27 {background-color: #FFFF44;}\n",
       ".cython.score-28 {background-color: #FFFF43;}\n",
       ".cython.score-29 {background-color: #FFFF41;}\n",
       ".cython.score-30 {background-color: #FFFF3f;}\n",
       ".cython.score-31 {background-color: #FFFF3e;}\n",
       ".cython.score-32 {background-color: #FFFF3c;}\n",
       ".cython.score-33 {background-color: #FFFF3b;}\n",
       ".cython.score-34 {background-color: #FFFF39;}\n",
       ".cython.score-35 {background-color: #FFFF38;}\n",
       ".cython.score-36 {background-color: #FFFF37;}\n",
       ".cython.score-37 {background-color: #FFFF36;}\n",
       ".cython.score-38 {background-color: #FFFF35;}\n",
       ".cython.score-39 {background-color: #FFFF34;}\n",
       ".cython.score-40 {background-color: #FFFF33;}\n",
       ".cython.score-41 {background-color: #FFFF32;}\n",
       ".cython.score-42 {background-color: #FFFF31;}\n",
       ".cython.score-43 {background-color: #FFFF30;}\n",
       ".cython.score-44 {background-color: #FFFF2f;}\n",
       ".cython.score-45 {background-color: #FFFF2e;}\n",
       ".cython.score-46 {background-color: #FFFF2d;}\n",
       ".cython.score-47 {background-color: #FFFF2c;}\n",
       ".cython.score-48 {background-color: #FFFF2b;}\n",
       ".cython.score-49 {background-color: #FFFF2b;}\n",
       ".cython.score-50 {background-color: #FFFF2a;}\n",
       ".cython.score-51 {background-color: #FFFF29;}\n",
       ".cython.score-52 {background-color: #FFFF29;}\n",
       ".cython.score-53 {background-color: #FFFF28;}\n",
       ".cython.score-54 {background-color: #FFFF27;}\n",
       ".cython.score-55 {background-color: #FFFF27;}\n",
       ".cython.score-56 {background-color: #FFFF26;}\n",
       ".cython.score-57 {background-color: #FFFF26;}\n",
       ".cython.score-58 {background-color: #FFFF25;}\n",
       ".cython.score-59 {background-color: #FFFF24;}\n",
       ".cython.score-60 {background-color: #FFFF24;}\n",
       ".cython.score-61 {background-color: #FFFF23;}\n",
       ".cython.score-62 {background-color: #FFFF23;}\n",
       ".cython.score-63 {background-color: #FFFF22;}\n",
       ".cython.score-64 {background-color: #FFFF22;}\n",
       ".cython.score-65 {background-color: #FFFF22;}\n",
       ".cython.score-66 {background-color: #FFFF21;}\n",
       ".cython.score-67 {background-color: #FFFF21;}\n",
       ".cython.score-68 {background-color: #FFFF20;}\n",
       ".cython.score-69 {background-color: #FFFF20;}\n",
       ".cython.score-70 {background-color: #FFFF1f;}\n",
       ".cython.score-71 {background-color: #FFFF1f;}\n",
       ".cython.score-72 {background-color: #FFFF1f;}\n",
       ".cython.score-73 {background-color: #FFFF1e;}\n",
       ".cython.score-74 {background-color: #FFFF1e;}\n",
       ".cython.score-75 {background-color: #FFFF1e;}\n",
       ".cython.score-76 {background-color: #FFFF1d;}\n",
       ".cython.score-77 {background-color: #FFFF1d;}\n",
       ".cython.score-78 {background-color: #FFFF1c;}\n",
       ".cython.score-79 {background-color: #FFFF1c;}\n",
       ".cython.score-80 {background-color: #FFFF1c;}\n",
       ".cython.score-81 {background-color: #FFFF1c;}\n",
       ".cython.score-82 {background-color: #FFFF1b;}\n",
       ".cython.score-83 {background-color: #FFFF1b;}\n",
       ".cython.score-84 {background-color: #FFFF1b;}\n",
       ".cython.score-85 {background-color: #FFFF1a;}\n",
       ".cython.score-86 {background-color: #FFFF1a;}\n",
       ".cython.score-87 {background-color: #FFFF1a;}\n",
       ".cython.score-88 {background-color: #FFFF1a;}\n",
       ".cython.score-89 {background-color: #FFFF19;}\n",
       ".cython.score-90 {background-color: #FFFF19;}\n",
       ".cython.score-91 {background-color: #FFFF19;}\n",
       ".cython.score-92 {background-color: #FFFF19;}\n",
       ".cython.score-93 {background-color: #FFFF18;}\n",
       ".cython.score-94 {background-color: #FFFF18;}\n",
       ".cython.score-95 {background-color: #FFFF18;}\n",
       ".cython.score-96 {background-color: #FFFF18;}\n",
       ".cython.score-97 {background-color: #FFFF17;}\n",
       ".cython.score-98 {background-color: #FFFF17;}\n",
       ".cython.score-99 {background-color: #FFFF17;}\n",
       ".cython.score-100 {background-color: #FFFF17;}\n",
       ".cython.score-101 {background-color: #FFFF16;}\n",
       ".cython.score-102 {background-color: #FFFF16;}\n",
       ".cython.score-103 {background-color: #FFFF16;}\n",
       ".cython.score-104 {background-color: #FFFF16;}\n",
       ".cython.score-105 {background-color: #FFFF16;}\n",
       ".cython.score-106 {background-color: #FFFF15;}\n",
       ".cython.score-107 {background-color: #FFFF15;}\n",
       ".cython.score-108 {background-color: #FFFF15;}\n",
       ".cython.score-109 {background-color: #FFFF15;}\n",
       ".cython.score-110 {background-color: #FFFF15;}\n",
       ".cython.score-111 {background-color: #FFFF15;}\n",
       ".cython.score-112 {background-color: #FFFF14;}\n",
       ".cython.score-113 {background-color: #FFFF14;}\n",
       ".cython.score-114 {background-color: #FFFF14;}\n",
       ".cython.score-115 {background-color: #FFFF14;}\n",
       ".cython.score-116 {background-color: #FFFF14;}\n",
       ".cython.score-117 {background-color: #FFFF14;}\n",
       ".cython.score-118 {background-color: #FFFF13;}\n",
       ".cython.score-119 {background-color: #FFFF13;}\n",
       ".cython.score-120 {background-color: #FFFF13;}\n",
       ".cython.score-121 {background-color: #FFFF13;}\n",
       ".cython.score-122 {background-color: #FFFF13;}\n",
       ".cython.score-123 {background-color: #FFFF13;}\n",
       ".cython.score-124 {background-color: #FFFF13;}\n",
       ".cython.score-125 {background-color: #FFFF12;}\n",
       ".cython.score-126 {background-color: #FFFF12;}\n",
       ".cython.score-127 {background-color: #FFFF12;}\n",
       ".cython.score-128 {background-color: #FFFF12;}\n",
       ".cython.score-129 {background-color: #FFFF12;}\n",
       ".cython.score-130 {background-color: #FFFF12;}\n",
       ".cython.score-131 {background-color: #FFFF12;}\n",
       ".cython.score-132 {background-color: #FFFF11;}\n",
       ".cython.score-133 {background-color: #FFFF11;}\n",
       ".cython.score-134 {background-color: #FFFF11;}\n",
       ".cython.score-135 {background-color: #FFFF11;}\n",
       ".cython.score-136 {background-color: #FFFF11;}\n",
       ".cython.score-137 {background-color: #FFFF11;}\n",
       ".cython.score-138 {background-color: #FFFF11;}\n",
       ".cython.score-139 {background-color: #FFFF11;}\n",
       ".cython.score-140 {background-color: #FFFF11;}\n",
       ".cython.score-141 {background-color: #FFFF10;}\n",
       ".cython.score-142 {background-color: #FFFF10;}\n",
       ".cython.score-143 {background-color: #FFFF10;}\n",
       ".cython.score-144 {background-color: #FFFF10;}\n",
       ".cython.score-145 {background-color: #FFFF10;}\n",
       ".cython.score-146 {background-color: #FFFF10;}\n",
       ".cython.score-147 {background-color: #FFFF10;}\n",
       ".cython.score-148 {background-color: #FFFF10;}\n",
       ".cython.score-149 {background-color: #FFFF10;}\n",
       ".cython.score-150 {background-color: #FFFF0f;}\n",
       ".cython.score-151 {background-color: #FFFF0f;}\n",
       ".cython.score-152 {background-color: #FFFF0f;}\n",
       ".cython.score-153 {background-color: #FFFF0f;}\n",
       ".cython.score-154 {background-color: #FFFF0f;}\n",
       ".cython.score-155 {background-color: #FFFF0f;}\n",
       ".cython.score-156 {background-color: #FFFF0f;}\n",
       ".cython.score-157 {background-color: #FFFF0f;}\n",
       ".cython.score-158 {background-color: #FFFF0f;}\n",
       ".cython.score-159 {background-color: #FFFF0f;}\n",
       ".cython.score-160 {background-color: #FFFF0f;}\n",
       ".cython.score-161 {background-color: #FFFF0e;}\n",
       ".cython.score-162 {background-color: #FFFF0e;}\n",
       ".cython.score-163 {background-color: #FFFF0e;}\n",
       ".cython.score-164 {background-color: #FFFF0e;}\n",
       ".cython.score-165 {background-color: #FFFF0e;}\n",
       ".cython.score-166 {background-color: #FFFF0e;}\n",
       ".cython.score-167 {background-color: #FFFF0e;}\n",
       ".cython.score-168 {background-color: #FFFF0e;}\n",
       ".cython.score-169 {background-color: #FFFF0e;}\n",
       ".cython.score-170 {background-color: #FFFF0e;}\n",
       ".cython.score-171 {background-color: #FFFF0e;}\n",
       ".cython.score-172 {background-color: #FFFF0e;}\n",
       ".cython.score-173 {background-color: #FFFF0d;}\n",
       ".cython.score-174 {background-color: #FFFF0d;}\n",
       ".cython.score-175 {background-color: #FFFF0d;}\n",
       ".cython.score-176 {background-color: #FFFF0d;}\n",
       ".cython.score-177 {background-color: #FFFF0d;}\n",
       ".cython.score-178 {background-color: #FFFF0d;}\n",
       ".cython.score-179 {background-color: #FFFF0d;}\n",
       ".cython.score-180 {background-color: #FFFF0d;}\n",
       ".cython.score-181 {background-color: #FFFF0d;}\n",
       ".cython.score-182 {background-color: #FFFF0d;}\n",
       ".cython.score-183 {background-color: #FFFF0d;}\n",
       ".cython.score-184 {background-color: #FFFF0d;}\n",
       ".cython.score-185 {background-color: #FFFF0d;}\n",
       ".cython.score-186 {background-color: #FFFF0d;}\n",
       ".cython.score-187 {background-color: #FFFF0c;}\n",
       ".cython.score-188 {background-color: #FFFF0c;}\n",
       ".cython.score-189 {background-color: #FFFF0c;}\n",
       ".cython.score-190 {background-color: #FFFF0c;}\n",
       ".cython.score-191 {background-color: #FFFF0c;}\n",
       ".cython.score-192 {background-color: #FFFF0c;}\n",
       ".cython.score-193 {background-color: #FFFF0c;}\n",
       ".cython.score-194 {background-color: #FFFF0c;}\n",
       ".cython.score-195 {background-color: #FFFF0c;}\n",
       ".cython.score-196 {background-color: #FFFF0c;}\n",
       ".cython.score-197 {background-color: #FFFF0c;}\n",
       ".cython.score-198 {background-color: #FFFF0c;}\n",
       ".cython.score-199 {background-color: #FFFF0c;}\n",
       ".cython.score-200 {background-color: #FFFF0c;}\n",
       ".cython.score-201 {background-color: #FFFF0c;}\n",
       ".cython.score-202 {background-color: #FFFF0c;}\n",
       ".cython.score-203 {background-color: #FFFF0b;}\n",
       ".cython.score-204 {background-color: #FFFF0b;}\n",
       ".cython.score-205 {background-color: #FFFF0b;}\n",
       ".cython.score-206 {background-color: #FFFF0b;}\n",
       ".cython.score-207 {background-color: #FFFF0b;}\n",
       ".cython.score-208 {background-color: #FFFF0b;}\n",
       ".cython.score-209 {background-color: #FFFF0b;}\n",
       ".cython.score-210 {background-color: #FFFF0b;}\n",
       ".cython.score-211 {background-color: #FFFF0b;}\n",
       ".cython.score-212 {background-color: #FFFF0b;}\n",
       ".cython.score-213 {background-color: #FFFF0b;}\n",
       ".cython.score-214 {background-color: #FFFF0b;}\n",
       ".cython.score-215 {background-color: #FFFF0b;}\n",
       ".cython.score-216 {background-color: #FFFF0b;}\n",
       ".cython.score-217 {background-color: #FFFF0b;}\n",
       ".cython.score-218 {background-color: #FFFF0b;}\n",
       ".cython.score-219 {background-color: #FFFF0b;}\n",
       ".cython.score-220 {background-color: #FFFF0b;}\n",
       ".cython.score-221 {background-color: #FFFF0b;}\n",
       ".cython.score-222 {background-color: #FFFF0a;}\n",
       ".cython.score-223 {background-color: #FFFF0a;}\n",
       ".cython.score-224 {background-color: #FFFF0a;}\n",
       ".cython.score-225 {background-color: #FFFF0a;}\n",
       ".cython.score-226 {background-color: #FFFF0a;}\n",
       ".cython.score-227 {background-color: #FFFF0a;}\n",
       ".cython.score-228 {background-color: #FFFF0a;}\n",
       ".cython.score-229 {background-color: #FFFF0a;}\n",
       ".cython.score-230 {background-color: #FFFF0a;}\n",
       ".cython.score-231 {background-color: #FFFF0a;}\n",
       ".cython.score-232 {background-color: #FFFF0a;}\n",
       ".cython.score-233 {background-color: #FFFF0a;}\n",
       ".cython.score-234 {background-color: #FFFF0a;}\n",
       ".cython.score-235 {background-color: #FFFF0a;}\n",
       ".cython.score-236 {background-color: #FFFF0a;}\n",
       ".cython.score-237 {background-color: #FFFF0a;}\n",
       ".cython.score-238 {background-color: #FFFF0a;}\n",
       ".cython.score-239 {background-color: #FFFF0a;}\n",
       ".cython.score-240 {background-color: #FFFF0a;}\n",
       ".cython.score-241 {background-color: #FFFF0a;}\n",
       ".cython.score-242 {background-color: #FFFF0a;}\n",
       ".cython.score-243 {background-color: #FFFF0a;}\n",
       ".cython.score-244 {background-color: #FFFF0a;}\n",
       ".cython.score-245 {background-color: #FFFF0a;}\n",
       ".cython.score-246 {background-color: #FFFF09;}\n",
       ".cython.score-247 {background-color: #FFFF09;}\n",
       ".cython.score-248 {background-color: #FFFF09;}\n",
       ".cython.score-249 {background-color: #FFFF09;}\n",
       ".cython.score-250 {background-color: #FFFF09;}\n",
       ".cython.score-251 {background-color: #FFFF09;}\n",
       ".cython.score-252 {background-color: #FFFF09;}\n",
       ".cython.score-253 {background-color: #FFFF09;}\n",
       ".cython.score-254 {background-color: #FFFF09;}\n",
       "pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".cython .hll { background-color: #ffffcc }\n",
       ".cython { background: #f8f8f8; }\n",
       ".cython .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".cython .err { border: 1px solid #FF0000 } /* Error */\n",
       ".cython .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".cython .o { color: #666666 } /* Operator */\n",
       ".cython .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".cython .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".cython .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".cython .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".cython .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".cython .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".cython .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".cython .ge { font-style: italic } /* Generic.Emph */\n",
       ".cython .gr { color: #E40000 } /* Generic.Error */\n",
       ".cython .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".cython .gi { color: #008400 } /* Generic.Inserted */\n",
       ".cython .go { color: #717171 } /* Generic.Output */\n",
       ".cython .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".cython .gs { font-weight: bold } /* Generic.Strong */\n",
       ".cython .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".cython .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".cython .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".cython .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".cython .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".cython .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".cython .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".cython .kt { color: #B00040 } /* Keyword.Type */\n",
       ".cython .m { color: #666666 } /* Literal.Number */\n",
       ".cython .s { color: #BA2121 } /* Literal.String */\n",
       ".cython .na { color: #687822 } /* Name.Attribute */\n",
       ".cython .nb { color: #008000 } /* Name.Builtin */\n",
       ".cython .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".cython .no { color: #880000 } /* Name.Constant */\n",
       ".cython .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".cython .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".cython .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".cython .nf { color: #0000FF } /* Name.Function */\n",
       ".cython .nl { color: #767600 } /* Name.Label */\n",
       ".cython .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".cython .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".cython .nv { color: #19177C } /* Name.Variable */\n",
       ".cython .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".cython .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".cython .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".cython .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".cython .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".cython .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".cython .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".cython .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".cython .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".cython .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".cython .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".cython .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".cython .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".cython .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".cython .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".cython .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".cython .sx { color: #008000 } /* Literal.String.Other */\n",
       ".cython .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".cython .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".cython .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".cython .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".cython .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".cython .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".cython .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".cython .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".cython .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".cython .il { color: #666666 } /* Literal.Number.Integer.Long */\n",
       "    </style>\n",
       "</head>\n",
       "<body class=\"cython\">\n",
       "<p><span style=\"border-bottom: solid 1px grey;\">Generated by Cython 0.29.34</span></p>\n",
       "<p>\n",
       "    <span style=\"background-color: #FFFF00\">Yellow lines</span> hint at Python interaction.<br />\n",
       "    Click on a line that starts with a \"<code>+</code>\" to see the C code that Cython generated for it.\n",
       "</p>\n",
       "<div class=\"cython\"><pre class=\"cython line score-8\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">01</span>: <span class=\"k\">from</span> <span class=\"nn\">libc.math</span> <span class=\"k\">cimport</span> <span class=\"n\">log</span><span class=\"p\">,</span> <span class=\"n\">isfinite</span></pre>\n",
       "<pre class='cython code score-8 '>  __pyx_t_3 = <span class='pyx_c_api'>__Pyx_PyDict_NewPresized</span>(0);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_test, __pyx_t_3) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 1, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">02</span>: <span class=\"k\">from</span> <span class=\"nn\">libc.stdlib</span> <span class=\"k\">cimport</span> <span class=\"n\">calloc</span><span class=\"p\">,</span> <span class=\"n\">free</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">03</span>: <span class=\"k\">cimport</span> <span class=\"nn\">cython</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">04</span>: <span class=\"k\">from</span> <span class=\"nn\">cython</span> <span class=\"k\">cimport</span> <span class=\"n\">floating</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">05</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">06</span>: <span class=\"k\">ctypedef</span> <span class=\"k\">fused</span> <span class=\"n\">floating_float_double</span><span class=\"p\">:</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">07</span>:     <span class=\"nb\">float</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">08</span>:     <span class=\"n\">double</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">09</span>: </pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">10</span>: <span class=\"nd\">@cython</span><span class=\"o\">.</span><span class=\"n\">boundscheck</span><span class=\"p\">(</span><span class=\"bp\">False</span><span class=\"p\">)</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">11</span>: <span class=\"nd\">@cython</span><span class=\"o\">.</span><span class=\"n\">wraparound</span><span class=\"p\">(</span><span class=\"bp\">False</span><span class=\"p\">)</span></pre>\n",
       "<pre class=\"cython line score-539\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">12</span>: <span class=\"k\">def</span> <span class=\"nf\">joint_to_mi_cython</span><span class=\"p\">(</span><span class=\"n\">floating_float_double</span><span class=\"p\">[:,</span> <span class=\"p\">::</span><span class=\"mf\">1</span><span class=\"p\">]</span> <span class=\"n\">joint</span><span class=\"p\">,</span> <span class=\"n\">floating_float_double</span> <span class=\"n\">forward_euler_a</span><span class=\"o\">=</span><span class=\"mf\">1.</span><span class=\"p\">,</span> <span class=\"n\">floating_float_double</span> <span class=\"n\">forward_euler_b</span><span class=\"o\">=</span><span class=\"mf\">1.</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-539 '>/* Python wrapper */\n",
       "static PyObject *__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_1joint_to_mi_cython(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/\n",
       "static PyMethodDef __pyx_mdef_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_1joint_to_mi_cython = {\"joint_to_mi_cython\", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_1joint_to_mi_cython, METH_VARARGS|METH_KEYWORDS, 0};\n",
       "static PyObject *__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_1joint_to_mi_cython(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {\n",
       "  PyObject *__pyx_v_signatures = 0;\n",
       "  PyObject *__pyx_v_args = 0;\n",
       "  PyObject *__pyx_v_kwargs = 0;\n",
       "  CYTHON_UNUSED PyObject *__pyx_v_defaults = 0;\n",
       "  PyObject *__pyx_r = 0;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"__pyx_fused_cpdef (wrapper)\", 0);\n",
       "  {\n",
       "    static PyObject **__pyx_pyargnames[] = {&amp;__pyx_n_s_signatures,&amp;__pyx_n_s_args,&amp;__pyx_n_s_kwargs,&amp;__pyx_n_s_defaults,0};\n",
       "    PyObject* values[4] = {0,0,0,0};\n",
       "    values[1] = __pyx_k_;\n",
       "    values[2] = __pyx_k__2;\n",
       "    if (unlikely(__pyx_kwds)) {\n",
       "      Py_ssize_t kw_args;\n",
       "      const Py_ssize_t pos_args = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args);\n",
       "      switch (pos_args) {\n",
       "        case  4: values[3] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 3);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  3: values[2] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 2);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2: values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1: values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  0: break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "      kw_args = <span class='py_c_api'>PyDict_Size</span>(__pyx_kwds);\n",
       "      switch (pos_args) {\n",
       "        case  0:\n",
       "        if (likely((values[0] = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_signatures)) != 0)) kw_args--;\n",
       "        else goto __pyx_L5_argtuple_error;\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1:\n",
       "        if (kw_args &gt; 0) {\n",
       "          PyObject* value = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_args);\n",
       "          if (value) { values[1] = value; kw_args--; }\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2:\n",
       "        if (kw_args &gt; 0) {\n",
       "          PyObject* value = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_kwargs);\n",
       "          if (value) { values[2] = value; kw_args--; }\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  3:\n",
       "        if (likely((values[3] = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_defaults)) != 0)) kw_args--;\n",
       "        else {\n",
       "          <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"__pyx_fused_cpdef\", 1, 4, 4, 3); <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "        }\n",
       "      }\n",
       "      if (unlikely(kw_args &gt; 0)) {\n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_ParseOptionalKeywords</span>(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, \"__pyx_fused_cpdef\") &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "      }\n",
       "    } else if (<span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args) != 4) {\n",
       "      goto __pyx_L5_argtuple_error;\n",
       "    } else {\n",
       "      values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "      values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "      values[2] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 2);\n",
       "      values[3] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 3);\n",
       "    }\n",
       "    __pyx_v_signatures = values[0];\n",
       "    __pyx_v_args = values[1];\n",
       "    __pyx_v_kwargs = values[2];\n",
       "    __pyx_v_defaults = values[3];\n",
       "  }\n",
       "  goto __pyx_L4_argument_unpacking_done;\n",
       "  __pyx_L5_argtuple_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"__pyx_fused_cpdef\", 1, 4, 4, <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args)); <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "  __pyx_L3_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_fb653f3f00a0b0d040a3af1124789652.__pyx_fused_cpdef\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return NULL;\n",
       "  __pyx_L4_argument_unpacking_done:;\n",
       "  __pyx_r = __pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_joint_to_mi_cython(__pyx_self, __pyx_v_signatures, __pyx_v_args, __pyx_v_kwargs, __pyx_v_defaults);\n",
       "  int __pyx_lineno = 0;\n",
       "  const char *__pyx_filename = NULL;\n",
       "  int __pyx_clineno = 0;\n",
       "\n",
       "  /* function exit code */\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static PyObject *__pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_joint_to_mi_cython(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_signatures, PyObject *__pyx_v_args, PyObject *__pyx_v_kwargs, CYTHON_UNUSED PyObject *__pyx_v_defaults) {\n",
       "  PyObject *__pyx_v_dest_sig = NULL;\n",
       "  Py_ssize_t __pyx_v_i;\n",
       "  PyTypeObject *__pyx_v_ndarray = 0;\n",
       "  __Pyx_memviewslice __pyx_v_memslice;\n",
       "  Py_ssize_t __pyx_v_itemsize;\n",
       "  CYTHON_UNUSED int __pyx_v_dtype_signed;\n",
       "  char __pyx_v_kind;\n",
       "  PyObject *__pyx_v_arg = NULL;\n",
       "  PyObject *__pyx_v_dtype = NULL;\n",
       "  PyObject *__pyx_v_arg_base = NULL;\n",
       "  PyObject *__pyx_v_candidates = NULL;\n",
       "  PyObject *__pyx_v_sig = NULL;\n",
       "  int __pyx_v_match_found;\n",
       "  PyObject *__pyx_v_src_sig = NULL;\n",
       "  PyObject *__pyx_v_dst_type = NULL;\n",
       "  PyObject *__pyx_r = NULL;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"joint_to_mi_cython\", 0);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_v_kwargs);\n",
       "  __pyx_t_1 = <span class='py_c_api'>PyList_New</span>(1);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(Py_None);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(Py_None);\n",
       "  <span class='py_macro_api'>PyList_SET_ITEM</span>(__pyx_t_1, 0, Py_None);\n",
       "  __pyx_v_dest_sig = ((PyObject*)__pyx_t_1);\n",
       "  __pyx_t_1 = 0;\n",
       "  __pyx_t_3 = (__pyx_v_kwargs != Py_None);\n",
       "  __pyx_t_4 = (__pyx_t_3 != 0);\n",
       "  if (__pyx_t_4) {\n",
       "  } else {\n",
       "    __pyx_t_2 = __pyx_t_4;\n",
       "    goto __pyx_L4_bool_binop_done;\n",
       "  }\n",
       "  __pyx_t_4 = <span class='pyx_c_api'>__Pyx_PyObject_IsTrue</span>(__pyx_v_kwargs); if (unlikely(__pyx_t_4 &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  __pyx_t_3 = ((!__pyx_t_4) != 0);\n",
       "  __pyx_t_2 = __pyx_t_3;\n",
       "  __pyx_L4_bool_binop_done:;\n",
       "  if (__pyx_t_2) {\n",
       "    <span class='pyx_macro_api'>__Pyx_INCREF</span>(Py_None);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_v_kwargs, Py_None);\n",
       "  }\n",
       "  __pyx_t_1 = ((PyObject *)<span class='pyx_c_api'>__Pyx_ImportNumPyArrayTypeIfAvailable</span>());<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  __pyx_v_ndarray = ((PyTypeObject*)__pyx_t_1);\n",
       "  __pyx_t_1 = 0;\n",
       "  __pyx_v_itemsize = -1L;\n",
       "  if (unlikely(__pyx_v_args == Py_None)) {\n",
       "    <span class='py_c_api'>PyErr_SetString</span>(PyExc_TypeError, \"object of type 'NoneType' has no len()\");\n",
       "    <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  }\n",
       "  __pyx_t_5 = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(((PyObject*)__pyx_v_args));<span class='error_goto'> if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  __pyx_t_2 = ((0 &lt; __pyx_t_5) != 0);\n",
       "  if (__pyx_t_2) {\n",
       "    if (unlikely(__pyx_v_args == Py_None)) {\n",
       "      <span class='py_c_api'>PyErr_SetString</span>(PyExc_TypeError, \"'NoneType' object is not subscriptable\");\n",
       "      <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    }\n",
       "    __pyx_t_1 = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(((PyObject*)__pyx_v_args), 0);\n",
       "    <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_1);\n",
       "    __pyx_v_arg = __pyx_t_1;\n",
       "    __pyx_t_1 = 0;\n",
       "    goto __pyx_L6;\n",
       "  }\n",
       "  __pyx_t_3 = (__pyx_v_kwargs != Py_None);\n",
       "  __pyx_t_4 = (__pyx_t_3 != 0);\n",
       "  if (__pyx_t_4) {\n",
       "  } else {\n",
       "    __pyx_t_2 = __pyx_t_4;\n",
       "    goto __pyx_L7_bool_binop_done;\n",
       "  }\n",
       "  if (unlikely(__pyx_v_kwargs == Py_None)) {\n",
       "    <span class='py_c_api'>PyErr_SetString</span>(PyExc_TypeError, \"'NoneType' object is not iterable\");\n",
       "    <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  }\n",
       "  __pyx_t_4 = (<span class='pyx_c_api'>__Pyx_PyDict_ContainsTF</span>(__pyx_n_s_joint, ((PyObject*)__pyx_v_kwargs), Py_EQ)); if (unlikely(__pyx_t_4 &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  __pyx_t_3 = (__pyx_t_4 != 0);\n",
       "  __pyx_t_2 = __pyx_t_3;\n",
       "  __pyx_L7_bool_binop_done:;\n",
       "  if (__pyx_t_2) {\n",
       "    if (unlikely(__pyx_v_kwargs == Py_None)) {\n",
       "      <span class='py_c_api'>PyErr_SetString</span>(PyExc_TypeError, \"'NoneType' object is not subscriptable\");\n",
       "      <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    }\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyDict_GetItem</span>(((PyObject*)__pyx_v_kwargs), __pyx_n_s_joint);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    __pyx_v_arg = __pyx_t_1;\n",
       "    __pyx_t_1 = 0;\n",
       "    goto __pyx_L6;\n",
       "  }\n",
       "  /*else*/ {\n",
       "    if (unlikely(__pyx_v_args == Py_None)) {\n",
       "      <span class='py_c_api'>PyErr_SetString</span>(PyExc_TypeError, \"object of type 'NoneType' has no len()\");\n",
       "      <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    }\n",
       "    __pyx_t_5 = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(((PyObject*)__pyx_v_args));<span class='error_goto'> if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    __pyx_t_1 = <span class='py_c_api'>PyInt_FromSsize_t</span>(__pyx_t_5);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    __pyx_t_6 = <span class='py_c_api'>PyTuple_New</span>(3);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "    <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_int_1);\n",
       "    <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_int_1);\n",
       "    <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_6, 0, __pyx_int_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_kp_s__3);\n",
       "    <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_kp_s__3);\n",
       "    <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_6, 1, __pyx_kp_s__3);\n",
       "    <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_1);\n",
       "    <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_6, 2, __pyx_t_1);\n",
       "    __pyx_t_1 = 0;\n",
       "    __pyx_t_1 = <span class='pyx_c_api'>__Pyx_PyString_Format</span>(__pyx_kp_s_Expected_at_least_d_argument_s_g, __pyx_t_6);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "    __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_CallOneArg</span>(__pyx_builtin_TypeError, __pyx_t_1);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "    <span class='pyx_c_api'>__Pyx_Raise</span>(__pyx_t_6, 0, 0, 0);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "    <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  }\n",
       "  __pyx_L6:;\n",
       "  while (1) {\n",
       "    __pyx_t_2 = (__pyx_v_ndarray != ((PyTypeObject*)Py_None));\n",
       "    __pyx_t_3 = (__pyx_t_2 != 0);\n",
       "    if (__pyx_t_3) {\n",
       "      __pyx_t_3 = <span class='pyx_c_api'>__Pyx_TypeCheck</span>(__pyx_v_arg, __pyx_v_ndarray); \n",
       "      __pyx_t_2 = (__pyx_t_3 != 0);\n",
       "      if (__pyx_t_2) {\n",
       "        __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_arg, __pyx_n_s_dtype);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "        __pyx_v_dtype = __pyx_t_6;\n",
       "        __pyx_t_6 = 0;\n",
       "        goto __pyx_L12;\n",
       "      }\n",
       "      __pyx_t_2 = __pyx_memoryview_check(__pyx_v_arg); \n",
       "      __pyx_t_3 = (__pyx_t_2 != 0);\n",
       "      if (__pyx_t_3) {\n",
       "        __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_arg, __pyx_n_s_base);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "        __pyx_v_arg_base = __pyx_t_6;\n",
       "        __pyx_t_6 = 0;\n",
       "        __pyx_t_3 = <span class='pyx_c_api'>__Pyx_TypeCheck</span>(__pyx_v_arg_base, __pyx_v_ndarray); \n",
       "        __pyx_t_2 = (__pyx_t_3 != 0);\n",
       "        if (__pyx_t_2) {\n",
       "          __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_arg_base, __pyx_n_s_dtype);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "          <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "          __pyx_v_dtype = __pyx_t_6;\n",
       "          __pyx_t_6 = 0;\n",
       "          goto __pyx_L13;\n",
       "        }\n",
       "        /*else*/ {\n",
       "          <span class='pyx_macro_api'>__Pyx_INCREF</span>(Py_None);\n",
       "          __pyx_v_dtype = Py_None;\n",
       "        }\n",
       "        __pyx_L13:;\n",
       "        goto __pyx_L12;\n",
       "      }\n",
       "      /*else*/ {\n",
       "        <span class='pyx_macro_api'>__Pyx_INCREF</span>(Py_None);\n",
       "        __pyx_v_dtype = Py_None;\n",
       "      }\n",
       "      __pyx_L12:;\n",
       "      __pyx_v_itemsize = -1L;\n",
       "      __pyx_t_2 = (__pyx_v_dtype != Py_None);\n",
       "      __pyx_t_3 = (__pyx_t_2 != 0);\n",
       "      if (__pyx_t_3) {\n",
       "        __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_dtype, __pyx_n_s_itemsize);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "        __pyx_t_5 = <span class='pyx_c_api'>__Pyx_PyIndex_AsSsize_t</span>(__pyx_t_6); if (unlikely((__pyx_t_5 == (Py_ssize_t)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "        __pyx_v_itemsize = __pyx_t_5;\n",
       "        __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_dtype, __pyx_n_s_kind);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "        __pyx_t_7 = <span class='pyx_c_api'>__Pyx_PyObject_Ord</span>(__pyx_t_6);<span class='error_goto'> if (unlikely(__pyx_t_7 == ((long)(long)(Py_UCS4)-1))) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "        __pyx_v_kind = __pyx_t_7;\n",
       "        __pyx_v_dtype_signed = (__pyx_v_kind == 'i');\n",
       "        switch (__pyx_v_kind) {\n",
       "          case 'i':\n",
       "          case 'u':\n",
       "          break;\n",
       "          case 'f':\n",
       "          __pyx_t_2 = (((sizeof(float)) == __pyx_v_itemsize) != 0);\n",
       "          if (__pyx_t_2) {\n",
       "          } else {\n",
       "            __pyx_t_3 = __pyx_t_2;\n",
       "            goto __pyx_L16_bool_binop_done;\n",
       "          }\n",
       "          __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_arg, __pyx_n_s_ndim);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "          <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "          __pyx_t_5 = <span class='pyx_c_api'>__Pyx_PyIndex_AsSsize_t</span>(__pyx_t_6); if (unlikely((__pyx_t_5 == (Py_ssize_t)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "          <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "          __pyx_t_2 = ((((Py_ssize_t)__pyx_t_5) == 2) != 0);\n",
       "          __pyx_t_3 = __pyx_t_2;\n",
       "          __pyx_L16_bool_binop_done:;\n",
       "          if (__pyx_t_3) {\n",
       "            if (unlikely(<span class='pyx_c_api'>__Pyx_SetItemInt</span>(__pyx_v_dest_sig, 0, __pyx_n_s_float, long, 1, __Pyx_PyInt_From_long, 1, 0, 0) &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "            goto __pyx_L10_break;\n",
       "          }\n",
       "          __pyx_t_2 = (((sizeof(double)) == __pyx_v_itemsize) != 0);\n",
       "          if (__pyx_t_2) {\n",
       "          } else {\n",
       "            __pyx_t_3 = __pyx_t_2;\n",
       "            goto __pyx_L19_bool_binop_done;\n",
       "          }\n",
       "          __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_arg, __pyx_n_s_ndim);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "          <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "          __pyx_t_5 = <span class='pyx_c_api'>__Pyx_PyIndex_AsSsize_t</span>(__pyx_t_6); if (unlikely((__pyx_t_5 == (Py_ssize_t)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "          <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "          __pyx_t_2 = ((((Py_ssize_t)__pyx_t_5) == 2) != 0);\n",
       "          __pyx_t_3 = __pyx_t_2;\n",
       "          __pyx_L19_bool_binop_done:;\n",
       "          if (__pyx_t_3) {\n",
       "            if (unlikely(<span class='pyx_c_api'>__Pyx_SetItemInt</span>(__pyx_v_dest_sig, 0, __pyx_n_s_double, long, 1, __Pyx_PyInt_From_long, 1, 0, 0) &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "            goto __pyx_L10_break;\n",
       "          }\n",
       "          break;\n",
       "          case 'c':\n",
       "          break;\n",
       "          case 'O':\n",
       "          break;\n",
       "          default: break;\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    __pyx_t_2 = ((__pyx_v_itemsize == -1L) != 0);\n",
       "    if (!__pyx_t_2) {\n",
       "    } else {\n",
       "      __pyx_t_3 = __pyx_t_2;\n",
       "      goto __pyx_L22_bool_binop_done;\n",
       "    }\n",
       "    __pyx_t_2 = ((__pyx_v_itemsize == (sizeof(float))) != 0);\n",
       "    __pyx_t_3 = __pyx_t_2;\n",
       "    __pyx_L22_bool_binop_done:;\n",
       "    if (__pyx_t_3) {\n",
       "      __pyx_t_8 = <span class='pyx_c_api'>__Pyx_PyObject_to_MemoryviewSlice_d_dc_float</span>(__pyx_v_arg, 0); \n",
       "      __pyx_v_memslice = __pyx_t_8;\n",
       "      __pyx_t_3 = (__pyx_v_memslice.memview != 0);\n",
       "      if (__pyx_t_3) {\n",
       "        __PYX_XDEC_MEMVIEW((&amp;__pyx_v_memslice), 1); \n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_SetItemInt</span>(__pyx_v_dest_sig, 0, __pyx_n_s_float, long, 1, __Pyx_PyInt_From_long, 1, 0, 0) &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        goto __pyx_L10_break;\n",
       "      }\n",
       "      /*else*/ {\n",
       "        <span class='py_c_api'>PyErr_Clear</span>(); \n",
       "      }\n",
       "    }\n",
       "    __pyx_t_2 = ((__pyx_v_itemsize == -1L) != 0);\n",
       "    if (!__pyx_t_2) {\n",
       "    } else {\n",
       "      __pyx_t_3 = __pyx_t_2;\n",
       "      goto __pyx_L26_bool_binop_done;\n",
       "    }\n",
       "    __pyx_t_2 = ((__pyx_v_itemsize == (sizeof(double))) != 0);\n",
       "    __pyx_t_3 = __pyx_t_2;\n",
       "    __pyx_L26_bool_binop_done:;\n",
       "    if (__pyx_t_3) {\n",
       "      __pyx_t_8 = <span class='pyx_c_api'>__Pyx_PyObject_to_MemoryviewSlice_d_dc_double</span>(__pyx_v_arg, 0); \n",
       "      __pyx_v_memslice = __pyx_t_8;\n",
       "      __pyx_t_3 = (__pyx_v_memslice.memview != 0);\n",
       "      if (__pyx_t_3) {\n",
       "        __PYX_XDEC_MEMVIEW((&amp;__pyx_v_memslice), 1); \n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_SetItemInt</span>(__pyx_v_dest_sig, 0, __pyx_n_s_double, long, 1, __Pyx_PyInt_From_long, 1, 0, 0) &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        goto __pyx_L10_break;\n",
       "      }\n",
       "      /*else*/ {\n",
       "        <span class='py_c_api'>PyErr_Clear</span>(); \n",
       "      }\n",
       "    }\n",
       "    if (unlikely(<span class='pyx_c_api'>__Pyx_SetItemInt</span>(__pyx_v_dest_sig, 0, Py_None, long, 1, __Pyx_PyInt_From_long, 1, 0, 0) &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    goto __pyx_L10_break;\n",
       "  }\n",
       "  __pyx_L10_break:;\n",
       "  __pyx_t_6 = <span class='py_c_api'>PyList_New</span>(0);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "  __pyx_v_candidates = ((PyObject*)__pyx_t_6);\n",
       "  __pyx_t_6 = 0;\n",
       "  __pyx_t_5 = 0;\n",
       "  if (unlikely(__pyx_v_signatures == Py_None)) {\n",
       "    <span class='py_c_api'>PyErr_SetString</span>(PyExc_TypeError, \"'NoneType' object is not iterable\");\n",
       "    <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  }\n",
       "  __pyx_t_1 = __Pyx_dict_iterator(((PyObject*)__pyx_v_signatures), 1, ((PyObject *)NULL), (&amp;__pyx_t_9), (&amp;__pyx_t_10));<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_6);\n",
       "  __pyx_t_6 = __pyx_t_1;\n",
       "  __pyx_t_1 = 0;\n",
       "  while (1) {\n",
       "    __pyx_t_11 = __Pyx_dict_iter_next(__pyx_t_6, __pyx_t_9, &amp;__pyx_t_5, &amp;__pyx_t_1, NULL, NULL, __pyx_t_10);\n",
       "    if (unlikely(__pyx_t_11 == 0)) break;\n",
       "    if (unlikely(__pyx_t_11 == -1)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF_SET</span>(__pyx_v_sig, __pyx_t_1);\n",
       "    __pyx_t_1 = 0;\n",
       "    __pyx_v_match_found = 0;\n",
       "    __pyx_t_13 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_v_sig, __pyx_n_s_strip);<span class='error_goto'> if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_13);\n",
       "    __pyx_t_14 = NULL;\n",
       "    if (CYTHON_UNPACK_METHODS &amp;&amp; likely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_13))) {\n",
       "      __pyx_t_14 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_13);\n",
       "      if (likely(__pyx_t_14)) {\n",
       "        PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_13);\n",
       "        <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_14);\n",
       "        <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "        <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_13, function);\n",
       "      }\n",
       "    }\n",
       "    __pyx_t_12 = (__pyx_t_14) ? __Pyx_PyObject_Call2Args(__pyx_t_13, __pyx_t_14, __pyx_kp_s__4) : <span class='pyx_c_api'>__Pyx_PyObject_CallOneArg</span>(__pyx_t_13, __pyx_kp_s__4);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_14); __pyx_t_14 = 0;\n",
       "    if (unlikely(!__pyx_t_12)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_12);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_13); __pyx_t_13 = 0;\n",
       "    __pyx_t_13 = <span class='pyx_c_api'>__Pyx_PyObject_GetAttrStr</span>(__pyx_t_12, __pyx_n_s_split);<span class='error_goto'> if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_13);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_12); __pyx_t_12 = 0;\n",
       "    __pyx_t_12 = NULL;\n",
       "    if (CYTHON_UNPACK_METHODS &amp;&amp; likely(<span class='py_c_api'>PyMethod_Check</span>(__pyx_t_13))) {\n",
       "      __pyx_t_12 = <span class='py_macro_api'>PyMethod_GET_SELF</span>(__pyx_t_13);\n",
       "      if (likely(__pyx_t_12)) {\n",
       "        PyObject* function = <span class='py_macro_api'>PyMethod_GET_FUNCTION</span>(__pyx_t_13);\n",
       "        <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_12);\n",
       "        <span class='pyx_macro_api'>__Pyx_INCREF</span>(function);\n",
       "        <span class='pyx_macro_api'>__Pyx_DECREF_SET</span>(__pyx_t_13, function);\n",
       "      }\n",
       "    }\n",
       "    __pyx_t_1 = (__pyx_t_12) ? __Pyx_PyObject_Call2Args(__pyx_t_13, __pyx_t_12, __pyx_kp_s__5) : <span class='pyx_c_api'>__Pyx_PyObject_CallOneArg</span>(__pyx_t_13, __pyx_kp_s__5);\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_12); __pyx_t_12 = 0;\n",
       "    if (unlikely(!__pyx_t_1)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_13); __pyx_t_13 = 0;\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF_SET</span>(__pyx_v_src_sig, __pyx_t_1);\n",
       "    __pyx_t_1 = 0;\n",
       "    __pyx_t_15 = <span class='py_macro_api'>PyList_GET_SIZE</span>(__pyx_v_dest_sig);<span class='error_goto'> if (unlikely(__pyx_t_15 == ((Py_ssize_t)-1))) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    __pyx_t_16 = __pyx_t_15;\n",
       "    for (__pyx_t_17 = 0; __pyx_t_17 &lt; __pyx_t_16; __pyx_t_17+=1) {\n",
       "      __pyx_v_i = __pyx_t_17;\n",
       "      __pyx_t_1 = <span class='py_macro_api'>PyList_GET_ITEM</span>(__pyx_v_dest_sig, __pyx_v_i);\n",
       "      <span class='pyx_macro_api'>__Pyx_INCREF</span>(__pyx_t_1);\n",
       "      <span class='pyx_macro_api'>__Pyx_XDECREF_SET</span>(__pyx_v_dst_type, __pyx_t_1);\n",
       "      __pyx_t_1 = 0;\n",
       "      __pyx_t_3 = (__pyx_v_dst_type != Py_None);\n",
       "      __pyx_t_2 = (__pyx_t_3 != 0);\n",
       "      if (__pyx_t_2) {\n",
       "        __pyx_t_1 = <span class='pyx_c_api'>__Pyx_GetItemInt</span>(__pyx_v_src_sig, __pyx_v_i, Py_ssize_t, 1, PyInt_FromSsize_t, 0, 0, 0);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "        __pyx_t_13 = <span class='py_c_api'>PyObject_RichCompare</span>(__pyx_t_1, __pyx_v_dst_type, Py_EQ); <span class='refnanny'>__Pyx_XGOTREF</span>(__pyx_t_13);<span class='error_goto'> if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "        __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyObject_IsTrue</span>(__pyx_t_13); if (unlikely(__pyx_t_2 &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "        <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_13); __pyx_t_13 = 0;\n",
       "        if (__pyx_t_2) {\n",
       "          __pyx_v_match_found = 1;\n",
       "          goto __pyx_L34;\n",
       "        }\n",
       "        /*else*/ {\n",
       "          __pyx_v_match_found = 0;\n",
       "          goto __pyx_L32_break;\n",
       "        }\n",
       "        __pyx_L34:;\n",
       "      }\n",
       "    }\n",
       "    __pyx_L32_break:;\n",
       "    __pyx_t_2 = (__pyx_v_match_found != 0);\n",
       "    if (__pyx_t_2) {\n",
       "      __pyx_t_18 = <span class='pyx_c_api'>__Pyx_PyList_Append</span>(__pyx_v_candidates, __pyx_v_sig);<span class='error_goto'> if (unlikely(__pyx_t_18 == ((int)-1))) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    }\n",
       "  }\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "  __pyx_t_2 = (<span class='py_macro_api'>PyList_GET_SIZE</span>(__pyx_v_candidates) != 0);\n",
       "  __pyx_t_3 = ((!__pyx_t_2) != 0);\n",
       "  if (__pyx_t_3) {\n",
       "    __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_Call</span>(__pyx_builtin_TypeError, __pyx_tuple__6, NULL);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "    <span class='pyx_c_api'>__Pyx_Raise</span>(__pyx_t_6, 0, 0, 0);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "    <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  }\n",
       "  __pyx_t_9 = <span class='py_macro_api'>PyList_GET_SIZE</span>(__pyx_v_candidates);<span class='error_goto'> if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  __pyx_t_3 = ((__pyx_t_9 &gt; 1) != 0);\n",
       "  if (__pyx_t_3) {\n",
       "/* … */\n",
       "  __pyx_tuple__6 = <span class='py_c_api'>PyTuple_Pack</span>(1, __pyx_kp_s_No_matching_signature_found);<span class='error_goto'> if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple__6);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple__6);\n",
       "    __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyObject_Call</span>(__pyx_builtin_TypeError, __pyx_tuple__7, NULL);<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "    <span class='pyx_c_api'>__Pyx_Raise</span>(__pyx_t_6, 0, 0, 0);\n",
       "    <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_6); __pyx_t_6 = 0;\n",
       "    <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  }\n",
       "  /*else*/ {\n",
       "    <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "    if (unlikely(__pyx_v_signatures == Py_None)) {\n",
       "      <span class='py_c_api'>PyErr_SetString</span>(PyExc_TypeError, \"'NoneType' object is not subscriptable\");\n",
       "      <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    }\n",
       "    __pyx_t_6 = <span class='pyx_c_api'>__Pyx_PyDict_GetItem</span>(((PyObject*)__pyx_v_signatures), <span class='py_macro_api'>PyList_GET_ITEM</span>(__pyx_v_candidates, 0));<span class='error_goto'> if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "    <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_6);\n",
       "    __pyx_r = __pyx_t_6;\n",
       "    __pyx_t_6 = 0;\n",
       "    goto __pyx_L0;\n",
       "  }\n",
       "\n",
       "  /* function exit code */\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_6);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_12);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_13);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_14);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_fb653f3f00a0b0d040a3af1124789652.__pyx_fused_cpdef\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = NULL;\n",
       "  __pyx_L0:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_dest_sig);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_ndarray);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_arg);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_dtype);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_arg_base);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_candidates);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_sig);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_src_sig);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_dst_type);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_v_kwargs);\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static PyObject *__pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_12__defaults__(CYTHON_UNUSED PyObject *__pyx_self) {\n",
       "  PyObject *__pyx_r = NULL;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"__defaults__\", 0);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "  __pyx_t_1 = <span class='py_c_api'>PyFloat_FromDouble</span>(<span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults2, __pyx_self)-&gt;__pyx_arg_forward_euler_a);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  __pyx_t_2 = <span class='py_c_api'>PyFloat_FromDouble</span>(<span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults2, __pyx_self)-&gt;__pyx_arg_forward_euler_b);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = <span class='py_c_api'>PyTuple_New</span>(2);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_1);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 0, __pyx_t_1);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_2);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 1, __pyx_t_2);\n",
       "  __pyx_t_1 = 0;\n",
       "  __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = <span class='py_c_api'>PyTuple_New</span>(2);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_3);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_2, 0, __pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(Py_None);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(Py_None);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_2, 1, Py_None);\n",
       "  __pyx_t_3 = 0;\n",
       "  __pyx_r = __pyx_t_2;\n",
       "  __pyx_t_2 = 0;\n",
       "  goto __pyx_L0;\n",
       "\n",
       "  /* function exit code */\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_fb653f3f00a0b0d040a3af1124789652.__defaults__\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = NULL;\n",
       "  __pyx_L0:;\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "/* Python wrapper */\n",
       "static PyObject *__pyx_fuse_0__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_3joint_to_mi_cython(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/\n",
       "static PyMethodDef __pyx_fuse_0__pyx_mdef_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_3joint_to_mi_cython = {\"__pyx_fuse_0joint_to_mi_cython\", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_fuse_0__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_3joint_to_mi_cython, METH_VARARGS|METH_KEYWORDS, 0};\n",
       "static PyObject *__pyx_fuse_0__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_3joint_to_mi_cython(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {\n",
       "  __Pyx_memviewslice __pyx_v_joint = { 0, 0, { 0 }, { 0 }, { 0 } };\n",
       "  float __pyx_v_forward_euler_a;\n",
       "  float __pyx_v_forward_euler_b;\n",
       "  PyObject *__pyx_r = 0;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"joint_to_mi_cython (wrapper)\", 0);\n",
       "  {\n",
       "    static PyObject **__pyx_pyargnames[] = {&amp;__pyx_n_s_joint,&amp;__pyx_n_s_forward_euler_a,&amp;__pyx_n_s_forward_euler_b,0};\n",
       "    PyObject* values[3] = {0,0,0};\n",
       "    __pyx_defaults2 *__pyx_dynamic_args = <span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults2, __pyx_self);\n",
       "    if (unlikely(__pyx_kwds)) {\n",
       "      Py_ssize_t kw_args;\n",
       "      const Py_ssize_t pos_args = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args);\n",
       "      switch (pos_args) {\n",
       "        case  3: values[2] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 2);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2: values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1: values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  0: break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "      kw_args = <span class='py_c_api'>PyDict_Size</span>(__pyx_kwds);\n",
       "      switch (pos_args) {\n",
       "        case  0:\n",
       "        if (likely((values[0] = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_joint)) != 0)) kw_args--;\n",
       "        else goto __pyx_L5_argtuple_error;\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1:\n",
       "        if (kw_args &gt; 0) {\n",
       "          PyObject* value = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_forward_euler_a);\n",
       "          if (value) { values[1] = value; kw_args--; }\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2:\n",
       "        if (kw_args &gt; 0) {\n",
       "          PyObject* value = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_forward_euler_b);\n",
       "          if (value) { values[2] = value; kw_args--; }\n",
       "        }\n",
       "      }\n",
       "      if (unlikely(kw_args &gt; 0)) {\n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_ParseOptionalKeywords</span>(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, \"joint_to_mi_cython\") &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "      }\n",
       "    } else {\n",
       "      switch (<span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args)) {\n",
       "        case  3: values[2] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 2);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2: values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1: values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "        break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "    }\n",
       "    __pyx_v_joint = <span class='pyx_c_api'>__Pyx_PyObject_to_MemoryviewSlice_d_dc_float</span>(values[0], PyBUF_WRITABLE);<span class='error_goto'> if (unlikely(!__pyx_v_joint.memview)) __PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "    if (values[1]) {\n",
       "      __pyx_v_forward_euler_a = __pyx_<span class='py_c_api'>PyFloat_AsFloat</span>(values[1]); if (unlikely((__pyx_v_forward_euler_a == (float)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "    } else {\n",
       "      __pyx_v_forward_euler_a = __pyx_dynamic_args-&gt;__pyx_arg_forward_euler_a;\n",
       "    }\n",
       "    if (values[2]) {\n",
       "      __pyx_v_forward_euler_b = __pyx_<span class='py_c_api'>PyFloat_AsFloat</span>(values[2]); if (unlikely((__pyx_v_forward_euler_b == (float)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "    } else {\n",
       "      __pyx_v_forward_euler_b = __pyx_dynamic_args-&gt;__pyx_arg_forward_euler_b;\n",
       "    }\n",
       "  }\n",
       "  goto __pyx_L4_argument_unpacking_done;\n",
       "  __pyx_L5_argtuple_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"joint_to_mi_cython\", 0, 1, 3, <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args)); <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "  __pyx_L3_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_fb653f3f00a0b0d040a3af1124789652.joint_to_mi_cython\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return NULL;\n",
       "  __pyx_L4_argument_unpacking_done:;\n",
       "  __pyx_r = __pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_2joint_to_mi_cython(__pyx_self, __pyx_v_joint, __pyx_v_forward_euler_a, __pyx_v_forward_euler_b);\n",
       "  int __pyx_lineno = 0;\n",
       "  const char *__pyx_filename = NULL;\n",
       "  int __pyx_clineno = 0;\n",
       "\n",
       "  /* function exit code */\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static PyObject *__pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_2joint_to_mi_cython(CYTHON_UNUSED PyObject *__pyx_self, __Pyx_memviewslice __pyx_v_joint, float __pyx_v_forward_euler_a, float __pyx_v_forward_euler_b) {\n",
       "  int __pyx_v_i;\n",
       "  int __pyx_v_j;\n",
       "  int __pyx_v_joint_shape0;\n",
       "  int __pyx_v_joint_shape1;\n",
       "  float *__pyx_v_log_a_marginal;\n",
       "  float *__pyx_v_log_b_marginal;\n",
       "  float __pyx_v_temp_sum;\n",
       "  CYTHON_UNUSED float __pyx_v_log_temp_sum;\n",
       "  float __pyx_v_log_forward_euler_a;\n",
       "  float __pyx_v_log_forward_euler_b;\n",
       "  float __pyx_v_log_joint;\n",
       "  float __pyx_v_output;\n",
       "  PyObject *__pyx_r = NULL;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"__pyx_fuse_0joint_to_mi_cython\", 0);\n",
       "/* … */\n",
       "  /* function exit code */\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_15);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_fb653f3f00a0b0d040a3af1124789652.joint_to_mi_cython\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = NULL;\n",
       "  __pyx_L0:;\n",
       "  __PYX_XDEC_MEMVIEW(&amp;__pyx_v_joint, 1);\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static PyObject *__pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_14__defaults__(CYTHON_UNUSED PyObject *__pyx_self) {\n",
       "  PyObject *__pyx_r = NULL;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"__defaults__\", 0);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "  __pyx_t_1 = <span class='py_c_api'>PyFloat_FromDouble</span>(<span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults3, __pyx_self)-&gt;__pyx_arg_forward_euler_a);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  __pyx_t_2 = <span class='py_c_api'>PyFloat_FromDouble</span>(<span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults3, __pyx_self)-&gt;__pyx_arg_forward_euler_b);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = <span class='py_c_api'>PyTuple_New</span>(2);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_1);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 0, __pyx_t_1);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_2);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 1, __pyx_t_2);\n",
       "  __pyx_t_1 = 0;\n",
       "  __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = <span class='py_c_api'>PyTuple_New</span>(2);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_3);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_2, 0, __pyx_t_3);\n",
       "  <span class='pyx_macro_api'>__Pyx_INCREF</span>(Py_None);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(Py_None);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_2, 1, Py_None);\n",
       "  __pyx_t_3 = 0;\n",
       "  __pyx_r = __pyx_t_2;\n",
       "  __pyx_t_2 = 0;\n",
       "  goto __pyx_L0;\n",
       "\n",
       "  /* function exit code */\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_2);\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_3);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_fb653f3f00a0b0d040a3af1124789652.__defaults__\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = NULL;\n",
       "  __pyx_L0:;\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "/* Python wrapper */\n",
       "static PyObject *__pyx_fuse_1__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_5joint_to_mi_cython(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/\n",
       "static PyMethodDef __pyx_fuse_1__pyx_mdef_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_5joint_to_mi_cython = {\"__pyx_fuse_1joint_to_mi_cython\", (PyCFunction)(void*)(PyCFunctionWithKeywords)__pyx_fuse_1__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_5joint_to_mi_cython, METH_VARARGS|METH_KEYWORDS, 0};\n",
       "static PyObject *__pyx_fuse_1__pyx_pw_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_5joint_to_mi_cython(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {\n",
       "  __Pyx_memviewslice __pyx_v_joint = { 0, 0, { 0 }, { 0 }, { 0 } };\n",
       "  double __pyx_v_forward_euler_a;\n",
       "  double __pyx_v_forward_euler_b;\n",
       "  PyObject *__pyx_r = 0;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"joint_to_mi_cython (wrapper)\", 0);\n",
       "  {\n",
       "    static PyObject **__pyx_pyargnames[] = {&amp;__pyx_n_s_joint,&amp;__pyx_n_s_forward_euler_a,&amp;__pyx_n_s_forward_euler_b,0};\n",
       "    PyObject* values[3] = {0,0,0};\n",
       "    __pyx_defaults3 *__pyx_dynamic_args = <span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults3, __pyx_self);\n",
       "    if (unlikely(__pyx_kwds)) {\n",
       "      Py_ssize_t kw_args;\n",
       "      const Py_ssize_t pos_args = <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args);\n",
       "      switch (pos_args) {\n",
       "        case  3: values[2] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 2);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2: values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1: values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  0: break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "      kw_args = <span class='py_c_api'>PyDict_Size</span>(__pyx_kwds);\n",
       "      switch (pos_args) {\n",
       "        case  0:\n",
       "        if (likely((values[0] = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_joint)) != 0)) kw_args--;\n",
       "        else goto __pyx_L5_argtuple_error;\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1:\n",
       "        if (kw_args &gt; 0) {\n",
       "          PyObject* value = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_forward_euler_a);\n",
       "          if (value) { values[1] = value; kw_args--; }\n",
       "        }\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2:\n",
       "        if (kw_args &gt; 0) {\n",
       "          PyObject* value = <span class='pyx_c_api'>__Pyx_PyDict_GetItemStr</span>(__pyx_kwds, __pyx_n_s_forward_euler_b);\n",
       "          if (value) { values[2] = value; kw_args--; }\n",
       "        }\n",
       "      }\n",
       "      if (unlikely(kw_args &gt; 0)) {\n",
       "        if (unlikely(<span class='pyx_c_api'>__Pyx_ParseOptionalKeywords</span>(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, \"joint_to_mi_cython\") &lt; 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "      }\n",
       "    } else {\n",
       "      switch (<span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args)) {\n",
       "        case  3: values[2] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 2);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  2: values[1] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 1);\n",
       "        CYTHON_FALLTHROUGH;\n",
       "        case  1: values[0] = <span class='py_macro_api'>PyTuple_GET_ITEM</span>(__pyx_args, 0);\n",
       "        break;\n",
       "        default: goto __pyx_L5_argtuple_error;\n",
       "      }\n",
       "    }\n",
       "    __pyx_v_joint = <span class='pyx_c_api'>__Pyx_PyObject_to_MemoryviewSlice_d_dc_double</span>(values[0], PyBUF_WRITABLE);<span class='error_goto'> if (unlikely(!__pyx_v_joint.memview)) __PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "    if (values[1]) {\n",
       "      __pyx_v_forward_euler_a = __pyx_<span class='py_c_api'>PyFloat_AsDouble</span>(values[1]); if (unlikely((__pyx_v_forward_euler_a == (double)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "    } else {\n",
       "      __pyx_v_forward_euler_a = __pyx_dynamic_args-&gt;__pyx_arg_forward_euler_a;\n",
       "    }\n",
       "    if (values[2]) {\n",
       "      __pyx_v_forward_euler_b = __pyx_<span class='py_c_api'>PyFloat_AsDouble</span>(values[2]); if (unlikely((__pyx_v_forward_euler_b == (double)-1) &amp;&amp; <span class='py_c_api'>PyErr_Occurred</span>())) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "    } else {\n",
       "      __pyx_v_forward_euler_b = __pyx_dynamic_args-&gt;__pyx_arg_forward_euler_b;\n",
       "    }\n",
       "  }\n",
       "  goto __pyx_L4_argument_unpacking_done;\n",
       "  __pyx_L5_argtuple_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_RaiseArgtupleInvalid</span>(\"joint_to_mi_cython\", 0, 1, 3, <span class='py_macro_api'>PyTuple_GET_SIZE</span>(__pyx_args)); <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L3_error)</span>\n",
       "  __pyx_L3_error:;\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_fb653f3f00a0b0d040a3af1124789652.joint_to_mi_cython\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return NULL;\n",
       "  __pyx_L4_argument_unpacking_done:;\n",
       "  __pyx_r = __pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_4joint_to_mi_cython(__pyx_self, __pyx_v_joint, __pyx_v_forward_euler_a, __pyx_v_forward_euler_b);\n",
       "  int __pyx_lineno = 0;\n",
       "  const char *__pyx_filename = NULL;\n",
       "  int __pyx_clineno = 0;\n",
       "\n",
       "  /* function exit code */\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "\n",
       "static PyObject *__pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_4joint_to_mi_cython(CYTHON_UNUSED PyObject *__pyx_self, __Pyx_memviewslice __pyx_v_joint, double __pyx_v_forward_euler_a, double __pyx_v_forward_euler_b) {\n",
       "  int __pyx_v_i;\n",
       "  int __pyx_v_j;\n",
       "  int __pyx_v_joint_shape0;\n",
       "  int __pyx_v_joint_shape1;\n",
       "  double *__pyx_v_log_a_marginal;\n",
       "  double *__pyx_v_log_b_marginal;\n",
       "  double __pyx_v_temp_sum;\n",
       "  CYTHON_UNUSED double __pyx_v_log_temp_sum;\n",
       "  double __pyx_v_log_forward_euler_a;\n",
       "  double __pyx_v_log_forward_euler_b;\n",
       "  double __pyx_v_log_joint;\n",
       "  double __pyx_v_output;\n",
       "  PyObject *__pyx_r = NULL;\n",
       "  <span class='refnanny'>__Pyx_RefNannyDeclarations</span>\n",
       "  <span class='refnanny'>__Pyx_RefNannySetupContext</span>(\"__pyx_fuse_1joint_to_mi_cython\", 0);\n",
       "/* … */\n",
       "  /* function exit code */\n",
       "  __pyx_L1_error:;\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_t_15);\n",
       "  <span class='pyx_c_api'>__Pyx_AddTraceback</span>(\"_cython_magic_fb653f3f00a0b0d040a3af1124789652.joint_to_mi_cython\", __pyx_clineno, __pyx_lineno, __pyx_filename);\n",
       "  __pyx_r = NULL;\n",
       "  __pyx_L0:;\n",
       "  __PYX_XDEC_MEMVIEW(&amp;__pyx_v_joint, 1);\n",
       "  <span class='refnanny'>__Pyx_XGIVEREF</span>(__pyx_r);\n",
       "  <span class='refnanny'>__Pyx_RefNannyFinishContext</span>();\n",
       "  return __pyx_r;\n",
       "}\n",
       "  __pyx_tuple__7 = <span class='py_c_api'>PyTuple_Pack</span>(1, __pyx_kp_s_Function_call_with_ambiguous_arg);<span class='error_goto'> if (unlikely(!__pyx_tuple__7)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple__7);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple__7);\n",
       "/* … */\n",
       "  __pyx_t_1 = <span class='py_c_api'>PyFloat_FromDouble</span>(1.);<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  __pyx_t_2 = <span class='py_c_api'>PyFloat_FromDouble</span>(1.);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_3 = <span class='py_c_api'>PyTuple_New</span>(2);<span class='error_goto'> if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_3);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_1);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 0, __pyx_t_1);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_2);\n",
       "  <span class='py_macro_api'>PyTuple_SET_ITEM</span>(__pyx_t_3, 1, __pyx_t_2);\n",
       "  __pyx_t_1 = 0;\n",
       "  __pyx_t_2 = 0;\n",
       "/* … */\n",
       "  __pyx_tuple__27 = <span class='py_c_api'>PyTuple_Pack</span>(15, __pyx_n_s_joint, __pyx_n_s_forward_euler_a, __pyx_n_s_forward_euler_b, __pyx_n_s_i, __pyx_n_s_j, __pyx_n_s_joint_shape0, __pyx_n_s_joint_shape1, __pyx_n_s_log_a_marginal, __pyx_n_s_log_b_marginal, __pyx_n_s_temp_sum, __pyx_n_s_log_temp_sum, __pyx_n_s_log_forward_euler_a, __pyx_n_s_log_forward_euler_b, __pyx_n_s_log_joint, __pyx_n_s_output);<span class='error_goto'> if (unlikely(!__pyx_tuple__27)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_tuple__27);\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_tuple__27);\n",
       "  __pyx_t_2 = <span class='py_c_api'>PyFloat_FromDouble</span>(1.);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_k_ = __pyx_t_2;\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_2);\n",
       "  __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = <span class='py_c_api'>PyFloat_FromDouble</span>(1.);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_k__2 = __pyx_t_2;\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_2);\n",
       "  __pyx_t_2 = 0;\n",
       "  __pyx_t_2 = <span class='pyx_c_api'>__Pyx_PyDict_NewPresized</span>(2);<span class='error_goto'> if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_2);\n",
       "  __pyx_t_1 = __pyx_FusedFunction_New(&amp;__pyx_fuse_0__pyx_mdef_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_3joint_to_mi_cython, 0, __pyx_n_s_joint_to_mi_cython, NULL, __pyx_n_s_cython_magic_fb653f3f00a0b0d040, __pyx_d, ((PyObject *)__pyx_codeobj__28));<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  if (!<span class='pyx_c_api'>__Pyx_CyFunction_InitDefaults</span>(__pyx_t_1, sizeof(__pyx_defaults2), 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults2, __pyx_t_1)-&gt;__pyx_arg_forward_euler_a = 1.;\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults2, __pyx_t_1)-&gt;__pyx_arg_forward_euler_b = 1.;\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_SetDefaultsTuple</span>(__pyx_t_1, __pyx_t_3);\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_SetDefaultsGetter</span>(__pyx_t_1, __pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_12__defaults__);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_t_2, __pyx_n_s_float, __pyx_t_1) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "  __pyx_t_1 = __pyx_FusedFunction_New(&amp;__pyx_fuse_1__pyx_mdef_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_5joint_to_mi_cython, 0, __pyx_n_s_joint_to_mi_cython, NULL, __pyx_n_s_cython_magic_fb653f3f00a0b0d040, __pyx_d, ((PyObject *)__pyx_codeobj__28));<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  if (!<span class='pyx_c_api'>__Pyx_CyFunction_InitDefaults</span>(__pyx_t_1, sizeof(__pyx_defaults3), 0)) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults3, __pyx_t_1)-&gt;__pyx_arg_forward_euler_a = 1.;\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_Defaults</span>(__pyx_defaults3, __pyx_t_1)-&gt;__pyx_arg_forward_euler_b = 1.;\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_SetDefaultsTuple</span>(__pyx_t_1, __pyx_t_3);\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_SetDefaultsGetter</span>(__pyx_t_1, __pyx_pf_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_14__defaults__);\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_t_2, __pyx_n_s_double, __pyx_t_1) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "  __pyx_t_1 = __pyx_FusedFunction_New(&amp;__pyx_mdef_46_cython_magic_fb653f3f00a0b0d040a3af1124789652_1joint_to_mi_cython, 0, __pyx_n_s_joint_to_mi_cython, NULL, __pyx_n_s_cython_magic_fb653f3f00a0b0d040, __pyx_d, ((PyObject *)__pyx_codeobj__28));<span class='error_goto'> if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_1);\n",
       "  <span class='pyx_c_api'>__Pyx_CyFunction_SetDefaultsTuple</span>(__pyx_t_1, __pyx_t_3);\n",
       "  ((__pyx_FusedFunctionObject *) __pyx_t_1)-&gt;__signatures__ = __pyx_t_2;\n",
       "  <span class='refnanny'>__Pyx_GIVEREF</span>(__pyx_t_2);\n",
       "  __pyx_t_2 = 0;\n",
       "  if (<span class='py_c_api'>PyDict_SetItem</span>(__pyx_d, __pyx_n_s_joint_to_mi_cython, __pyx_t_1) &lt; 0) <span class='error_goto'>__PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_1); __pyx_t_1 = 0;\n",
       "  <span class='pyx_macro_api'>__Pyx_DECREF</span>(__pyx_t_3); __pyx_t_3 = 0;\n",
       "  __pyx_codeobj__28 = (PyObject*)<span class='pyx_c_api'>__Pyx_PyCode_New</span>(3, 0, 15, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__27, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_Users_alphaito_ipython_cython, __pyx_n_s_joint_to_mi_cython, 12, __pyx_empty_bytes);<span class='error_goto'> if (unlikely(!__pyx_codeobj__28)) __PYX_ERR(0, 12, __pyx_L1_error)</span>\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">13</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">i</span><span class=\"p\">,</span> <span class=\"nf\">j</span></pre>\n",
       "<pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">14</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">joint_shape0</span> <span class=\"o\">=</span> <span class=\"n\">joint</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mf\">0</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_joint_shape0 = (__pyx_v_joint.shape[0]);\n",
       "/* … */\n",
       "  __pyx_v_joint_shape0 = (__pyx_v_joint.shape[0]);\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">15</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">int</span> <span class=\"nf\">joint_shape1</span> <span class=\"o\">=</span> <span class=\"n\">joint</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mf\">1</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_joint_shape1 = (__pyx_v_joint.shape[1]);\n",
       "/* … */\n",
       "  __pyx_v_joint_shape1 = (__pyx_v_joint.shape[1]);\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">16</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">floating_float_double</span> *<span class=\"nf\">log_a_marginal</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">floating_float_double</span><span class=\"o\">*&gt;</span><span class=\"n\">calloc</span><span class=\"p\">(</span><span class=\"n\">joint_shape0</span><span class=\"p\">,</span> <span class=\"n\">sizeof</span><span class=\"p\">(</span><span class=\"n\">floating_float_double</span><span class=\"p\">))</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_log_a_marginal = ((float *)calloc(__pyx_v_joint_shape0, (sizeof(float))));\n",
       "/* … */\n",
       "  __pyx_v_log_a_marginal = ((double *)calloc(__pyx_v_joint_shape0, (sizeof(double))));\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">17</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">floating_float_double</span> *<span class=\"nf\">log_b_marginal</span> <span class=\"o\">=</span> <span class=\"o\">&lt;</span><span class=\"n\">floating_float_double</span><span class=\"o\">*&gt;</span><span class=\"n\">calloc</span><span class=\"p\">(</span><span class=\"n\">joint_shape1</span><span class=\"p\">,</span> <span class=\"n\">sizeof</span><span class=\"p\">(</span><span class=\"n\">floating_float_double</span><span class=\"p\">))</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_log_b_marginal = ((float *)calloc(__pyx_v_joint_shape1, (sizeof(float))));\n",
       "/* … */\n",
       "  __pyx_v_log_b_marginal = ((double *)calloc(__pyx_v_joint_shape1, (sizeof(double))));\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">18</span>:     <span class=\"k\">cdef</span> <span class=\"kt\">floating_float_double</span> <span class=\"nf\">temp_sum</span><span class=\"p\">,</span> <span class=\"nf\">log_temp_sum</span><span class=\"p\">,</span> <span class=\"nf\">log_forward_euler_a</span><span class=\"p\">,</span> <span class=\"nf\">log_forward_euler_b</span><span class=\"p\">,</span> <span class=\"nf\">log_joint</span><span class=\"p\">,</span> <span class=\"nf\">output</span></pre>\n",
       "<pre class=\"cython line score-0\">&#xA0;<span class=\"\">19</span>: </pre>\n",
       "<pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">20</span>:     <span class=\"n\">temp_sum</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_temp_sum = 0.0;\n",
       "/* … */\n",
       "  __pyx_v_temp_sum = 0.0;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">21</span>:     <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">joint_shape0</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_t_1 = __pyx_v_joint_shape0;\n",
       "  __pyx_t_2 = __pyx_t_1;\n",
       "  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {\n",
       "    __pyx_v_i = __pyx_t_3;\n",
       "/* … */\n",
       "  __pyx_t_1 = __pyx_v_joint_shape0;\n",
       "  __pyx_t_2 = __pyx_t_1;\n",
       "  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {\n",
       "    __pyx_v_i = __pyx_t_3;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">22</span>:         <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">joint_shape1</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>    __pyx_t_4 = __pyx_v_joint_shape1;\n",
       "    __pyx_t_5 = __pyx_t_4;\n",
       "    for (__pyx_t_6 = 0; __pyx_t_6 &lt; __pyx_t_5; __pyx_t_6+=1) {\n",
       "      __pyx_v_j = __pyx_t_6;\n",
       "/* … */\n",
       "    __pyx_t_4 = __pyx_v_joint_shape1;\n",
       "    __pyx_t_5 = __pyx_t_4;\n",
       "    for (__pyx_t_6 = 0; __pyx_t_6 &lt; __pyx_t_5; __pyx_t_6+=1) {\n",
       "      __pyx_v_j = __pyx_t_6;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">23</span>:             <span class=\"n\">log_a_marginal</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">joint</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>      __pyx_t_7 = __pyx_v_i;\n",
       "      __pyx_t_8 = __pyx_v_i;\n",
       "      __pyx_t_9 = __pyx_v_j;\n",
       "      (__pyx_v_log_a_marginal[__pyx_t_7]) = ((__pyx_v_log_a_marginal[__pyx_t_7]) + (*((float *) ( /* dim=1 */ ((char *) (((float *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_8 * __pyx_v_joint.strides[0]) )) + __pyx_t_9)) ))));\n",
       "/* … */\n",
       "      __pyx_t_7 = __pyx_v_i;\n",
       "      __pyx_t_8 = __pyx_v_i;\n",
       "      __pyx_t_9 = __pyx_v_j;\n",
       "      (__pyx_v_log_a_marginal[__pyx_t_7]) = ((__pyx_v_log_a_marginal[__pyx_t_7]) + (*((double *) ( /* dim=1 */ ((char *) (((double *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_8 * __pyx_v_joint.strides[0]) )) + __pyx_t_9)) ))));\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">24</span>:             <span class=\"n\">log_b_marginal</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">+=</span> <span class=\"n\">joint</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>      __pyx_t_7 = __pyx_v_j;\n",
       "      __pyx_t_9 = __pyx_v_i;\n",
       "      __pyx_t_8 = __pyx_v_j;\n",
       "      (__pyx_v_log_b_marginal[__pyx_t_7]) = ((__pyx_v_log_b_marginal[__pyx_t_7]) + (*((float *) ( /* dim=1 */ ((char *) (((float *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_9 * __pyx_v_joint.strides[0]) )) + __pyx_t_8)) ))));\n",
       "    }\n",
       "/* … */\n",
       "      __pyx_t_7 = __pyx_v_j;\n",
       "      __pyx_t_9 = __pyx_v_i;\n",
       "      __pyx_t_8 = __pyx_v_j;\n",
       "      (__pyx_v_log_b_marginal[__pyx_t_7]) = ((__pyx_v_log_b_marginal[__pyx_t_7]) + (*((double *) ( /* dim=1 */ ((char *) (((double *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_9 * __pyx_v_joint.strides[0]) )) + __pyx_t_8)) ))));\n",
       "    }\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">25</span>:         <span class=\"n\">temp_sum</span> <span class=\"o\">+=</span> <span class=\"n\">log_a_marginal</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span></pre>\n",
       "<pre class='cython code score-0 '>    __pyx_v_temp_sum = (__pyx_v_temp_sum + (__pyx_v_log_a_marginal[__pyx_v_i]));\n",
       "  }\n",
       "/* … */\n",
       "    __pyx_v_temp_sum = (__pyx_v_temp_sum + (__pyx_v_log_a_marginal[__pyx_v_i]));\n",
       "  }\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">26</span>:     <span class=\"n\">temp_sum</span> <span class=\"o\">*=</span> <span class=\"n\">forward_euler_a</span> <span class=\"o\">*</span> <span class=\"n\">forward_euler_b</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_temp_sum = (__pyx_v_temp_sum * (__pyx_v_forward_euler_a * __pyx_v_forward_euler_b));\n",
       "/* … */\n",
       "  __pyx_v_temp_sum = (__pyx_v_temp_sum * (__pyx_v_forward_euler_a * __pyx_v_forward_euler_b));\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">27</span>:     <span class=\"n\">log_temp_sum</span> <span class=\"o\">=</span> <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">temp_sum</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_log_temp_sum = log(__pyx_v_temp_sum);\n",
       "/* … */\n",
       "  __pyx_v_log_temp_sum = log(__pyx_v_temp_sum);\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">28</span>:     <span class=\"n\">log_forward_euler_a</span> <span class=\"o\">=</span> <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">forward_euler_a</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_log_forward_euler_a = log(__pyx_v_forward_euler_a);\n",
       "/* … */\n",
       "  __pyx_v_log_forward_euler_a = log(__pyx_v_forward_euler_a);\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">29</span>:     <span class=\"n\">log_forward_euler_b</span> <span class=\"o\">=</span> <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">forward_euler_b</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_log_forward_euler_b = log(__pyx_v_forward_euler_b);\n",
       "/* … */\n",
       "  __pyx_v_log_forward_euler_b = log(__pyx_v_forward_euler_b);\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">30</span>: </pre>\n",
       "<pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">31</span>:     <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">joint_shape0</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_t_1 = __pyx_v_joint_shape0;\n",
       "  __pyx_t_2 = __pyx_t_1;\n",
       "  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {\n",
       "    __pyx_v_i = __pyx_t_3;\n",
       "/* … */\n",
       "  __pyx_t_1 = __pyx_v_joint_shape0;\n",
       "  __pyx_t_2 = __pyx_t_1;\n",
       "  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {\n",
       "    __pyx_v_i = __pyx_t_3;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">32</span>:         <span class=\"n\">log_a_marginal</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">log_a_marginal</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"o\">+</span> <span class=\"n\">log_forward_euler_b</span> <span class=\"k\">if</span> <span class=\"n\">isfinite</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">log_a_marginal</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]))</span> <span class=\"k\">else</span> <span class=\"mf\">0.0</span></pre>\n",
       "<pre class='cython code score-0 '>    if ((isfinite(log((__pyx_v_log_a_marginal[__pyx_v_i]))) != 0)) {\n",
       "      __pyx_t_10 = (log((__pyx_v_log_a_marginal[__pyx_v_i])) + __pyx_v_log_forward_euler_b);\n",
       "    } else {\n",
       "      __pyx_t_10 = 0.0;\n",
       "    }\n",
       "    (__pyx_v_log_a_marginal[__pyx_v_i]) = __pyx_t_10;\n",
       "  }\n",
       "/* … */\n",
       "    if ((isfinite(log((__pyx_v_log_a_marginal[__pyx_v_i]))) != 0)) {\n",
       "      __pyx_t_10 = (log((__pyx_v_log_a_marginal[__pyx_v_i])) + __pyx_v_log_forward_euler_b);\n",
       "    } else {\n",
       "      __pyx_t_10 = 0.0;\n",
       "    }\n",
       "    (__pyx_v_log_a_marginal[__pyx_v_i]) = __pyx_t_10;\n",
       "  }\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">33</span>:     <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">joint_shape1</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_t_1 = __pyx_v_joint_shape1;\n",
       "  __pyx_t_2 = __pyx_t_1;\n",
       "  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {\n",
       "    __pyx_v_j = __pyx_t_3;\n",
       "/* … */\n",
       "  __pyx_t_1 = __pyx_v_joint_shape1;\n",
       "  __pyx_t_2 = __pyx_t_1;\n",
       "  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {\n",
       "    __pyx_v_j = __pyx_t_3;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">34</span>:         <span class=\"n\">log_b_marginal</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">log_b_marginal</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">])</span> <span class=\"o\">+</span> <span class=\"n\">log_forward_euler_a</span> <span class=\"k\">if</span> <span class=\"n\">isfinite</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">log_b_marginal</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">]))</span> <span class=\"k\">else</span> <span class=\"mf\">0.0</span></pre>\n",
       "<pre class='cython code score-0 '>    if ((isfinite(log((__pyx_v_log_b_marginal[__pyx_v_j]))) != 0)) {\n",
       "      __pyx_t_10 = (log((__pyx_v_log_b_marginal[__pyx_v_j])) + __pyx_v_log_forward_euler_a);\n",
       "    } else {\n",
       "      __pyx_t_10 = 0.0;\n",
       "    }\n",
       "    (__pyx_v_log_b_marginal[__pyx_v_j]) = __pyx_t_10;\n",
       "  }\n",
       "/* … */\n",
       "    if ((isfinite(log((__pyx_v_log_b_marginal[__pyx_v_j]))) != 0)) {\n",
       "      __pyx_t_10 = (log((__pyx_v_log_b_marginal[__pyx_v_j])) + __pyx_v_log_forward_euler_a);\n",
       "    } else {\n",
       "      __pyx_t_10 = 0.0;\n",
       "    }\n",
       "    (__pyx_v_log_b_marginal[__pyx_v_j]) = __pyx_t_10;\n",
       "  }\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">35</span>: </pre>\n",
       "<pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">36</span>:     <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"mf\">0.0</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_v_output = 0.0;\n",
       "/* … */\n",
       "  __pyx_v_output = 0.0;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">37</span>:     <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">joint_shape0</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_t_1 = __pyx_v_joint_shape0;\n",
       "  __pyx_t_2 = __pyx_t_1;\n",
       "  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {\n",
       "    __pyx_v_i = __pyx_t_3;\n",
       "/* … */\n",
       "  __pyx_t_1 = __pyx_v_joint_shape0;\n",
       "  __pyx_t_2 = __pyx_t_1;\n",
       "  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {\n",
       "    __pyx_v_i = __pyx_t_3;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">38</span>:         <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">joint_shape1</span><span class=\"p\">):</span></pre>\n",
       "<pre class='cython code score-0 '>    __pyx_t_4 = __pyx_v_joint_shape1;\n",
       "    __pyx_t_5 = __pyx_t_4;\n",
       "    for (__pyx_t_6 = 0; __pyx_t_6 &lt; __pyx_t_5; __pyx_t_6+=1) {\n",
       "      __pyx_v_j = __pyx_t_6;\n",
       "/* … */\n",
       "    __pyx_t_4 = __pyx_v_joint_shape1;\n",
       "    __pyx_t_5 = __pyx_t_4;\n",
       "    for (__pyx_t_6 = 0; __pyx_t_6 &lt; __pyx_t_5; __pyx_t_6+=1) {\n",
       "      __pyx_v_j = __pyx_t_6;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">39</span>:             <span class=\"n\">log_joint</span> <span class=\"o\">=</span> <span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">joint</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span> <span class=\"k\">if</span> <span class=\"n\">isfinite</span><span class=\"p\">(</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"n\">joint</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">]))</span> <span class=\"k\">else</span> <span class=\"mf\">0.0</span></pre>\n",
       "<pre class='cython code score-0 '>      __pyx_t_8 = __pyx_v_i;\n",
       "      __pyx_t_9 = __pyx_v_j;\n",
       "      if ((isfinite(log((*((float *) ( /* dim=1 */ ((char *) (((float *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_8 * __pyx_v_joint.strides[0]) )) + __pyx_t_9)) ))))) != 0)) {\n",
       "        __pyx_t_11 = __pyx_v_i;\n",
       "        __pyx_t_12 = __pyx_v_j;\n",
       "        __pyx_t_10 = log((*((float *) ( /* dim=1 */ ((char *) (((float *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_11 * __pyx_v_joint.strides[0]) )) + __pyx_t_12)) ))));\n",
       "      } else {\n",
       "        __pyx_t_10 = 0.0;\n",
       "      }\n",
       "      __pyx_v_log_joint = __pyx_t_10;\n",
       "/* … */\n",
       "      __pyx_t_8 = __pyx_v_i;\n",
       "      __pyx_t_9 = __pyx_v_j;\n",
       "      if ((isfinite(log((*((double *) ( /* dim=1 */ ((char *) (((double *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_8 * __pyx_v_joint.strides[0]) )) + __pyx_t_9)) ))))) != 0)) {\n",
       "        __pyx_t_11 = __pyx_v_i;\n",
       "        __pyx_t_12 = __pyx_v_j;\n",
       "        __pyx_t_10 = log((*((double *) ( /* dim=1 */ ((char *) (((double *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_11 * __pyx_v_joint.strides[0]) )) + __pyx_t_12)) ))));\n",
       "      } else {\n",
       "        __pyx_t_10 = 0.0;\n",
       "      }\n",
       "      __pyx_v_log_joint = __pyx_t_10;\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">40</span>:             <span class=\"n\">output</span> <span class=\"o\">+=</span> <span class=\"n\">joint</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"p\">(</span><span class=\"n\">log_joint</span> <span class=\"o\">-</span> <span class=\"n\">log_a_marginal</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">log_b_marginal</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">])</span> <span class=\"o\">*</span> <span class=\"n\">forward_euler_a</span> <span class=\"o\">*</span> <span class=\"n\">forward_euler_b</span></pre>\n",
       "<pre class='cython code score-0 '>      __pyx_t_9 = __pyx_v_i;\n",
       "      __pyx_t_8 = __pyx_v_j;\n",
       "      __pyx_v_output = (__pyx_v_output + ((((*((float *) ( /* dim=1 */ ((char *) (((float *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_9 * __pyx_v_joint.strides[0]) )) + __pyx_t_8)) ))) * ((__pyx_v_log_joint - (__pyx_v_log_a_marginal[__pyx_v_i])) - (__pyx_v_log_b_marginal[__pyx_v_j]))) * __pyx_v_forward_euler_a) * __pyx_v_forward_euler_b));\n",
       "    }\n",
       "  }\n",
       "/* … */\n",
       "      __pyx_t_9 = __pyx_v_i;\n",
       "      __pyx_t_8 = __pyx_v_j;\n",
       "      __pyx_v_output = (__pyx_v_output + ((((*((double *) ( /* dim=1 */ ((char *) (((double *) ( /* dim=0 */ (__pyx_v_joint.data + __pyx_t_9 * __pyx_v_joint.strides[0]) )) + __pyx_t_8)) ))) * ((__pyx_v_log_joint - (__pyx_v_log_a_marginal[__pyx_v_i])) - (__pyx_v_log_b_marginal[__pyx_v_j]))) * __pyx_v_forward_euler_a) * __pyx_v_forward_euler_b));\n",
       "    }\n",
       "  }\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">41</span>: </pre>\n",
       "<pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">42</span>:     <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"mf\">0.0</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-0 '>  __pyx_t_10 = 0.0;\n",
       "  __pyx_t_13 = __pyx_v_output;\n",
       "  if (((__pyx_t_10 &gt; __pyx_t_13) != 0)) {\n",
       "    __pyx_t_14 = __pyx_t_10;\n",
       "  } else {\n",
       "    __pyx_t_14 = __pyx_t_13;\n",
       "  }\n",
       "  __pyx_v_output = __pyx_t_14;\n",
       "/* … */\n",
       "  __pyx_t_10 = 0.0;\n",
       "  __pyx_t_13 = __pyx_v_output;\n",
       "  if (((__pyx_t_10 &gt; __pyx_t_13) != 0)) {\n",
       "    __pyx_t_14 = __pyx_t_10;\n",
       "  } else {\n",
       "    __pyx_t_14 = __pyx_t_13;\n",
       "  }\n",
       "  __pyx_v_output = __pyx_t_14;\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">43</span>: </pre>\n",
       "<pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">44</span>:     <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">log_a_marginal</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-0 '>  free(__pyx_v_log_a_marginal);\n",
       "/* … */\n",
       "  free(__pyx_v_log_a_marginal);\n",
       "</pre><pre class=\"cython line score-0\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">45</span>:     <span class=\"n\">free</span><span class=\"p\">(</span><span class=\"n\">log_b_marginal</span><span class=\"p\">)</span></pre>\n",
       "<pre class='cython code score-0 '>  free(__pyx_v_log_b_marginal);\n",
       "/* … */\n",
       "  free(__pyx_v_log_b_marginal);\n",
       "</pre><pre class=\"cython line score-0\">&#xA0;<span class=\"\">46</span>: </pre>\n",
       "<pre class=\"cython line score-12\" onclick=\"(function(s){s.display=s.display==='block'?'none':'block'})(this.nextElementSibling.style)\">+<span class=\"\">47</span>:     <span class=\"k\">return</span> <span class=\"n\">output</span></pre>\n",
       "<pre class='cython code score-12 '>  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "  __pyx_t_15 = <span class='py_c_api'>PyFloat_FromDouble</span>(__pyx_v_output);<span class='error_goto'> if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 47, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_15);\n",
       "  __pyx_r = __pyx_t_15;\n",
       "  __pyx_t_15 = 0;\n",
       "  goto __pyx_L0;\n",
       "/* … */\n",
       "  <span class='pyx_macro_api'>__Pyx_XDECREF</span>(__pyx_r);\n",
       "  __pyx_t_15 = <span class='py_c_api'>PyFloat_FromDouble</span>(__pyx_v_output);<span class='error_goto'> if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 47, __pyx_L1_error)</span>\n",
       "  <span class='refnanny'>__Pyx_GOTREF</span>(__pyx_t_15);\n",
       "  __pyx_r = __pyx_t_15;\n",
       "  __pyx_t_15 = 0;\n",
       "  goto __pyx_L0;\n",
       "</pre></div></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cython -a\n",
    "from libc.math cimport log, isfinite\n",
    "from libc.stdlib cimport calloc, free\n",
    "cimport cython\n",
    "from cython cimport floating\n",
    "\n",
    "ctypedef fused floating_float_double:\n",
    "    float\n",
    "    double\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def joint_to_mi_cython(floating_float_double[:, ::1] joint, floating_float_double forward_euler_a=1., floating_float_double forward_euler_b=1.):\n",
    "    cdef int i, j\n",
    "    cdef int joint_shape0 = joint.shape[0]\n",
    "    cdef int joint_shape1 = joint.shape[1]\n",
    "    cdef floating_float_double *log_a_marginal = <floating_float_double*>calloc(joint_shape0, sizeof(floating_float_double))\n",
    "    cdef floating_float_double *log_b_marginal = <floating_float_double*>calloc(joint_shape1, sizeof(floating_float_double))\n",
    "    cdef floating_float_double temp_sum, log_temp_sum, log_forward_euler_a, log_forward_euler_b, log_joint, output\n",
    "    \n",
    "    temp_sum = 0.0\n",
    "    for i in range(joint_shape0):\n",
    "        for j in range(joint_shape1):\n",
    "            log_a_marginal[i] += joint[i, j]\n",
    "            log_b_marginal[j] += joint[i, j]\n",
    "        temp_sum += log_a_marginal[i]\n",
    "    temp_sum *= forward_euler_a * forward_euler_b\n",
    "    log_temp_sum = log(temp_sum)\n",
    "    log_forward_euler_a = log(forward_euler_a)\n",
    "    log_forward_euler_b = log(forward_euler_b)\n",
    "    \n",
    "    for i in range(joint_shape0):\n",
    "        log_a_marginal[i] = log(log_a_marginal[i]) + log_forward_euler_b if isfinite(log(log_a_marginal[i])) else 0.0\n",
    "    for j in range(joint_shape1):\n",
    "        log_b_marginal[j] = log(log_b_marginal[j]) + log_forward_euler_a if isfinite(log(log_b_marginal[j])) else 0.0\n",
    "    \n",
    "    output = 0.0\n",
    "    for i in range(joint_shape0):\n",
    "        for j in range(joint_shape1):\n",
    "            log_joint = log(joint[i, j]) if isfinite(log(joint[i, j])) else 0.0\n",
    "            output += joint[i, j] * (log_joint - log_a_marginal[i] - log_b_marginal[j]) * forward_euler_a * forward_euler_b\n",
    "\n",
    "    output = max(output, 0.0)\n",
    "\n",
    "    free(log_a_marginal)\n",
    "    free(log_b_marginal)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1741add3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:36.728466Z",
     "start_time": "2023-04-16T15:44:36.707553Z"
    }
   },
   "outputs": [],
   "source": [
    "# @_njit(cache=True)\n",
    "def _nan_inf_to_0(x):\n",
    "    \"\"\"\n",
    "    To convert NaN to 0 in nopython mode.\n",
    "    \"\"\"\n",
    "    return _np.where(_np.isfinite(x), x, 0.)\n",
    "\n",
    "\n",
    "# @_njit(cache=True)\n",
    "def _joint_to_mi(joint, forward_euler_a=1., forward_euler_b=1.):\n",
    "    # assume that joint likelihood is of shape (len(a), len(b))\n",
    "    # forward_euler step being 1. means discrete r.v.\n",
    "    # to scale the cdf to 1.\n",
    "    joint /= _np.sum(joint) * forward_euler_a * forward_euler_b\n",
    "    log_a_marginal = _np.log(_np.sum(joint, 1)) + _np.log(forward_euler_b)\n",
    "    log_a_marginal = _nan_inf_to_0(log_a_marginal)\n",
    "    log_b_marginal = _np.log(_np.sum(joint, 0)) + _np.log(forward_euler_a)\n",
    "    log_b_marginal = _nan_inf_to_0(log_b_marginal)\n",
    "    log_joint = _np.log(joint)\n",
    "    log_joint = _nan_inf_to_0(log_joint)\n",
    "    mi_temp = _np.sum(\n",
    "        joint *\n",
    "        (log_joint - log_a_marginal.reshape(-1, 1) -\n",
    "         log_b_marginal.reshape(1, -1))) * forward_euler_a * forward_euler_b\n",
    "\n",
    "    # this is to ensure that estimated MI is positive, to solve an numerical issue\n",
    "    mi_temp = _np.max(_np.array([mi_temp, 0.]))\n",
    "\n",
    "    #     del log_a_marginal, log_b_marginal, log_joint\n",
    "\n",
    "    return mi_temp\n",
    "\n",
    "\n",
    "def MI_continuous_012(a, b, N=500, kernel=\"epa\", bw=\"silverman\", **kwarg):\n",
    "    \"\"\"\n",
    "    calculate mutual information between continuous outcome and an SNP variable of 0,1,2\n",
    "    assume no missing data\n",
    "    \"\"\"\n",
    "    # first estimate the pmf\n",
    "    p0 = _np.count_nonzero(b == 0) / len(b)\n",
    "    p1 = _np.count_nonzero(b == 1) / len(b)\n",
    "    p2 = 1. - p0 - p1\n",
    "    _a = _scaler().fit_transform(a.reshape(-1, 1)).flatten()\n",
    "    # this step is just to get the boundary width for the joint density grid\n",
    "    # the three conditional density estimates need to be evaluated on the joint density grid\n",
    "    a_temp, _ = _FFTKDE(kernel=kernel, bw=bw, **kwarg).fit(data=_a).evaluate(N)\n",
    "    # estimate cond density\n",
    "    _b0 = (b == 0)\n",
    "    if _np.count_nonzero(_b0) > 2:\n",
    "        # here proceed to kde only if there are more than 5 data points\n",
    "        y_cond_p0 = _FFTKDE(kernel=kernel, bw=bw, **kwarg).fit(data=_a[_b0])\n",
    "    else:\n",
    "        y_cond_p0 = _np.zeros_like\n",
    "    _b1 = (b == 1)\n",
    "    if _np.count_nonzero(_b1) > 2:\n",
    "        y_cond_p1 = _FFTKDE(kernel=kernel, bw=bw, **kwarg).fit(data=_a[_b1])\n",
    "    else:\n",
    "        y_cond_p1 = _np.zeros_like\n",
    "    _b2 = (b == 2)\n",
    "    if _np.count_nonzero(_b2) > 2:\n",
    "        y_cond_p2 = _FFTKDE(kernel=kernel, bw=bw, **kwarg).fit(data=_a[_b2])\n",
    "    else:\n",
    "        y_cond_p2 = _np.zeros_like\n",
    "    joint = _np.zeros((N, 3))\n",
    "    joint[:, 0] = y_cond_p0(a_temp) * p0\n",
    "    joint[:, 1] = y_cond_p1(a_temp) * p1\n",
    "    joint[:, 2] = y_cond_p2(a_temp) * p2\n",
    "    forward_euler_step = a_temp[1] - a_temp[0]\n",
    "    mask = joint < 0.\n",
    "    joint[mask] = 0.\n",
    "\n",
    "    #     joint = _np.ascontiguousarray(joint)\n",
    "\n",
    "    mi_temp = joint_to_mi_cython(joint=joint,\n",
    "                                 forward_euler_a=forward_euler_step)\n",
    "\n",
    "    #     del p0, p1, p2, _a, a_temp, _, _b0, y_cond_p0, _b1, y_cond_p1, _b2, y_cond_p2, joint, mask, forward_euler_step\n",
    "\n",
    "    return mi_temp\n",
    "\n",
    "\n",
    "# @_njit(cache=True)\n",
    "def MI_binary_012(a, b):\n",
    "    \"\"\"\n",
    "    calculate mutual information between binary outcome and an SNP variable of 0,1,2\n",
    "    assume no missing data\n",
    "    \"\"\"\n",
    "    return MI_012_012(a, b)\n",
    "\n",
    "\n",
    "# @_njit(cache=True)\n",
    "def MI_012_012(a, b):\n",
    "    \"\"\"\n",
    "    calculate mutual information between two SNPs\n",
    "    assume no missing data\n",
    "    could be very useful for a MI-based clumping\n",
    "    \"\"\"\n",
    "    # estimate the cond pmf\n",
    "    joint = _np.zeros((3, 3))\n",
    "    _b0 = (b == 0)\n",
    "    joint[0, 0] = _np.count_nonzero(_np.logical_and(a == 0, _b0)) / len(a)\n",
    "    joint[1, 0] = _np.count_nonzero(_np.logical_and(a == 1, _b0)) / len(a)\n",
    "    joint[2, 0] = _np.count_nonzero(_np.logical_and(a == 2, _b0)) / len(a)\n",
    "    _b1 = (b == 1)\n",
    "    joint[0, 1] = _np.count_nonzero(_np.logical_and(a == 0, _b1)) / len(a)\n",
    "    joint[1, 1] = _np.count_nonzero(_np.logical_and(a == 1, _b1)) / len(a)\n",
    "    joint[2, 1] = _np.count_nonzero(_np.logical_and(a == 2, _b1)) / len(a)\n",
    "    _b2 = (b == 2)\n",
    "    joint[0, 2] = _np.count_nonzero(_np.logical_and(a == 0, _b2)) / len(a)\n",
    "    joint[1, 2] = _np.count_nonzero(_np.logical_and(a == 1, _b2)) / len(a)\n",
    "    joint[2, 2] = _np.count_nonzero(_np.logical_and(a == 2, _b2)) / len(a)\n",
    "\n",
    "    #     joint = _np.ascontiguousarray(joint)\n",
    "\n",
    "    mi_temp = joint_to_mi_cython(joint=joint)\n",
    "\n",
    "    #     del joint\n",
    "\n",
    "    return mi_temp\n",
    "\n",
    "\n",
    "def MI_continuous_continuous(a,\n",
    "                             b,\n",
    "                             a_N=300,\n",
    "                             b_N=300,\n",
    "                             kernel=\"epa\",\n",
    "                             bw=\"silverman\",\n",
    "                             norm=2,\n",
    "                             **kwarg):\n",
    "    \"\"\"\n",
    "    (Single Core version) calculate mutual information on bivariate continuous r.v..\n",
    "    \"\"\"\n",
    "    _temp = _np.argsort(a)\n",
    "    data = _np.hstack((a[_temp].reshape(-1, 1), b[_temp].reshape(-1, 1)))\n",
    "    _data = _scaler().fit_transform(data)\n",
    "    grid, joint = _FFTKDE(kernel=kernel, norm=norm,\n",
    "                          **kwarg).fit(_data).evaluate((a_N, b_N))\n",
    "    joint = joint.reshape(b_N, -1).T\n",
    "    # this gives joint as a (a_N, b_N) array, following example: https://kdepy.readthedocs.io/en/latest/examples.html#the-effect-of-norms-in-2d\n",
    "    a_forward_euler_step = grid[b_N, 0] - grid[0, 0]\n",
    "    b_forward_euler_step = grid[1, 1] - grid[0, 1]\n",
    "    mask = joint < 0.\n",
    "    joint[mask] = 0.\n",
    "\n",
    "    #     joint = _np.ascontiguousarray(joint)\n",
    "\n",
    "    mi_temp = joint_to_mi_cython(joint=joint,\n",
    "                                 forward_euler_a=a_forward_euler_step,\n",
    "                                 forward_euler_b=b_forward_euler_step)\n",
    "\n",
    "    #     del _temp, data, _data, grid, joint, mask, a_forward_euler_step, b_forward_euler_step\n",
    "\n",
    "    return mi_temp\n",
    "\n",
    "\n",
    "def MI_binary_continuous(a, b, N=500, kernel=\"epa\", bw=\"silverman\", **kwarg):\n",
    "    return MI_continuous_012(a=b, b=a, N=N, kernel=kernel, bw=bw, **kwarg)\n",
    "\n",
    "\n",
    "@_njit(cache=True)\n",
    "def Pearson_to_MI_Gaussian(corr):\n",
    "    \"\"\"\n",
    "    Assuming the input variables are bivariate Gaussian, convert their Pearson correlatin to mutual information.\n",
    "    \"\"\"\n",
    "    return -.5 * (_np.log(1 + corr) + _np.log(1 - corr))\n",
    "\n",
    "\n",
    "@_njit(cache=True)\n",
    "def MI_to_Linfoot(mi):\n",
    "    \"\"\"\n",
    "    Convert calcualted mutual information estimator to Linfoot's measure of association.\n",
    "    \"\"\"\n",
    "    return (1. - _np.exp(-2. * mi))**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec539665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.212493Z",
     "start_time": "2023-04-16T15:44:36.729361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 ms ± 51.3 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "255 ms ± 4.15 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cython is faster than Python implementation, even in our case of massive vectorization\n",
    "a, b = _np.random.rand(10000), _np.random.rand(3000)\n",
    "joint = a * b.reshape(-1, 1)\n",
    "%timeit joint_to_mi_cython(joint)\n",
    "%timeit _joint_to_mi(joint)\n",
    "\n",
    "joint_to_mi_cython(joint) == _joint_to_mi(joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd816b0e",
   "metadata": {},
   "source": [
    "# For `plink` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce8b66d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.313022Z",
     "start_time": "2023-04-16T15:44:49.213442Z"
    }
   },
   "outputs": [],
   "source": [
    "# outcome_iid should be a  list of strings for identifiers\n",
    "def continuous_screening_plink(bed_file,\n",
    "                               bim_file,\n",
    "                               fam_file,\n",
    "                               outcome,\n",
    "                               outcome_iid,\n",
    "                               N=500,\n",
    "                               kernel=\"epa\",\n",
    "                               bw=\"silverman\",\n",
    "                               verbose=1,\n",
    "                               **kwarg):\n",
    "    \"\"\"\n",
    "    (Single Core version) take plink files to calculate the mutual information between the continuous outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    gene_iid = _np.array(list(bed1.iid))\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    outcome = outcome[_np.intersect1d(outcome_iid,\n",
    "                                      gene_iid,\n",
    "                                      assume_unique=True,\n",
    "                                      return_indices=True)[1]]\n",
    "\n",
    "    # get genetic indices\n",
    "    gene_ind = _np.intersect1d(gene_iid,\n",
    "                               outcome_iid,\n",
    "                               assume_unique=True,\n",
    "                               return_indices=True)[1]\n",
    "\n",
    "    def _map_foo(j):\n",
    "        _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "        _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "        _outcome = outcome[_SNP != -127]  # remove missing SNP in outcome\n",
    "        _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "        return MI_continuous_012(a=_outcome,\n",
    "                                 b=_SNP,\n",
    "                                 N=N,\n",
    "                                 kernel=kernel,\n",
    "                                 bw=bw,\n",
    "                                 **kwarg)\n",
    "\n",
    "    _iter = range(len(bed1_sid))\n",
    "    if verbose > 1:\n",
    "        _iter = _tqdm(iter)\n",
    "    MI_UKBB = _np.array(list(map(_map_foo, _iter)))\n",
    "    return MI_UKBB\n",
    "\n",
    "\n",
    "def binary_screening_plink(bed_file,\n",
    "                           bim_file,\n",
    "                           fam_file,\n",
    "                           outcome,\n",
    "                           outcome_iid,\n",
    "                           verbose=1,\n",
    "                           **kwarg):\n",
    "    \"\"\"\n",
    "    (Single Core version) take plink files to calculate the mutual information between the binary outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    gene_iid = _np.array(list(bed1.iid))\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    outcome = outcome[_np.intersect1d(outcome_iid,\n",
    "                                      gene_iid,\n",
    "                                      assume_unique=True,\n",
    "                                      return_indices=True)[1]]\n",
    "    # get genetic indices\n",
    "    gene_ind = _np.intersect1d(gene_iid,\n",
    "                               outcome_iid,\n",
    "                               assume_unique=True,\n",
    "                               return_indices=True)[1]\n",
    "\n",
    "    def _map_foo(j):\n",
    "        _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "        _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "        _outcome = outcome[_SNP != -127]  # remove missing SNP in outcome\n",
    "        _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "        return MI_binary_012(a=_outcome, b=_SNP, **kwarg)\n",
    "\n",
    "    _iter = range(len(bed1_sid))\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    MI_UKBB = _np.array(list(map(_map_foo, _iter)))\n",
    "    return MI_UKBB\n",
    "\n",
    "\n",
    "def continuous_screening_plink_parallel(bed_file,\n",
    "                                        bim_file,\n",
    "                                        fam_file,\n",
    "                                        outcome,\n",
    "                                        outcome_iid,\n",
    "                                        N=500,\n",
    "                                        kernel=\"epa\",\n",
    "                                        bw=\"silverman\",\n",
    "                                        core_num=\"NOT DECLARED\",\n",
    "                                        multp=10,\n",
    "                                        verbose=1,\n",
    "                                        **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) take plink files to calculate the mutual information between the continuous outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    # read some metadata\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    gene_iid = _np.array(list(bed1.iid))\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    outcome = outcome[_np.intersect1d(outcome_iid,\n",
    "                                      gene_iid,\n",
    "                                      assume_unique=True,\n",
    "                                      return_indices=True)[1]]\n",
    "    # get genetic indices\n",
    "    gene_ind = _np.intersect1d(gene_iid,\n",
    "                               outcome_iid,\n",
    "                               assume_unique=True,\n",
    "                               return_indices=True)[1]\n",
    "\n",
    "    def _continuous_screening_plink_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "            _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "            _outcome = outcome[_SNP != -127]  # remove missing SNP in outcome\n",
    "            _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "            return MI_continuous_012(a=_outcome,\n",
    "                                     b=_SNP,\n",
    "                                     N=N,\n",
    "                                     kernel=kernel,\n",
    "                                     bw=bw,\n",
    "                                     **kwarg)\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(len(bed1_sid))\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_UKBB = pl.map(_continuous_screening_plink_slice, _iter)\n",
    "    MI_UKBB = _np.hstack(MI_UKBB)\n",
    "    return MI_UKBB\n",
    "\n",
    "\n",
    "def binary_screening_plink_parallel(bed_file,\n",
    "                                    bim_file,\n",
    "                                    fam_file,\n",
    "                                    outcome,\n",
    "                                    outcome_iid,\n",
    "                                    core_num=\"NOT DECLARED\",\n",
    "                                    multp=10,\n",
    "                                    verbose=1,\n",
    "                                    **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) take plink files to calculate the mutual information between the binary outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    # check basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    # read some metadata\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    gene_iid = _np.array(list(bed1.iid))\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    outcome = outcome[_np.intersect1d(outcome_iid,\n",
    "                                      gene_iid,\n",
    "                                      assume_unique=True,\n",
    "                                      return_indices=True)[1]]\n",
    "    # get genetic indices\n",
    "    gene_ind = _np.intersect1d(gene_iid,\n",
    "                               outcome_iid,\n",
    "                               assume_unique=True,\n",
    "                               return_indices=True)[1]\n",
    "\n",
    "    def _binary_screening_plink_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "            _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "            _outcome = outcome[_SNP != -127]  # remove missing SNP in outcome\n",
    "            _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "            return MI_binary_012(a=_outcome, b=_SNP, **kwarg)\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(len(bed1_sid))\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose > 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_UKBB = pl.map(_binary_screening_plink_slice, _iter)\n",
    "    MI_UKBB = _np.hstack(MI_UKBB)\n",
    "    return MI_UKBB\n",
    "\n",
    "\n",
    "def clump_plink_parallel(bed_file,\n",
    "                         bim_file,\n",
    "                         fam_file,\n",
    "                         clumping_threshold=Pearson_to_MI_Gaussian(.6),\n",
    "                         num_SNPS_exam=_np.infty,\n",
    "                         core_num=\"NOT DECLARED\",\n",
    "                         multp=10,\n",
    "                         verbose=1):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) take plink files to calculate the mutual information between the binary outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    # check basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    # read some metadata\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    if num_SNPS_exam == _np.infty:\n",
    "        num_SNPS_exam = len(bed1_sid) - 1\n",
    "    keep_cols = _np.arange(\n",
    "        len(bed1_sid))  # pruning by keeping all SNPS at the beginning\n",
    "    _iter = _np.arange(num_SNPS_exam)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    for current_var_ind in _iter:  # note that here _iter and keep_cols don't need to agree, by the break command comes later\n",
    "        if current_var_ind + 1 <= len(keep_cols):\n",
    "            outcome = bed1.read(_np.s_[:, current_var_ind],\n",
    "                                dtype=_np.int8).flatten()\n",
    "            gene_ind = _np.where(outcome != -127)\n",
    "            outcome = outcome[gene_ind]\n",
    "\n",
    "            def _012_012_plink_slice(_slice):\n",
    "                def _map_foo(j):\n",
    "                    _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "                    _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "                    _outcome = outcome[_SNP !=\n",
    "                                       -127]  # remove missing SNP in outcome\n",
    "                    _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "                    return MI_012_012(a=_outcome, b=_SNP)\n",
    "\n",
    "                _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "                return _MI_slice\n",
    "\n",
    "            # multiprocessing starts here\n",
    "            ind = keep_cols[current_var_ind + 1:]\n",
    "            __iter = _np.array_split(ind, core_num * multp)\n",
    "            with _mp.Pool(core_num) as pl:\n",
    "                MI_UKBB = pl.map(_012_012_plink_slice, __iter)\n",
    "            MI_UKBB = _np.hstack(MI_UKBB)\n",
    "            keep_cols = _np.hstack(\n",
    "                (keep_cols[:current_var_ind + 1],\n",
    "                 keep_cols[current_var_ind +\n",
    "                           1:][MI_UKBB <= clumping_threshold]))\n",
    "        else:\n",
    "            break\n",
    "    return current_var_ind, bed1_sid[keep_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508b94e",
   "metadata": {},
   "source": [
    "# For `csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51fcb92a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.385417Z",
     "start_time": "2023-04-16T15:44:49.314064Z"
    }
   },
   "outputs": [],
   "source": [
    "def _read_csv(csv_file, _usecols, csv_engine, parquet_file, sample, verbose=1):\n",
    "    \"\"\"\n",
    "    Read a csv file using differnet engines. Use dask to read csv if low in memory.\n",
    "    \"\"\"\n",
    "    assert csv_engine in [\n",
    "        \"dask\", \"pyarrow\", \"fastparquet\", \"c\", \"python\"\n",
    "    ], \"Only dask and pandas csv engines or fastparquet are supported to read csv files.\"\n",
    "    if _np.array(_usecols).size == 0:\n",
    "        if verbose > 1:\n",
    "            print(\n",
    "                \"Variable names not provided -- start reading variable names from csv file now, might take some time, depending on the csv file size.\"\n",
    "            )\n",
    "        if csv_engine == \"dask\":\n",
    "            _df = _dd.read_csv(csv_file, sample=sample)\n",
    "            _usecols = _np.array(list(_df.columns)[1:])\n",
    "        elif csv_engine in [\"pyarrow\", \"c\",\n",
    "                            \"python\"]:  # these are pandas CSV engines\n",
    "            _df = _pd.read_csv(csv_file,\n",
    "                               encoding='unicode_escape',\n",
    "                               engine=csv_engine)\n",
    "            _usecols = _np.array(_df.columns.to_list()[1:])\n",
    "        elif csv_engine == \"fastparquet\":\n",
    "            _df = _pd.read_parquet(parquet_file, engine=\"fastparquet\")\n",
    "            _usecols = _np.array(_df.columns.to_list()[1:])\n",
    "        if verbose > 1:\n",
    "            print(\"Reading variable names from csv file finished.\")\n",
    "    else:\n",
    "        _usecols = _np.array(_usecols)\n",
    "        if csv_engine == \"dask\":\n",
    "            _df = _dd.read_csv(csv_file, names=_usecols, sample=sample)\n",
    "        elif csv_engine in [\"pyarrow\", \"c\", \"python\"]:\n",
    "            _df = _pd.read_csv(csv_file,\n",
    "                               encoding='unicode_escape',\n",
    "                               usecols=_usecols,\n",
    "                               engine=csv_engine)\n",
    "        elif csv_engine == \"fastparquet\":\n",
    "            _df = _pd.read_parquet(parquet_file,\n",
    "                                   engine=\"fastparquet\")[_usecols]\n",
    "    return _df, _usecols\n",
    "\n",
    "\n",
    "def _read_two_columns(_df, __, csv_engine):\n",
    "    \"\"\"\n",
    "    Read two columns from a dataframe object, remove NaN. Use dask to read csv if low in memory.\n",
    "    \"\"\"\n",
    "    if csv_engine == \"dask\":\n",
    "        _ = _np.asarray(_df[__].dropna().compute())\n",
    "    elif csv_engine in [\"pyarrow\", \"c\", \"python\",\n",
    "                        \"fastparquet\"]:  # these are engines using pandas\n",
    "        _ = _df[__].dropna().to_numpy()\n",
    "\n",
    "    _a = _[:, 0]\n",
    "    _b = _[:, 1]\n",
    "    return _a, _b\n",
    "\n",
    "\n",
    "def binary_screening_csv(csv_file=\"_\",\n",
    "                         _usecols=[],\n",
    "                         N=500,\n",
    "                         kernel=\"epa\",\n",
    "                         bw=\"silverman\",\n",
    "                         csv_engine=\"c\",\n",
    "                         parquet_file=\"_\",\n",
    "                         sample=256000,\n",
    "                         verbose=1,\n",
    "                         **kwarg):\n",
    "    \"\"\"\n",
    "    Take a (potentionally large) csv file to calculate the mutual information between outcome and covariates.\n",
    "    The outcome should be binary and the covariates be continuous. \n",
    "    If _usecols is given, the returned mutual information will match _usecols. \n",
    "    By default, the left first covariate should be the outcome -- use _usecols to adjust if not the case.\n",
    "    \"\"\"\n",
    "    assert csv_file != \"_\" or parquet_file != \"_\", \"CSV or parquet filepath should be declared\"\n",
    "    # outcome is the first variable by default; if other specifications are needed, put it the first item in _usecols\n",
    "    # read csv\n",
    "    _df, _usecols = _read_csv(csv_file=csv_file,\n",
    "                              _usecols=_usecols,\n",
    "                              csv_engine=csv_engine,\n",
    "                              parquet_file=parquet_file,\n",
    "                              sample=sample,\n",
    "                              verbose=verbose)\n",
    "\n",
    "    def _map_foo(j):\n",
    "        __ = [\n",
    "            _usecols[0], _usecols[j + 1]\n",
    "        ]  # here using _usecol[j + 1] because the left first column is the outcome\n",
    "        _a, _b = _read_two_columns(_df=_df, __=__, csv_engine=csv_engine)\n",
    "        return MI_binary_continuous(a=_a,\n",
    "                                    b=_b,\n",
    "                                    N=N,\n",
    "                                    kernel=kernel,\n",
    "                                    bw=bw,\n",
    "                                    **kwarg)\n",
    "\n",
    "    _iter = _np.arange(len(_usecols) - 1)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    MI_df = _np.array(list(map(_map_foo, _iter)))\n",
    "\n",
    "    del _df\n",
    "\n",
    "    return MI_df\n",
    "\n",
    "\n",
    "def continuous_screening_csv(csv_file=\"_\",\n",
    "                             _usecols=[],\n",
    "                             a_N=300,\n",
    "                             b_N=300,\n",
    "                             kernel=\"epa\",\n",
    "                             bw=\"silverman\",\n",
    "                             norm=2,\n",
    "                             csv_engine=\"c\",\n",
    "                             parquet_file=\"_\",\n",
    "                             sample=256000,\n",
    "                             verbose=1,\n",
    "                             **kwarg):\n",
    "    \"\"\"\n",
    "    Take a (potentionally large) csv file to calculate the mutual information between outcome and covariates.\n",
    "    Both the outcome and the covariates should be continuous. \n",
    "    If _usecols is given, the returned mutual information will match _usecols. \n",
    "    By default, the left first covariate should be the outcome -- use _usecols to adjust if not the case.\n",
    "    \"\"\"\n",
    "    assert csv_file != \"_\" or parquet_file != \"_\", \"CSV or parquet filepath should be declared\"\n",
    "    # read csv\n",
    "    _df, _usecols = _read_csv(csv_file=csv_file,\n",
    "                              _usecols=_usecols,\n",
    "                              csv_engine=csv_engine,\n",
    "                              parquet_file=parquet_file,\n",
    "                              sample=sample,\n",
    "                              verbose=verbose)\n",
    "\n",
    "    def _map_foo(j):\n",
    "        __ = [\n",
    "            _usecols[0], _usecols[j + 1]\n",
    "        ]  # here using _usecol[j + 1] because the left first column is the outcome\n",
    "        _a, _b = _read_two_columns(_df=_df, __=__, csv_engine=csv_engine)\n",
    "        return MI_continuous_continuous(a=_a,\n",
    "                                        b=_b,\n",
    "                                        a_N=a_N,\n",
    "                                        b_N=b_N,\n",
    "                                        kernel=kernel,\n",
    "                                        bw=bw,\n",
    "                                        norm=norm,\n",
    "                                        **kwarg)\n",
    "\n",
    "    _iter = _np.arange(len(_usecols) - 1)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    MI_df = _np.array(list(map(_map_foo, _iter)))\n",
    "\n",
    "    del _df\n",
    "\n",
    "    return MI_df\n",
    "\n",
    "\n",
    "def binary_screening_csv_parallel(csv_file=\"_\",\n",
    "                                  _usecols=[],\n",
    "                                  N=500,\n",
    "                                  kernel=\"epa\",\n",
    "                                  bw=\"silverman\",\n",
    "                                  core_num=\"NOT DECLARED\",\n",
    "                                  multp=10,\n",
    "                                  csv_engine=\"c\",\n",
    "                                  parquet_file=\"_\",\n",
    "                                  sample=256000,\n",
    "                                  verbose=1,\n",
    "                                  share_memory=True,\n",
    "                                  **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Take a (potentionally large) csv file to calculate the mutual information between outcome and covariates.\n",
    "    The outcome should be binary and the covariates be continuous. \n",
    "    If _usecols is given, the returned mutual information will match _usecols. \n",
    "    By default, the left first covariate should be the outcome -- use _usecols to adjust if not the case.\n",
    "    share_memory is to indicate whether to share the dataframe in memory to \n",
    "    multiple processes -- if set to False, each process will copy the entire dataframe respectively. However, \n",
    "    to read very large dataframe using dask, this option should usually be turned off.\n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    assert csv_file != \"_\" or parquet_file != \"_\", \"CSV or parquet filepath should be declared\"\n",
    "\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    # read csv\n",
    "    _df, _usecols = _read_csv(csv_file=csv_file,\n",
    "                              _usecols=_usecols,\n",
    "                              csv_engine=csv_engine,\n",
    "                              parquet_file=parquet_file,\n",
    "                              sample=sample,\n",
    "                              verbose=verbose)\n",
    "\n",
    "    # share_memory for multiprocess\n",
    "    if share_memory == True:\n",
    "        # the origingal dataframe is df, store the columns/dtypes pairs\n",
    "        df_dtypes_dict = dict(list(zip(_df.columns, _df.dtypes)))\n",
    "        # declare a shared Array with data from df\n",
    "        mparr = _mp.Array(_ctypes.c_double, _df.values.reshape(-1))\n",
    "        # create a new df based on the shared array\n",
    "        _df = _pd.DataFrame(_np.frombuffer(mparr.get_obj()).reshape(_df.shape),\n",
    "                            columns=_df.columns).astype(df_dtypes_dict)\n",
    "\n",
    "    def _binary_screening_csv_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            __ = [\n",
    "                _usecols[0], _usecols[j]\n",
    "            ]  # here using _usecol[j] because only input variables indices were splitted\n",
    "            _a, _b = _read_two_columns(_df=_df, __=__, csv_engine=csv_engine)\n",
    "            return MI_binary_continuous(a=_a,\n",
    "                                        b=_b,\n",
    "                                        N=N,\n",
    "                                        kernel=kernel,\n",
    "                                        bw=bw,\n",
    "                                        **kwarg)\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "\n",
    "    ind = _np.arange(\n",
    "        1, len(_usecols)\n",
    "    )  # starting from 1 because the first left column should be the outcome\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_df = pl.map(_binary_screening_csv_slice, _iter)\n",
    "    MI_df = _np.hstack(MI_df)\n",
    "\n",
    "    del _df\n",
    "\n",
    "    return MI_df\n",
    "\n",
    "\n",
    "def continuous_screening_csv_parallel(csv_file=\"_\",\n",
    "                                      _usecols=[],\n",
    "                                      a_N=300,\n",
    "                                      b_N=300,\n",
    "                                      kernel=\"epa\",\n",
    "                                      bw=\"silverman\",\n",
    "                                      norm=2,\n",
    "                                      core_num=\"NOT DECLARED\",\n",
    "                                      multp=10,\n",
    "                                      csv_engine=\"c\",\n",
    "                                      parquet_file=\"_\",\n",
    "                                      sample=256000,\n",
    "                                      verbose=1,\n",
    "                                      share_memory=True,\n",
    "                                      **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Take a (potentionally large) csv file to calculate the mutual information between outcome and covariates.\n",
    "    Both the outcome and the covariates should be continuous. \n",
    "    If _usecols is given, the returned mutual information will match _usecols. \n",
    "    By default, the left first covariate should be the outcome -- use _usecols to adjust if not the case.\n",
    "    share_memory is to indicate whether to share the dataframe in memory to \n",
    "    multiple processes -- if set to False, each process will copy the entire dataframe respectively. However, \n",
    "    to read very large dataframe using dask, this option should usually be turned off.\n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    assert csv_file != \"_\" or parquet_file != \"_\", \"CSV or parquet filepath should be declared\"\n",
    "\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    # read csv\n",
    "    _df, _usecols = _read_csv(csv_file=csv_file,\n",
    "                              _usecols=_usecols,\n",
    "                              csv_engine=csv_engine,\n",
    "                              parquet_file=parquet_file,\n",
    "                              sample=sample,\n",
    "                              verbose=verbose)\n",
    "\n",
    "    # share_memory for multiprocess\n",
    "    if share_memory == True:\n",
    "        # the origingal dataframe is df, store the columns/dtypes pairs\n",
    "        df_dtypes_dict = dict(list(zip(_df.columns, _df.dtypes)))\n",
    "        # declare a shared Array with data from df\n",
    "        mparr = _mp.Array(_ctypes.c_double, _df.values.reshape(-1))\n",
    "        # create a new df based on the shared array\n",
    "        _df = _pd.DataFrame(_np.frombuffer(mparr.get_obj()).reshape(_df.shape),\n",
    "                            columns=_df.columns).astype(df_dtypes_dict)\n",
    "\n",
    "    def _continuous_screening_csv_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            __ = [\n",
    "                _usecols[0], _usecols[j]\n",
    "            ]  # here using _usecol[j] because only input variables indices were splitted\n",
    "            _a, _b = _read_two_columns(_df=_df, __=__, csv_engine=csv_engine)\n",
    "            return MI_continuous_continuous(a=_a,\n",
    "                                            b=_b,\n",
    "                                            a_N=a_N,\n",
    "                                            b_N=b_N,\n",
    "                                            kernel=kernel,\n",
    "                                            bw=bw,\n",
    "                                            norm=norm,\n",
    "                                            **kwarg)\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(\n",
    "        1, len(_usecols)\n",
    "    )  # starting from 1 because the first left column should be the outcome\n",
    "\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_df = pl.map(_continuous_screening_csv_slice, _iter)\n",
    "    MI_df = _np.hstack(MI_df)\n",
    "\n",
    "    del _df\n",
    "\n",
    "    return MI_df\n",
    "\n",
    "\n",
    "def binary_skMI_screening_csv_parallel(csv_file=\"_\",\n",
    "                                       _usecols=[],\n",
    "                                       n_neighbors=3,\n",
    "                                       core_num=\"NOT DECLARED\",\n",
    "                                       multp=10,\n",
    "                                       csv_engine=\"c\",\n",
    "                                       parquet_file=\"_\",\n",
    "                                       sample=256000,\n",
    "                                       verbose=1,\n",
    "                                       share_memory=True,\n",
    "                                       **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Take a (potentionally large) csv file to calculate the mutual information between outcome and covariates.\n",
    "    Both the outcome and the covariates should be binary. \n",
    "    If _usecols is given, the returned mutual information will match _usecols. \n",
    "    By default, the left first covariate should be the outcome -- use _usecols to adjust if not the case.\n",
    "    share_memory is to indicate whether to share the dataframe in memory to \n",
    "    multiple processes -- if set to False, each process will copy the entire dataframe respectively. However, \n",
    "    to read very large dataframe using dask, this option should usually be turned off.\n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    assert csv_file != \"_\" or parquet_file != \"_\", \"CSV or parquet filepath should be declared\"\n",
    "\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    # read csv\n",
    "    _df, _usecols = _read_csv(csv_file=csv_file,\n",
    "                              _usecols=_usecols,\n",
    "                              csv_engine=csv_engine,\n",
    "                              parquet_file=parquet_file,\n",
    "                              sample=sample,\n",
    "                              verbose=verbose)\n",
    "\n",
    "    # share_memory for multiprocess\n",
    "    if share_memory == True:\n",
    "        # the origingal dataframe is df, store the columns/dtypes pairs\n",
    "        df_dtypes_dict = dict(list(zip(_df.columns, _df.dtypes)))\n",
    "        # declare a shared Array with data from df\n",
    "        mparr = _mp.Array(_ctypes.c_double, _df.values.reshape(-1))\n",
    "        # create a new df based on the shared array\n",
    "        _df = _pd.DataFrame(_np.frombuffer(mparr.get_obj()).reshape(_df.shape),\n",
    "                            columns=_df.columns).astype(df_dtypes_dict)\n",
    "\n",
    "    def _binary_skMI_df_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            __ = [\n",
    "                _usecols[0], _usecols[j]\n",
    "            ]  # here using _usecol[j] because only input variables indices were splitted\n",
    "            _a, _b = _read_two_columns(_df=_df, __=__, csv_engine=csv_engine)\n",
    "            return _mutual_info_classif(y=_a.reshape(-1, 1),\n",
    "                                        X=_b.reshape(-1, 1),\n",
    "                                        n_neighbors=n_neighbors,\n",
    "                                        discrete_features=False,\n",
    "                                        **kwarg)[0]\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(\n",
    "        1, len(_usecols)\n",
    "    )  # starting from 1 because the first left column should be the outcome\n",
    "\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_df = pl.map(_binary_skMI_df_slice, _iter)\n",
    "    MI_df = _np.hstack(MI_df)\n",
    "\n",
    "    del _df\n",
    "\n",
    "    return MI_df\n",
    "\n",
    "\n",
    "def continuous_skMI_screening_csv_parallel(csv_file=\"_\",\n",
    "                                           _usecols=[],\n",
    "                                           n_neighbors=3,\n",
    "                                           core_num=\"NOT DECLARED\",\n",
    "                                           multp=10,\n",
    "                                           csv_engine=\"c\",\n",
    "                                           parquet_file=\"_\",\n",
    "                                           sample=256000,\n",
    "                                           verbose=1,\n",
    "                                           share_memory=True,\n",
    "                                           **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Take a (potentionally large) csv file to calculate the mutual information between outcome and covariates.\n",
    "    Both the outcome and the covariates should be continuous. \n",
    "    If _usecols is given, the returned mutual information will match _usecols. \n",
    "    By default, the left first covariate should be the outcome -- use _usecols to adjust if not the case.\n",
    "    share_memory is to indicate whether to share the dataframe in memory to \n",
    "    multiple processes -- if set to False, each process will copy the entire dataframe respectively. However, \n",
    "    to read very large dataframe using dask, this option should usually be turned off.\n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    assert csv_file != \"_\" or parquet_file != \"_\", \"CSV or parquet filepath should be declared\"\n",
    "\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    # read csv\n",
    "    _df, _usecols = _read_csv(csv_file=csv_file,\n",
    "                              _usecols=_usecols,\n",
    "                              csv_engine=csv_engine,\n",
    "                              parquet_file=parquet_file,\n",
    "                              sample=sample,\n",
    "                              verbose=verbose)\n",
    "\n",
    "    # share_memory for multiprocess\n",
    "    if share_memory == True:\n",
    "        # the origingal dataframe is df, store the columns/dtypes pairs\n",
    "        df_dtypes_dict = dict(list(zip(_df.columns, _df.dtypes)))\n",
    "        # declare a shared Array with data from df\n",
    "        mparr = _mp.Array(_ctypes.c_double, _df.values.reshape(-1))\n",
    "        # create a new df based on the shared array\n",
    "        _df = _pd.DataFrame(_np.frombuffer(mparr.get_obj()).reshape(_df.shape),\n",
    "                            columns=_df.columns).astype(df_dtypes_dict)\n",
    "\n",
    "    def _continuous_skMI_df_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            __ = [\n",
    "                _usecols[0], _usecols[j]\n",
    "            ]  # here using _usecol[j] because only input variables indices were splitted\n",
    "            _a, _b = _read_two_columns(_df=_df, __=__, csv_engine=csv_engine)\n",
    "            return _mutual_info_regression(y=_a.reshape(-1, 1),\n",
    "                                           X=_b.reshape(-1, 1),\n",
    "                                           n_neighbors=n_neighbors,\n",
    "                                           discrete_features=False,\n",
    "                                           **kwarg)[0]\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(\n",
    "        1, len(_usecols)\n",
    "    )  # starting from 1 because the first left column should be the outcome\n",
    "\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_df = pl.map(_continuous_skMI_df_slice, _iter)\n",
    "    MI_df = _np.hstack(MI_df)\n",
    "\n",
    "    del _df\n",
    "\n",
    "    return MI_df\n",
    "\n",
    "\n",
    "def Pearson_screening_csv_parallel(csv_file=\"_\",\n",
    "                                   _usecols=[],\n",
    "                                   core_num=\"NOT DECLARED\",\n",
    "                                   multp=10,\n",
    "                                   csv_engine=\"c\",\n",
    "                                   parquet_file=\"_\",\n",
    "                                   sample=256000,\n",
    "                                   verbose=1,\n",
    "                                   share_memory=True):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Take a (potentionally large) csv file to calculate the Pearson's correlation between outcome and covariates.\n",
    "    If _usecols is given, the returned Pearson correlation will match _usecols. \n",
    "    By default, the left first covariate should be the outcome -- use _usecols to adjust if not the case.\n",
    "    This function accounts for missing data better than the Pearson's correlation matrix function provided by numpy.\n",
    "    share_memory is to indicate whether to share the dataframe in memory to \n",
    "    multiple processes -- if set to False, each process will copy the entire dataframe respectively. However, \n",
    "    to read very large dataframe using dask, this option should usually be turned off.    \"\"\"\n",
    "    # check some basic things\n",
    "    assert csv_file != \"_\" or parquet_file != \"_\", \"CSV or parquet filepath should be declared\"\n",
    "\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    # read csv\n",
    "    _df, _usecols = _read_csv(csv_file=csv_file,\n",
    "                              _usecols=_usecols,\n",
    "                              csv_engine=csv_engine,\n",
    "                              parquet_file=parquet_file,\n",
    "                              sample=sample,\n",
    "                              verbose=verbose)\n",
    "\n",
    "    # share_memory for multiprocess\n",
    "    if share_memory == True:\n",
    "        # the origingal dataframe is df, store the columns/dtypes pairs\n",
    "        df_dtypes_dict = dict(list(zip(_df.columns, _df.dtypes)))\n",
    "        # declare a shared Array with data from df\n",
    "        mparr = _mp.Array(_ctypes.c_double, _df.values.reshape(-1))\n",
    "        # create a new df based on the shared array\n",
    "        _df = _pd.DataFrame(_np.frombuffer(mparr.get_obj()).reshape(_df.shape),\n",
    "                            columns=_df.columns).astype(df_dtypes_dict)\n",
    "\n",
    "    def _Pearson_screening_df_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            __ = [\n",
    "                _usecols[0], _usecols[j]\n",
    "            ]  # here using _usecol[j] because only input variables indices were splitted\n",
    "            _a, _b = _read_two_columns(_df=_df, __=__, csv_engine=csv_engine)\n",
    "            # returned Pearson correlation is a symmetric matrix\n",
    "            _a -= _np.mean(_a)\n",
    "            _a /= _np.std(_a)\n",
    "            _b -= _np.mean(_b)\n",
    "            _b /= _np.std(_b)\n",
    "            #             return _np.corrcoef(_a, _b)[0, 1]\n",
    "            return _a @ _b / len(_a)\n",
    "\n",
    "        _pearson_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _pearson_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(\n",
    "        1, len(_usecols)\n",
    "    )  # starting from 1 because the first left column should be the outcome\n",
    "\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        Pearson_df = pl.map(_Pearson_screening_df_slice, _iter)\n",
    "    Pearson_df = _np.hstack(Pearson_df)\n",
    "\n",
    "    del _df\n",
    "\n",
    "    return Pearson_df\n",
    "\n",
    "\n",
    "def clump_continuous_csv_parallel(\n",
    "        csv_file=\"_\",\n",
    "        _usecols=[],\n",
    "        a_N=300,\n",
    "        b_N=300,\n",
    "        kernel=\"epa\",\n",
    "        bw=\"silverman\",\n",
    "        norm=2,\n",
    "        clumping_threshold=Pearson_to_MI_Gaussian(.6),\n",
    "        num_vars_exam=_np.infty,\n",
    "        core_num=\"NOT DECLARED\",\n",
    "        multp=10,\n",
    "        csv_engine=\"c\",\n",
    "        parquet_file=\"_\",\n",
    "        sample=256000,\n",
    "        verbose=1,\n",
    "        share_memory=True,\n",
    "        **kwarg):\n",
    "    \"\"\"\n",
    "    Perform clumping based on mutual information thresholding\n",
    "    The clumping process starts from the left to right, preserve input variables under the clumping threshold\n",
    "    share_memory is to indicate whether to share the dataframe in memory to \n",
    "    multiple processes -- if set to False, each process will copy the entire dataframe respectively. However, \n",
    "    to read very large dataframe using dask, this option should usually be turned off.    \"\"\"\n",
    "    # initialization\n",
    "    _, keep_cols = _read_csv(csv_file=csv_file,\n",
    "                             _usecols=_usecols,\n",
    "                             csv_engine=\"dask\",\n",
    "                             parquet_file=parquet_file,\n",
    "                             sample=sample,\n",
    "                             verbose=verbose)\n",
    "\n",
    "    del _\n",
    "\n",
    "    if num_vars_exam == _np.infty:\n",
    "        num_vars_exam = len(keep_cols) - 1\n",
    "    _iter = _np.arange(num_vars_exam)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    for current_var_ind in _iter:  # note that here _iter and keep_cols don't need to agree, by the break command comes later\n",
    "        if current_var_ind + 1 <= len(keep_cols):\n",
    "            _MI = continuous_screening_csv_parallel(\n",
    "                csv_file=csv_file,\n",
    "                _usecols=keep_cols[current_var_ind:],\n",
    "                core_num=core_num,\n",
    "                multp=multp,\n",
    "                csv_engine=csv_engine,\n",
    "                parquet_file=parquet_file,\n",
    "                sample=sample,\n",
    "                verbose=0,\n",
    "                share_memory=share_memory,\n",
    "                **kwarg)\n",
    "            # current_var_ind + 1 since the current variable will be included anyway\n",
    "            keep_cols = _np.hstack(\n",
    "                (keep_cols[:current_var_ind + 1],\n",
    "                 keep_cols[current_var_ind + 1:][_MI <= clumping_threshold]))\n",
    "        else:\n",
    "            break\n",
    "    return current_var_ind, keep_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f2694",
   "metadata": {},
   "source": [
    "# For numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07043f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.404067Z",
     "start_time": "2023-04-16T15:44:49.386412Z"
    }
   },
   "outputs": [],
   "source": [
    "def continuous_skMI_array_parallel(X,\n",
    "                                   y,\n",
    "                                   drop_na=True,\n",
    "                                   n_neighbors=3,\n",
    "                                   core_num=\"NOT DECLARED\",\n",
    "                                   multp=10,\n",
    "                                   verbose=1,\n",
    "                                   **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Calculate the mutual information using sklearn implementation between outcome and covariates.\n",
    "    The outcome should be binary and the covariates be continuous. \n",
    "    If drop_na is set to be True, the NaN values will be dropped in a bivariate manner. \n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    def _continuous_skMI_array_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            _a, _b = y.copy(), X[:, j].copy()\n",
    "            if drop_na == True:\n",
    "                _keep = _np.logical_not(\n",
    "                    _np.logical_or(_np.isnan(_a), _np.isnan(_b)))\n",
    "                _a, _b = _a[_keep], _b[_keep]\n",
    "            return _mutual_info_regression(y=_a.reshape(-1, 1),\n",
    "                                           X=_b.reshape(-1, 1),\n",
    "                                           n_neighbors=n_neighbors,\n",
    "                                           discrete_features=False,\n",
    "                                           **kwarg)[0]\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(X.shape[1])\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_array = pl.map(_continuous_skMI_array_slice, _iter)\n",
    "    MI_array = _np.hstack(MI_array)\n",
    "    return MI_array\n",
    "\n",
    "\n",
    "def binary_screening_array(X,\n",
    "                           y,\n",
    "                           drop_na=True,\n",
    "                           N=500,\n",
    "                           kernel=\"epa\",\n",
    "                           bw=\"silverman\",\n",
    "                           verbose=1,\n",
    "                           **kwarg):\n",
    "    \"\"\"\n",
    "    Take a numpy file to calculate the mutual information between outcome and covariates.\n",
    "    The outcome should be binary and the covariates be continuous. \n",
    "    If drop_na is set to be True, the NaN values will be dropped in a bivariate manner. \n",
    "    \"\"\"\n",
    "    def _map_foo(j):\n",
    "        _a, _b = y.copy(), X[:, j].copy()\n",
    "        if drop_na == True:\n",
    "            _keep = _np.logical_not(\n",
    "                _np.logical_or(_np.isnan(_a), _np.isnan(_b)))\n",
    "            _a, _b = _a[_keep], _b[_keep]\n",
    "        return MI_binary_continuous(a=_a,\n",
    "                                    b=_b,\n",
    "                                    N=N,\n",
    "                                    kernel=kernel,\n",
    "                                    bw=bw,\n",
    "                                    **kwarg)\n",
    "\n",
    "    _iter = _np.arange(X.shape[1])\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    MI_array = _np.array(list(map(_map_foo, _iter)))\n",
    "    return MI_array\n",
    "\n",
    "\n",
    "def continuous_screening_array(X,\n",
    "                               y,\n",
    "                               drop_na=True,\n",
    "                               a_N=300,\n",
    "                               b_N=300,\n",
    "                               kernel=\"epa\",\n",
    "                               bw=\"silverman\",\n",
    "                               norm=2,\n",
    "                               verbose=1,\n",
    "                               **kwarg):\n",
    "    \"\"\"\n",
    "    Take a numpy file to calculate the mutual information between outcome and covariates.\n",
    "    The outcome should be continuous and the covariates be continuous. \n",
    "    If drop_na is set to be True, the NaN values will be dropped in a bivariate manner. \n",
    "    \"\"\"\n",
    "    def _map_foo(j):\n",
    "        _a, _b = y.copy(), X[:, j].copy()\n",
    "        if drop_na == True:\n",
    "            _keep = _np.logical_not(\n",
    "                _np.logical_or(_np.isnan(_a), _np.isnan(_b)))\n",
    "            _a, _b = _a[_keep], _b[_keep]\n",
    "        return MI_continuous_continuous(a=_a,\n",
    "                                        b=_b,\n",
    "                                        a_N=a_N,\n",
    "                                        b_N=b_N,\n",
    "                                        kernel=kernel,\n",
    "                                        bw=bw,\n",
    "                                        norm=norm,\n",
    "                                        **kwarg)\n",
    "\n",
    "    _iter = _np.arange(X.shape[1])\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    MI_array = _np.array(list(map(_map_foo, _iter)))\n",
    "    return MI_array\n",
    "\n",
    "\n",
    "def binary_screening_array_parallel(X,\n",
    "                                    y,\n",
    "                                    drop_na=True,\n",
    "                                    N=500,\n",
    "                                    kernel=\"epa\",\n",
    "                                    bw=\"silverman\",\n",
    "                                    core_num=\"NOT DECLARED\",\n",
    "                                    multp=10,\n",
    "                                    verbose=1,\n",
    "                                    **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Calculate the mutual information between outcome and covariates.\n",
    "    The outcome should be binary and the covariates be continuous. \n",
    "    If drop_na is set to be True, the NaN values will be dropped in a bivariate manner. \n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    def _binary_screening_array_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            _a, _b = y.copy(), X[:, j].copy()\n",
    "            if drop_na == True:\n",
    "                _keep = _np.logical_not(\n",
    "                    _np.logical_or(_np.isnan(_a), _np.isnan(_b)))\n",
    "                _a, _b = _a[_keep], _b[_keep]\n",
    "            return MI_binary_continuous(a=_a,\n",
    "                                        b=_b,\n",
    "                                        N=N,\n",
    "                                        kernel=kernel,\n",
    "                                        bw=bw,\n",
    "                                        **kwarg)\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(\n",
    "        X.shape[1]\n",
    "    )  # starting from 1 because the first left column should be the outcome\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_array = pl.map(_binary_screening_csv_slice, _iter)\n",
    "    MI_array = _np.hstack(MI_array)\n",
    "    return MI_array\n",
    "\n",
    "\n",
    "def continuous_screening_array_parallel(X,\n",
    "                                        y,\n",
    "                                        drop_na=True,\n",
    "                                        a_N=300,\n",
    "                                        b_N=300,\n",
    "                                        kernel=\"epa\",\n",
    "                                        bw=\"silverman\",\n",
    "                                        norm=2,\n",
    "                                        core_num=\"NOT DECLARED\",\n",
    "                                        multp=10,\n",
    "                                        verbose=1,\n",
    "                                        **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Calculate the mutual information between outcome and covariates.\n",
    "    The outcome should be continuous and the covariates be continuous. \n",
    "    If drop_na is set to be True, the NaN values will be dropped in a bivariate manner. \n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    def _continuous_screening_array_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            _a, _b = y.copy(), X[:, j].copy()\n",
    "            if drop_na == True:\n",
    "                _keep = _np.logical_not(\n",
    "                    _np.logical_or(_np.isnan(_a), _np.isnan(_b)))\n",
    "                _a, _b = _a[_keep], _b[_keep]\n",
    "            return MI_continuous_continuous(a=_a,\n",
    "                                            b=_b,\n",
    "                                            a_N=a_N,\n",
    "                                            b_N=b_N,\n",
    "                                            kernel=kernel,\n",
    "                                            bw=bw,\n",
    "                                            norm=norm,\n",
    "                                            **kwarg)\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(X.shape[1])\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_array = pl.map(_continuous_screening_array_slice, _iter)\n",
    "    MI_array = _np.hstack(MI_array)\n",
    "    return MI_array\n",
    "\n",
    "\n",
    "def binary_skMI_array_parallel(X,\n",
    "                               y,\n",
    "                               drop_na=True,\n",
    "                               n_neighbors=3,\n",
    "                               core_num=\"NOT DECLARED\",\n",
    "                               multp=10,\n",
    "                               verbose=1,\n",
    "                               **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Calculate the mutual information using sklearn implementation between outcome and covariates.\n",
    "    The outcome should be binary and the covariates be binary. \n",
    "    If drop_na is set to be True, the NaN values will be dropped in a bivariate manner. \n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    def _binary_skMI_array_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            _a, _b = y.copy(), X[:, j].copy()\n",
    "            if drop_na == True:\n",
    "                _keep = _np.logical_not(\n",
    "                    _np.logical_or(_np.isnan(_a), _np.isnan(_b)))\n",
    "                _a, _b = _a[_keep], _b[_keep]\n",
    "            return _mutual_info_classif(y=_a.reshape(-1, 1),\n",
    "                                        X=_b.reshape(-1, 1),\n",
    "                                        n_neighbors=n_neighbors,\n",
    "                                        discrete_features=False,\n",
    "                                        **kwarg)[0]\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(X.shape[1])\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_array = pl.map(_binary_skMI_array_slice, _iter)\n",
    "    MI_array = _np.hstack(MI_array)\n",
    "    return MI_array\n",
    "\n",
    "\n",
    "def continuous_skMI_array_parallel(X,\n",
    "                                   y,\n",
    "                                   drop_na=True,\n",
    "                                   n_neighbors=3,\n",
    "                                   core_num=\"NOT DECLARED\",\n",
    "                                   multp=10,\n",
    "                                   verbose=1,\n",
    "                                   **kwarg):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Calculate the mutual information using sklearn implementation between outcome and covariates.\n",
    "    The outcome should be binary and the covariates be continuous. \n",
    "    If drop_na is set to be True, the NaN values will be dropped in a bivariate manner. \n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    def _continuous_skMI_array_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            _a, _b = y.copy(), X[:, j].copy()\n",
    "            if drop_na == True:\n",
    "                _keep = _np.logical_not(\n",
    "                    _np.logical_or(_np.isnan(_a), _np.isnan(_b)))\n",
    "                _a, _b = _a[_keep], _b[_keep]\n",
    "            return _mutual_info_regression(y=_a.reshape(-1, 1),\n",
    "                                           X=_b.reshape(-1, 1),\n",
    "                                           n_neighbors=n_neighbors,\n",
    "                                           discrete_features=False,\n",
    "                                           **kwarg)[0]\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(X.shape[1])\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_array = pl.map(_continuous_skMI_array_slice, _iter)\n",
    "    MI_array = _np.hstack(MI_array)\n",
    "    return MI_array\n",
    "\n",
    "\n",
    "def continuous_Pearson_array_parallel(X,\n",
    "                                      y,\n",
    "                                      drop_na=True,\n",
    "                                      n_neighbors=3,\n",
    "                                      core_num=\"NOT DECLARED\",\n",
    "                                      multp=10,\n",
    "                                      verbose=1):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) Calculate the mutual information using sklearn implementation between outcome and covariates.\n",
    "    The outcome should be binary and the covariates be continuous. \n",
    "    If drop_na is set to be True, the NaN values will be dropped in a bivariate manner. \n",
    "    \"\"\"\n",
    "    # check some basic things\n",
    "    if core_num == \"NOT DECLARED\":\n",
    "        core_num = _mp.cpu_count()\n",
    "    else:\n",
    "        assert core_num <= _mp.cpu_count(\n",
    "        ), \"Declared number of cores used for multiprocessing should not exceed number of cores on this machine.\"\n",
    "    assert core_num >= 2, \"Multiprocessing should not be used on single-core machines.\"\n",
    "\n",
    "    def _continuous_Pearson_array_slice(_slice):\n",
    "        def _map_foo(j):\n",
    "            _a, _b = y.copy(), X[:, j].copy()\n",
    "            if drop_na == True:\n",
    "                _keep = _np.logical_not(\n",
    "                    _np.logical_or(_np.isnan(_a), _np.isnan(_b)))\n",
    "                _a, _b = _a[_keep], _b[_keep]\n",
    "            _a -= _np.mean(_a)\n",
    "            _a /= _np.std(_a)\n",
    "            _b -= _np.mean(_b)\n",
    "            _b /= _np.std(_b)\n",
    "            return _a @ _b / len(_a)\n",
    "\n",
    "        _MI_slice = _np.array(list(map(_map_foo, _slice)))\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(X.shape[1])\n",
    "    _iter = _np.array_split(ind, core_num * multp)\n",
    "    if verbose >= 1:\n",
    "        _iter = _tqdm(_iter)\n",
    "    with _mp.Pool(core_num) as pl:\n",
    "        MI_array = pl.map(_continuous_Pearson_array_slice, _iter)\n",
    "    MI_array = _np.hstack(MI_array)\n",
    "    return MI_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd99543",
   "metadata": {},
   "source": [
    "# Tests\n",
    "## test for basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a032b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.849905Z",
     "start_time": "2023-04-16T15:44:49.404952Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bed_reader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbed_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_bed\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# import cupy as cp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m toeplitz, block_diag\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bed_reader'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bed_reader import open_bed\n",
    "# import cupy as cp\n",
    "from scipy.linalg import toeplitz, block_diag\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "a = np.random.binomial(2, .3, 2000)\n",
    "b = np.random.binomial(2, .3, 2000)\n",
    "print(\n",
    "    \"two independant generalized Bern. r.v. realisations has MI estimate of \",\n",
    "    MI_binary_012(a, b))\n",
    "print(\n",
    "    \"two independant generalized Bern. r.v. realisations has MI estimate of \",\n",
    "    MI_012_012(a, b))\n",
    "\n",
    "a = np.random.normal(size=2000)\n",
    "b = np.random.normal(size=2000)\n",
    "\n",
    "print(\n",
    "    \"two independant generalized Gaussian r.v. realisations has MI estimate of \",\n",
    "    MI_continuous_continuous(a, b))\n",
    "a_MI = np.zeros(500)\n",
    "b_MI = np.zeros(500)\n",
    "for i in np.arange(500):\n",
    "    np.random.seed(i)\n",
    "    a = np.random.normal(size=2000)\n",
    "    b = np.random.normal(size=2000)\n",
    "    a_MI[i] = MI_continuous_continuous(a, a)\n",
    "    b_MI[i] = MI_continuous_continuous(a, b)\n",
    "print(\"MI estimate between a,a and a,b: \", np.mean(a_MI), np.mean(b_MI))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc9ae9",
   "metadata": {},
   "source": [
    "## test for `plink` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5549d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.851167Z",
     "start_time": "2023-04-16T15:44:49.851160Z"
    }
   },
   "outputs": [],
   "source": [
    "# test for continuous screening on plink files\n",
    "bed_file = r\"./fastHDMI/tests/sim/sim1.bed\"\n",
    "bim_file = r\"./fastHDMI/tests/sim/sim1.bim\"\n",
    "fam_file = r\"./fastHDMI/tests/sim/sim1.fam\"\n",
    "\n",
    "_bed = open_bed(filepath=bed_file,\n",
    "                fam_filepath=fam_file,\n",
    "                bim_filepath=bim_file)\n",
    "outcome = np.random.rand(_bed.iid_count)\n",
    "outcome_iid = _bed.iid\n",
    "\n",
    "true_beta = np.array([4.2, -2.5, 2.6])\n",
    "for j in np.arange(3):\n",
    "    outcome += true_beta[j] * _bed.read(np.s_[:, j], dtype=np.int8).flatten()\n",
    "    print(_bed.read(np.s_[:, j], dtype=np.float64).flatten())\n",
    "\n",
    "iid_ind = np.random.permutation(np.arange(_bed.iid_count))\n",
    "outcome = outcome[iid_ind]\n",
    "outcome_iid = outcome_iid[iid_ind]\n",
    "\n",
    "MI_continuous = continuous_screening_plink_parallel(bed_file=bed_file,\n",
    "                                                    bim_file=bim_file,\n",
    "                                                    fam_file=fam_file,\n",
    "                                                    outcome=outcome,\n",
    "                                                    outcome_iid=outcome_iid)\n",
    "assert np.all(MI_continuous >= 0)\n",
    "\n",
    "plt.plot(MI_continuous)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5026fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.851850Z",
     "start_time": "2023-04-16T15:44:49.851842Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing for binary plink files screening\n",
    "bed_file = r\"./fastHDMI/tests/sim/sim1.bed\"\n",
    "bim_file = r\"./fastHDMI/tests/sim/sim1.bim\"\n",
    "fam_file = r\"./fastHDMI/tests/sim/sim1.fam\"\n",
    "\n",
    "_bed = open_bed(filepath=bed_file,\n",
    "                fam_filepath=fam_file,\n",
    "                bim_filepath=bim_file)\n",
    "outcome = np.random.rand(_bed.iid_count)\n",
    "outcome_iid = _bed.iid\n",
    "\n",
    "true_beta = np.array([4.2, -2.5, 2.6])\n",
    "for j in np.arange(3):\n",
    "    outcome += true_beta[j] * _bed.read(np.s_[:, j], dtype=np.int8).flatten()\n",
    "    print(_bed.read(np.s_[:, j], dtype=np.float64).flatten())\n",
    "\n",
    "outcome = np.random.binomial(1, np.tanh(outcome / 2) / 2 + .5)\n",
    "\n",
    "iid_ind = np.random.permutation(np.arange(_bed.iid_count))\n",
    "outcome = outcome[iid_ind]\n",
    "outcome_iid = outcome_iid[iid_ind]\n",
    "\n",
    "MI_binary = binary_screening_plink_parallel(bed_file=bed_file,\n",
    "                                            bim_file=bim_file,\n",
    "                                            fam_file=fam_file,\n",
    "                                            outcome=outcome,\n",
    "                                            outcome_iid=outcome_iid)\n",
    "assert np.all(MI_binary >= 0)\n",
    "\n",
    "plt.plot(MI_binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657c60c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.852386Z",
     "start_time": "2023-04-16T15:44:49.852379Z"
    }
   },
   "outputs": [],
   "source": [
    "# test for clumping for plink files\n",
    "bed_file = r\"./fastHDMI/tests/sim/sim1.bed\"\n",
    "bim_file = r\"./fastHDMI/tests/sim/sim1.bim\"\n",
    "fam_file = r\"./fastHDMI/tests/sim/sim1.fam\"\n",
    "\n",
    "clump_plink_parallel(bed_file=bed_file,\n",
    "                     bim_file=bim_file,\n",
    "                     fam_file=fam_file,\n",
    "                     num_SNPS_exam=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba5d6b",
   "metadata": {},
   "source": [
    "## test for `csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764c527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.852951Z",
     "start_time": "2023-04-16T15:44:49.852944Z"
    }
   },
   "outputs": [],
   "source": [
    "# # This is to generate the test csv files\n",
    "# import numpy as np\n",
    "# from scipy.linalg import toeplitz, block_diag\n",
    "# import pandas as pd\n",
    "\n",
    "# np.random.seed(123)\n",
    "# np.random.seed(np.around(np.random.rand(1) * 1e6, 3).astype(int))\n",
    "# N = 1000\n",
    "# SNR = 5.\n",
    "# true_beta = np.array([2., -2., 8., -8.] + [0] * 2000)\n",
    "# X_cov = toeplitz(.6**np.arange(true_beta.shape[0]))\n",
    "# X_cov = np.asarray(X_cov)\n",
    "# mean = (np.random.rand(true_beta.shape[0]) - .5) * 100\n",
    "# X = np.random.multivariate_normal(mean, X_cov, N)\n",
    "# X -= np.mean(X, 0).reshape(1, -1)\n",
    "# X /= np.std(X, 0).reshape(1, -1)\n",
    "# intercept_design_column = np.ones(N).reshape(N, 1)\n",
    "# X_sim = np.concatenate((intercept_design_column, X), 1)\n",
    "# true_sigma_sim = np.sqrt(true_beta.T @ X_cov @ true_beta / SNR)\n",
    "# true_beta_intercept = np.concatenate((np.array([0]), true_beta))\n",
    "# y_sim = X_sim @ true_beta_intercept + np.random.normal(0, true_sigma_sim, N)\n",
    "# X = X**2\n",
    "# X -= np.mean(X, 0).reshape(1, -1)\n",
    "# X /= np.std(X, 0).reshape(1, -1)\n",
    "# X = np.concatenate((y_sim.reshape(-1, 1), X), 1)\n",
    "# X.ravel()[np.random.choice(X.size, int(X.size * .1),\n",
    "#                            replace=False)] = np.nan  # 10% missing data\n",
    "\n",
    "# pd.DataFrame(X,\n",
    "#              columns=map(lambda x: \"Var \" + str(x), np.arange(\n",
    "#                  1, X.shape[1] +\n",
    "#                  1))).to_csv(r\"./fastHDMI/tests/sim/sim_continuous.csv\")\n",
    "\n",
    "# # this cell is for profiling the function\n",
    "# np.random.seed(321)\n",
    "# np.random.seed(np.around(np.random.rand(1) * 1e6, 3).astype(int))\n",
    "# N = 1000\n",
    "# SNR = 5.\n",
    "# true_beta = np.array([.5, -.5, .8, -.8] + [0] * 2000)\n",
    "# X_cov = toeplitz(.6**np.arange(true_beta.shape[0]))\n",
    "# X_cov = np.asarray(X_cov)\n",
    "# mean = (np.random.rand(true_beta.shape[0]) - .5) * 100\n",
    "# X = np.random.multivariate_normal(mean, X_cov, N)\n",
    "# X -= np.mean(X, 0).reshape(1, -1)\n",
    "# X /= np.std(X, 0).reshape(1, -1)\n",
    "# intercept_design_column = np.ones(N).reshape(N, 1)\n",
    "# X_sim = np.concatenate((intercept_design_column, X), 1)\n",
    "# true_sigma_sim = np.sqrt(true_beta.T @ X_cov @ true_beta / SNR)\n",
    "# true_beta_intercept = np.concatenate((np.array([0]), true_beta))\n",
    "# # + np.random.normal(0, true_sigma_sim, N)\n",
    "# signal = X_sim @ true_beta_intercept\n",
    "# y_sim = np.random.binomial(1, np.tanh(signal / 2) / 2 + .5)\n",
    "# # X = X**2\n",
    "# # X -= np.mean(X, 0).reshape(1, -1)\n",
    "# # X /= np.std(X, 0).reshape(1, -1)\n",
    "# X = np.concatenate((y_sim.reshape(-1, 1), X), 1)\n",
    "# X.ravel()[np.random.choice(X.size, int(X.size * .1),\n",
    "#                            replace=False)] = np.nan  # 10% missing data\n",
    "\n",
    "# pd.DataFrame(X,\n",
    "#              columns=map(lambda x: \"Var \" + str(x), np.arange(\n",
    "#                  1, X.shape[1] +\n",
    "#                  1))).to_csv(r\"./fastHDMI/tests/sim/sim_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4c7d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.853553Z",
     "start_time": "2023-04-16T15:44:49.853547Z"
    }
   },
   "outputs": [],
   "source": [
    "# single-thread continuous version test\n",
    "a = continuous_screening_csv(r\"./fastHDMI/tests/sim/sim_continuous.csv\")\n",
    "assert np.all(a >= 0)\n",
    "\n",
    "plt.plot(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637d850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.853990Z",
     "start_time": "2023-04-16T15:44:49.853983Z"
    }
   },
   "outputs": [],
   "source": [
    "# parallel continuous version test XXX\n",
    "a = continuous_screening_csv_parallel(\n",
    "    r\"./fastHDMI/tests/sim/sim_continuous.csv\")\n",
    "assert np.all(a >= 0)\n",
    "plt.plot(a)\n",
    "plt.show()\n",
    "\n",
    "b = np.absolute(\n",
    "    Pearson_screening_csv_parallel(r\"./fastHDMI/tests/sim/sim_continuous.csv\"))\n",
    "plt.plot(b)\n",
    "plt.show()\n",
    "\n",
    "c = continuous_skMI_screening_csv_parallel(\n",
    "    r\"./fastHDMI/tests/sim/sim_continuous.csv\", random_state=0)\n",
    "assert np.all(c >= 0)\n",
    "plt.plot(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ddd1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.854574Z",
     "start_time": "2023-04-16T15:44:49.854567Z"
    }
   },
   "outputs": [],
   "source": [
    "# single-thread binary version for csv\n",
    "a = binary_screening_csv(r\"./fastHDMI/tests/sim/sim_binary.csv\")\n",
    "print(a)\n",
    "assert np.all(a >= 0)\n",
    "plt.plot(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51a385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.855187Z",
     "start_time": "2023-04-16T15:44:49.855181Z"
    }
   },
   "outputs": [],
   "source": [
    "# parallel binary version test\n",
    "a = binary_screening_csv_parallel(r\"./fastHDMI/tests/sim/sim_binary.csv\")\n",
    "assert np.all(a >= 0)\n",
    "plt.plot(a)\n",
    "plt.show()\n",
    "\n",
    "b = np.absolute(\n",
    "    Pearson_screening_csv_parallel(r\"./fastHDMI/tests/sim/sim_binary.csv\"))\n",
    "plt.plot(b)\n",
    "plt.show()\n",
    "\n",
    "c = binary_skMI_screening_csv_parallel(r\"./fastHDMI/tests/sim/sim_binary.csv\",\n",
    "                                       random_state=0)\n",
    "assert np.all(c >= 0)\n",
    "plt.plot(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9dda67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.855762Z",
     "start_time": "2023-04-16T15:44:49.855756Z"
    }
   },
   "outputs": [],
   "source": [
    "# test for clumping for CSV files\n",
    "clump_continuous_csv_parallel(\n",
    "    csv_file=r\"./fastHDMI/tests/sim/sim_continuous.csv\", num_vars_exam=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d68690",
   "metadata": {},
   "source": [
    "## test for `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c8ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:44:49.856220Z",
     "start_time": "2023-04-16T15:44:49.856214Z"
    }
   },
   "outputs": [],
   "source": [
    "# parallel continuous version but using numpy array\n",
    "csv = pd.read_csv(r\"./fastHDMI/tests/sim/sim_continuous.csv\",\n",
    "                  encoding='unicode_escape',\n",
    "                  engine=\"c\")\n",
    "# here it is because pandas reads the first column as the index\n",
    "X, y = csv.iloc[:, 2:].to_numpy(), csv.iloc[:, 1].to_numpy()\n",
    "\n",
    "MI = continuous_screening_array_parallel(X, y)\n",
    "assert np.all(MI >= 0)\n",
    "plt.plot(MI)\n",
    "plt.show()\n",
    "\n",
    "skMI = continuous_skMI_array_parallel(X, y, n_neighbors=3, random_state=0)\n",
    "assert np.all(skMI >= 0)\n",
    "plt.plot(skMI)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8be973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "893.844px",
    "left": "2190px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
