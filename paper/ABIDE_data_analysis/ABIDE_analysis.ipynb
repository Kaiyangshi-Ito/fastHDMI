{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b753056",
   "metadata": {},
   "source": [
    "# Case and Simulation studies based on ABIDE data\n",
    "## Kai Yang\n",
    "## <kai.yang2 \"at\" mail.mcgill.ca>\n",
    "## License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)\n",
    "## [GPG Public key Fingerprint: CC02CF153594774CF956691492B2600D18170329](https://keys.openpgp.org/vks/v1/by-fingerprint/CC02CF153594774CF956691492B2600D18170329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39eea284-aeec-427b-b3fc-2a35d72a5825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:13.727222Z",
     "start_time": "2023-12-23T21:19:13.192966Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "# import fastHDMI as mi # I comment out since I am running the Jupyter notebook on my M1 Macbook air\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Times New Roman\",\n",
    "    \"font.sans-serif\": [\"Times New Roman\"],\n",
    "    \"font.size\": 12\n",
    "})\n",
    "\n",
    "os.chdir(sys.path[0])  # ensure working direcotry is set same as the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f64a8",
   "metadata": {},
   "source": [
    "# Simulation study for continuous and binary outcome based on ABIDE data, and testing the screening performance for all three methods\n",
    "\n",
    "## creating job submission scripts for simulation study\n",
    "\n",
    "### simulating *nonlinear* outcomes/predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0697560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:13.735609Z",
     "start_time": "2023-12-23T21:19:13.728699Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_generator(outcome, num_true_vars_iter):\n",
    "    py_1 = r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# read the data\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "\n",
    "abide_original = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "_abide_name = abide_original.columns.tolist()[1:]\n",
    "\n",
    "# print(_abide_name)\n",
    "\n",
    "abide_name_original = _abide_name[1:-3]\n",
    "\n",
    "# preserve only the neuro-imaging data\n",
    "abide_original = abide_original[abide_name_original]\n",
    "\n",
    "def convert2list(a):\n",
    "    b = np.asarray(a)\n",
    "    return b.tolist()\n",
    "\"\"\"\n",
    "    if outcome == \"continuous\":\n",
    "        py_2 = r\"\"\"\n",
    "def sim_based_on_abide_continuous(pair):\n",
    "    abide, abide_name = abide_original.copy(), abide_name_original.copy()\n",
    "    _num_true_vars, _seed = pair\n",
    "    SNR = 3.\n",
    "    num_true_vars = _num_true_vars\n",
    "    seed = _seed\n",
    "    assert num_true_vars < len(abide_name)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    true_attr_label = np.zeros(len(abide_name), dtype=int)\n",
    "    true_attr_index = np.arange(len(abide_name))\n",
    "    true_attr_index = np.random.choice(true_attr_index,\n",
    "                                       num_true_vars,\n",
    "                                       replace=False)\n",
    "    true_names = np.take(abide_name,\n",
    "                         true_attr_index)  # this is a list for true names\n",
    "    true_names = convert2list(true_names)\n",
    "    true_attr_label[\n",
    "        true_attr_index] = 1  # true_attr_label is binary indicate whether the covaraite is \"true\"\n",
    "\n",
    "    true_beta = np.random.choice([1., -1.], num_true_vars, replace=True)\n",
    "    #     true_beta = np.random.uniform(low=5.0, high=6.0,\n",
    "    #                                   size=num_true_vars) * np.random.choice(\n",
    "    #                                       [1., -1.], num_true_vars, replace=True)\n",
    "\n",
    "    sim_data = abide[true_names].to_numpy(copy=True)\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    sim_data = sim_data**2\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "\n",
    "    X_cov = np.corrcoef(sim_data, rowvar=False)\n",
    "    true_sigma_sim = np.sqrt(true_beta.T @ X_cov @ true_beta / SNR)\n",
    "\n",
    "    outcome = sim_data @ true_beta + np.random.normal(0, true_sigma_sim,\n",
    "                                                      sim_data.shape[0])\n",
    "\n",
    "    abide[\"outcome\"] = outcome\n",
    "    abide = abide[[\"outcome\"] + abide_name]\n",
    "\n",
    "    print(\"The outcome is continuous.\")\n",
    "\n",
    "    print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "    try:\n",
    "        mi_output = mi.continuous_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"ISJ\",\n",
    "            norm=2)\n",
    "    except:\n",
    "        mi_output = mi.continuous_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"silverman\",\n",
    "            norm=2)\n",
    "\n",
    "    print(\"Our developed binning MI calculation:\")\n",
    "\n",
    "    binning_mi_output = mi.binning_continuous_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"sklearn MI calculation:\")\n",
    "\n",
    "    skmi_output = mi.continuous_skMI_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        random_state=0,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "    pearson_output = mi.Pearson_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    mi_pseudo_prob = np.abs(mi_output) / np.max(np.abs(mi_output))\n",
    "    mi_auroc = roc_auc_score(true_attr_label, mi_pseudo_prob)\n",
    "    binning_mi_pseudo_prob = np.abs(binning_mi_output) / np.max(\n",
    "        np.abs(binning_mi_output))\n",
    "    binning_mi_auroc = roc_auc_score(true_attr_label, binning_mi_pseudo_prob)\n",
    "    skmi_pseudo_prob = np.abs(skmi_output) / np.max(np.abs(skmi_output))\n",
    "    skmi_auroc = roc_auc_score(true_attr_label, skmi_pseudo_prob)\n",
    "    pearson_pseudo_prob = np.abs(pearson_output) / np.max(\n",
    "        np.abs(pearson_output))\n",
    "    pearson_auroc = roc_auc_score(true_attr_label, pearson_pseudo_prob)\n",
    "\n",
    "    del mi_output, binning_mi_output, skmi_output, pearson_output, abide, abide_name, true_names, true_beta, sim_data, X_cov, true_sigma_sim, outcome, mi_pseudo_prob, skmi_pseudo_prob, pearson_pseudo_prob\n",
    "\n",
    "    return np.array([mi_auroc, skmi_auroc, pearson_auroc, binning_mi_auroc])\n",
    "\n",
    "\n",
    "num_true_vars_list = [{_num_true_vars_iter}]\n",
    "seed_list = range(100)\n",
    "\n",
    "itrs = itertools.product(num_true_vars_list, seed_list)\n",
    "\n",
    "output_array = np.array(list(map(sim_based_on_abide_continuous, tqdm(itrs))))\n",
    "output_array = output_array.reshape(1, 100, 4).squeeze()\n",
    "np.save(r\"./ABIDE_{_outcome}_{_num_true_vars_iter}\", output_array)\n",
    "\"\"\".format(_num_true_vars_iter=num_true_vars_iter, _outcome=outcome)\n",
    "    elif outcome == \"binary_original\":\n",
    "        py_2 = r\"\"\"\n",
    "def sim_based_on_abide_binary(pair):\n",
    "    abide, abide_name = abide_original.copy(), abide_name_original.copy()\n",
    "    _num_true_vars, _seed = pair\n",
    "    num_true_vars = _num_true_vars\n",
    "    seed = _seed\n",
    "    assert num_true_vars < len(abide_name)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    true_attr_label = np.zeros(len(abide_name), dtype=int)\n",
    "    true_attr_index = np.arange(len(abide_name))\n",
    "    true_attr_index = np.random.choice(true_attr_index,\n",
    "                                       num_true_vars,\n",
    "                                       replace=False)\n",
    "    true_names = np.take(abide_name,\n",
    "                         true_attr_index)  # this is a list for true names\n",
    "    true_names = convert2list(true_names)\n",
    "    true_attr_label[\n",
    "        true_attr_index] = 1  # true_attr_label is binary indicate whether the covaraite is \"true\"\n",
    "\n",
    "    true_beta = np.random.choice([1., -1.], num_true_vars, replace=True)\n",
    "    #     true_beta = np.random.uniform(low=.5, high=.6,\n",
    "    #                                   size=num_true_vars) * np.random.choice(\n",
    "    #                                       [1., -1.], num_true_vars, replace=True)\n",
    "\n",
    "    sim_data = abide[true_names].to_numpy(copy=True)\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    sim_data = sim_data**2\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    signal = sim_data @ true_beta\n",
    "    signal -= np.mean(\n",
    "        signal\n",
    "    )  # make sure it's centered at 0 to avoid generated data all be in one class\n",
    "    signal /= np.std(signal)  # avoid the case if the data is too centered\n",
    "\n",
    "    outcome = np.random.binomial(1, np.tanh(signal / 2) / 2 + .5)  # logistic\n",
    "    # outcome = np.random.binomial(1,\n",
    "    #                              np.arcsin(np.sqrt(signal + np.min(signal))) /\n",
    "    #                              (np.pi / 2.))  # arcsin(sqrt(.))\n",
    "\n",
    "    abide[\"outcome\"] = outcome\n",
    "    abide = abide[[\"outcome\"] + abide_name]\n",
    "\n",
    "    print(\"The outcome is binary.\")\n",
    "\n",
    "    print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "    try:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"ISJ\")\n",
    "    except:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"silverman\")\n",
    "            \n",
    "    print(\"Our developed binning MI calculation:\")\n",
    "\n",
    "    binning_mi_output = mi.binning_binary_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"sklearn MI calculation:\")\n",
    "\n",
    "    skmi_output = mi.binary_skMI_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        random_state=0,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "    pearson_output = mi.Pearson_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    mi_pseudo_prob = np.abs(mi_output) / np.max(np.abs(mi_output))\n",
    "    mi_auroc = roc_auc_score(true_attr_label, mi_pseudo_prob)\n",
    "    binning_mi_pseudo_prob = np.abs(binning_mi_output) / np.max(\n",
    "        np.abs(binning_mi_output))\n",
    "    binning_mi_auroc = roc_auc_score(true_attr_label, binning_mi_pseudo_prob)\n",
    "    skmi_pseudo_prob = np.abs(skmi_output) / np.max(np.abs(skmi_output))\n",
    "    skmi_auroc = roc_auc_score(true_attr_label, skmi_pseudo_prob)\n",
    "    pearson_pseudo_prob = np.abs(pearson_output) / np.max(\n",
    "        np.abs(pearson_output))\n",
    "    pearson_auroc = roc_auc_score(true_attr_label, pearson_pseudo_prob)\n",
    "\n",
    "    del mi_output, binning_mi_output, skmi_output, pearson_output, abide, abide_name, true_names, true_beta, sim_data, signal, outcome, mi_pseudo_prob, skmi_pseudo_prob, pearson_pseudo_prob\n",
    "\n",
    "    return np.array([mi_auroc, skmi_auroc, pearson_auroc, binning_mi_auroc])\n",
    "\n",
    "\n",
    "num_true_vars_list = [{_num_true_vars_iter}]\n",
    "seed_list = range(100)\n",
    "\n",
    "itrs = itertools.product(num_true_vars_list, seed_list)\n",
    "\n",
    "output_array = np.array(list(map(sim_based_on_abide_binary, tqdm(itrs))))\n",
    "output_array = output_array.reshape(1, 100, 4).squeeze()\n",
    "np.save(r\"./ABIDE_{_outcome}_{_num_true_vars_iter}\", output_array)\n",
    "\"\"\".format(_num_true_vars_iter=num_true_vars_iter, _outcome=outcome)\n",
    "\n",
    "    elif outcome == \"binary_translated\":\n",
    "        py_2 = r\"\"\"\n",
    "def sim_based_on_abide_binary(pair):\n",
    "    abide, abide_name = abide_original.copy(), abide_name_original.copy()\n",
    "    _num_true_vars, _seed = pair\n",
    "    num_true_vars = _num_true_vars\n",
    "    seed = _seed\n",
    "    assert num_true_vars < len(abide_name)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    true_attr_label = np.zeros(len(abide_name), dtype=int)\n",
    "    true_attr_index = np.arange(len(abide_name))\n",
    "    true_attr_index = np.random.choice(true_attr_index,\n",
    "                                       num_true_vars,\n",
    "                                       replace=False)\n",
    "    true_names = np.take(abide_name,\n",
    "                         true_attr_index)  # this is a list for true names\n",
    "    true_names = convert2list(true_names)\n",
    "    true_attr_label[\n",
    "        true_attr_index] = 1  # true_attr_label is binary indicate whether the covaraite is \"true\"\n",
    "\n",
    "    true_beta = np.random.choice([1., -1.], num_true_vars, replace=True)\n",
    "    #     true_beta = np.random.uniform(low=.5, high=.6,\n",
    "    #                                   size=num_true_vars) * np.random.choice(\n",
    "    #                                       [1., -1.], num_true_vars, replace=True)\n",
    "\n",
    "    sim_data = abide[true_names].to_numpy(copy=True)\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    sim_data = sim_data**2\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    signal = sim_data @ true_beta\n",
    "    signal -= np.mean(\n",
    "        signal\n",
    "    )  # make sure it's centered at 0 to avoid generated data all be in one class\n",
    "    signal /= np.std(signal)  # avoid the case if the data is too centered\n",
    "    # this is to make the data centered at the point with highest curvature to archive most nonlinearity\n",
    "    signal += np.arctanh((1. / 3)**.5)\n",
    "\n",
    "    outcome = np.random.binomial(1, np.tanh(signal / 2) / 2 + .5)  # logistic\n",
    "    # outcome = np.random.binomial(1,\n",
    "    #                              np.arcsin(np.sqrt(signal + np.min(signal))) /\n",
    "    #                              (np.pi / 2.))  # arcsin(sqrt(.))\n",
    "\n",
    "    abide[\"outcome\"] = outcome\n",
    "    abide = abide[[\"outcome\"] + abide_name]\n",
    "\n",
    "    print(\"The outcome is binary.\")\n",
    "\n",
    "    print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "    try:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"ISJ\")\n",
    "    except:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"silverman\")\n",
    "\n",
    "    print(\"Our developed binning MI calculation:\")\n",
    "\n",
    "    binning_mi_output = mi.binning_binary_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"sklearn MI calculation:\")\n",
    "\n",
    "    skmi_output = mi.binary_skMI_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        random_state=0,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "    pearson_output = mi.Pearson_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    mi_pseudo_prob = np.abs(mi_output) / np.max(np.abs(mi_output))\n",
    "    mi_auroc = roc_auc_score(true_attr_label, mi_pseudo_prob)\n",
    "    binning_mi_pseudo_prob = np.abs(binning_mi_output) / np.max(\n",
    "        np.abs(binning_mi_output))\n",
    "    binning_mi_auroc = roc_auc_score(true_attr_label, binning_mi_pseudo_prob)\n",
    "    skmi_pseudo_prob = np.abs(skmi_output) / np.max(np.abs(skmi_output))\n",
    "    skmi_auroc = roc_auc_score(true_attr_label, skmi_pseudo_prob)\n",
    "    pearson_pseudo_prob = np.abs(pearson_output) / np.max(\n",
    "        np.abs(pearson_output))\n",
    "    pearson_auroc = roc_auc_score(true_attr_label, pearson_pseudo_prob)\n",
    "\n",
    "    del mi_output, binning_mi_output, skmi_output, pearson_output, abide, abide_name, true_names, true_beta, sim_data, signal, outcome, mi_pseudo_prob, skmi_pseudo_prob, pearson_pseudo_prob\n",
    "\n",
    "    return np.array([mi_auroc, skmi_auroc, pearson_auroc, binning_mi_auroc])\n",
    "\n",
    "\n",
    "num_true_vars_list = [{_num_true_vars_iter}]\n",
    "seed_list = range(100)\n",
    "\n",
    "itrs = itertools.product(num_true_vars_list, seed_list)\n",
    "\n",
    "output_array = np.array(list(map(sim_based_on_abide_binary, tqdm(itrs))))\n",
    "output_array = output_array.reshape(1, 100, 4).squeeze()\n",
    "np.save(r\"./ABIDE_{_outcome}_{_num_true_vars_iter}\", output_array)\n",
    "\"\"\".format(_num_true_vars_iter=num_true_vars_iter, _outcome=outcome)\n",
    "\n",
    "    Path(r\"./ABIDE_simulations_nonlinear/ABIDE_sim_\" + outcome +\n",
    "         r\"_{_num_true_vars_iter}\".format(\n",
    "             _num_true_vars_iter=num_true_vars_iter) + \".py\").touch()\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_simulations_nonlinear/ABIDE_sim_\" + outcome +\n",
    "        r\"_{_num_true_vars_iter}\".format(\n",
    "            _num_true_vars_iter=num_true_vars_iter) + \".py\", \"w\")\n",
    "    py_script.write(py_1 + py_2)\n",
    "\n",
    "    Path(r\"./ABIDE_simulations_nonlinear/ABIDE_sim_\" + outcome +\n",
    "         r\"_{_num_true_vars_iter}\".format(\n",
    "             _num_true_vars_iter=num_true_vars_iter) + \".sh\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_simulations_nonlinear/ABIDE_sim_\" + outcome +\n",
    "        r\"_{_num_true_vars_iter}\".format(\n",
    "            _num_true_vars_iter=num_true_vars_iter) + \".sh\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=32\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name={outcome}_{_num_true_vars_iter}\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_sim_{outcome}_{_num_true_vars_iter}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_sim_{outcome}_{_num_true_vars_iter}.py\n",
    "\"\"\".format(outcome=outcome, _num_true_vars_iter=num_true_vars_iter))\n",
    "\n",
    "\n",
    "num_true_vars_list = list(map(int, np.linspace(0, 200,\n",
    "                                               6)))[1:]  # we don't want 0 here\n",
    "\n",
    "for outcome in [\"continuous\", \"binary_original\", \"binary_translated\"]:\n",
    "    for num_true_vars_iter in num_true_vars_list:\n",
    "        job_generator(outcome=outcome, num_true_vars_iter=num_true_vars_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1d344",
   "metadata": {},
   "source": [
    "### simulating *linear* outcomes/predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46b12ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:13.761766Z",
     "start_time": "2023-12-23T21:19:13.736247Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_generator(outcome, num_true_vars_iter):\n",
    "    py_1 = r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# read the data\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "\n",
    "abide_original = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "_abide_name = abide_original.columns.tolist()[1:]\n",
    "\n",
    "# print(_abide_name)\n",
    "\n",
    "abide_name_original = _abide_name[1:-3]\n",
    "\n",
    "# preserve only the neuro-imaging data\n",
    "abide_original = abide_original[abide_name_original]\n",
    "\n",
    "def convert2list(a):\n",
    "    b = np.asarray(a)\n",
    "    return b.tolist()\n",
    "\"\"\"\n",
    "    if outcome == \"continuous\":\n",
    "        py_2 = r\"\"\"\n",
    "def sim_based_on_abide_continuous(pair):\n",
    "    abide, abide_name = abide_original.copy(), abide_name_original.copy()\n",
    "    _num_true_vars, _seed = pair\n",
    "    SNR = 3.\n",
    "    num_true_vars = _num_true_vars\n",
    "    seed = _seed\n",
    "    assert num_true_vars < len(abide_name)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    true_attr_label = np.zeros(len(abide_name), dtype=int)\n",
    "    true_attr_index = np.arange(len(abide_name))\n",
    "    true_attr_index = np.random.choice(true_attr_index,\n",
    "                                       num_true_vars,\n",
    "                                       replace=False)\n",
    "    true_names = np.take(abide_name,\n",
    "                         true_attr_index)  # this is a list for true names\n",
    "    true_names = convert2list(true_names)\n",
    "    true_attr_label[\n",
    "        true_attr_index] = 1  # true_attr_label is binary indicate whether the covaraite is \"true\"\n",
    "\n",
    "    true_beta = np.random.choice([1., -1.], num_true_vars, replace=True)\n",
    "    #     true_beta = np.random.uniform(low=5.0, high=6.0,\n",
    "    #                                   size=num_true_vars) * np.random.choice(\n",
    "    #                                       [1., -1.], num_true_vars, replace=True)\n",
    "\n",
    "    sim_data = abide[true_names].to_numpy(copy=True)\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "\n",
    "    X_cov = np.corrcoef(sim_data, rowvar=False)\n",
    "    true_sigma_sim = np.sqrt(true_beta.T @ X_cov @ true_beta / SNR)\n",
    "\n",
    "    outcome = sim_data @ true_beta + np.random.normal(0, true_sigma_sim,\n",
    "                                                      sim_data.shape[0])\n",
    "\n",
    "    abide[\"outcome\"] = outcome\n",
    "    abide = abide[[\"outcome\"] + abide_name]\n",
    "\n",
    "    print(\"The outcome is continuous.\")\n",
    "\n",
    "    print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "    try:\n",
    "        mi_output = mi.continuous_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"ISJ\",\n",
    "            norm=2)\n",
    "    except:\n",
    "        mi_output = mi.continuous_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"silverman\",\n",
    "            norm=2)\n",
    "    \n",
    "    print(\"Our developed binning MI calculation:\")\n",
    "\n",
    "    binning_mi_output = mi.binning_continuous_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"sklearn MI calculation:\")\n",
    "\n",
    "    skmi_output = mi.continuous_skMI_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        random_state=0,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "    pearson_output = mi.Pearson_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    mi_pseudo_prob = np.abs(mi_output) / np.max(np.abs(mi_output))\n",
    "    mi_auroc = roc_auc_score(true_attr_label, mi_pseudo_prob)\n",
    "    binning_mi_pseudo_prob = np.abs(binning_mi_output) / np.max(\n",
    "        np.abs(binning_mi_output))\n",
    "    binning_mi_auroc = roc_auc_score(true_attr_label, binning_mi_pseudo_prob)\n",
    "    skmi_pseudo_prob = np.abs(skmi_output) / np.max(np.abs(skmi_output))\n",
    "    skmi_auroc = roc_auc_score(true_attr_label, skmi_pseudo_prob)\n",
    "    pearson_pseudo_prob = np.abs(pearson_output) / np.max(\n",
    "        np.abs(pearson_output))\n",
    "    pearson_auroc = roc_auc_score(true_attr_label, pearson_pseudo_prob)\n",
    "\n",
    "    del mi_output,binning_mi_output, skmi_output, pearson_output, abide, abide_name, true_names, true_beta, sim_data, X_cov, true_sigma_sim, outcome, mi_pseudo_prob, skmi_pseudo_prob, pearson_pseudo_prob\n",
    "\n",
    "    return np.array([mi_auroc, skmi_auroc, pearson_auroc, binning_mi_auroc])\n",
    "\n",
    "\n",
    "num_true_vars_list = [{_num_true_vars_iter}]\n",
    "seed_list = range(100)\n",
    "\n",
    "itrs = itertools.product(num_true_vars_list, seed_list)\n",
    "\n",
    "output_array = np.array(list(map(sim_based_on_abide_continuous, tqdm(itrs))))\n",
    "output_array = output_array.reshape(1, 100, 4).squeeze()\n",
    "np.save(r\"./ABIDE_{_outcome}_{_num_true_vars_iter}\", output_array)\n",
    "\"\"\".format(_num_true_vars_iter=num_true_vars_iter, _outcome=outcome)\n",
    "    elif outcome == \"binary_original\":\n",
    "        py_2 = r\"\"\"\n",
    "def sim_based_on_abide_binary(pair):\n",
    "    abide, abide_name = abide_original.copy(), abide_name_original.copy()\n",
    "    _num_true_vars, _seed = pair\n",
    "    num_true_vars = _num_true_vars\n",
    "    seed = _seed\n",
    "    assert num_true_vars < len(abide_name)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    true_attr_label = np.zeros(len(abide_name), dtype=int)\n",
    "    true_attr_index = np.arange(len(abide_name))\n",
    "    true_attr_index = np.random.choice(true_attr_index,\n",
    "                                       num_true_vars,\n",
    "                                       replace=False)\n",
    "    true_names = np.take(abide_name,\n",
    "                         true_attr_index)  # this is a list for true names\n",
    "    true_names = convert2list(true_names)\n",
    "    true_attr_label[\n",
    "        true_attr_index] = 1  # true_attr_label is binary indicate whether the covaraite is \"true\"\n",
    "\n",
    "    true_beta = np.random.choice([1., -1.], num_true_vars, replace=True)\n",
    "    #     true_beta = np.random.uniform(low=.5, high=.6,\n",
    "    #                                   size=num_true_vars) * np.random.choice(\n",
    "    #                                       [1., -1.], num_true_vars, replace=True)\n",
    "\n",
    "    sim_data = abide[true_names].to_numpy(copy=True)\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    signal = sim_data @ true_beta\n",
    "    signal -= np.mean(\n",
    "        signal\n",
    "    )  # make sure it's centered at 0 to avoid generated data all be in one class\n",
    "    signal /= np.std(signal)  # avoid the case if the data is too centered\n",
    "\n",
    "    outcome = np.random.binomial(1, np.tanh(signal / 2) / 2 + .5) # logistic\n",
    "    # outcome = np.random.binomial(1,\n",
    "    #                              np.arcsin(np.sqrt(signal + np.min(signal))) /\n",
    "    #                              (np.pi / 2.))  # arcsin(sqrt(.))\n",
    "\n",
    "    abide[\"outcome\"] = outcome\n",
    "    abide = abide[[\"outcome\"] + abide_name]\n",
    "\n",
    "    print(\"The outcome is binary.\")\n",
    "\n",
    "    print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "    try:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"ISJ\")\n",
    "    except:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"silverman\")\n",
    "\n",
    "    print(\"Our developed binning MI calculation:\")\n",
    "\n",
    "    binning_mi_output = mi.binning_binary_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"sklearn MI calculation:\")\n",
    "\n",
    "    skmi_output = mi.binary_skMI_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        random_state=0,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "    pearson_output = mi.Pearson_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    mi_pseudo_prob = np.abs(mi_output) / np.max(np.abs(mi_output))\n",
    "    mi_auroc = roc_auc_score(true_attr_label, mi_pseudo_prob)\n",
    "    binning_mi_pseudo_prob = np.abs(binning_mi_output) / np.max(\n",
    "        np.abs(binning_mi_output))\n",
    "    binning_mi_auroc = roc_auc_score(true_attr_label, binning_mi_pseudo_prob)\n",
    "    skmi_pseudo_prob = np.abs(skmi_output) / np.max(np.abs(skmi_output))\n",
    "    skmi_auroc = roc_auc_score(true_attr_label, skmi_pseudo_prob)\n",
    "    pearson_pseudo_prob = np.abs(pearson_output) / np.max(\n",
    "        np.abs(pearson_output))\n",
    "    pearson_auroc = roc_auc_score(true_attr_label, pearson_pseudo_prob)\n",
    "\n",
    "    del mi_output,binning_mi_output, skmi_output, pearson_output, abide, abide_name, true_names, true_beta, sim_data, signal, outcome, mi_pseudo_prob, skmi_pseudo_prob, pearson_pseudo_prob\n",
    "\n",
    "    return np.array([mi_auroc, skmi_auroc, pearson_auroc, binning_mi_auroc])\n",
    "\n",
    "\n",
    "num_true_vars_list = [{_num_true_vars_iter}]\n",
    "seed_list = range(100)\n",
    "\n",
    "itrs = itertools.product(num_true_vars_list, seed_list)\n",
    "\n",
    "output_array = np.array(list(map(sim_based_on_abide_binary, tqdm(itrs))))\n",
    "output_array = output_array.reshape(1, 100, 4).squeeze()\n",
    "np.save(r\"./ABIDE_{_outcome}_{_num_true_vars_iter}\", output_array)\n",
    "\"\"\".format(_num_true_vars_iter=num_true_vars_iter, _outcome=outcome)\n",
    "\n",
    "    elif outcome == \"binary_translated\":\n",
    "        py_2 = r\"\"\"\n",
    "def sim_based_on_abide_binary(pair):\n",
    "    abide, abide_name = abide_original.copy(), abide_name_original.copy()\n",
    "    _num_true_vars, _seed = pair\n",
    "    num_true_vars = _num_true_vars\n",
    "    seed = _seed\n",
    "    assert num_true_vars < len(abide_name)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    true_attr_label = np.zeros(len(abide_name), dtype=int)\n",
    "    true_attr_index = np.arange(len(abide_name))\n",
    "    true_attr_index = np.random.choice(true_attr_index,\n",
    "                                       num_true_vars,\n",
    "                                       replace=False)\n",
    "    true_names = np.take(abide_name,\n",
    "                         true_attr_index)  # this is a list for true names\n",
    "    true_names = convert2list(true_names)\n",
    "    true_attr_label[\n",
    "        true_attr_index] = 1  # true_attr_label is binary indicate whether the covaraite is \"true\"\n",
    "\n",
    "    true_beta = np.random.choice([1., -1.], num_true_vars, replace=True)\n",
    "    #     true_beta = np.random.uniform(low=.5, high=.6,\n",
    "    #                                   size=num_true_vars) * np.random.choice(\n",
    "    #                                       [1., -1.], num_true_vars, replace=True)\n",
    "\n",
    "    sim_data = abide[true_names].to_numpy(copy=True)\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    signal = sim_data @ true_beta\n",
    "    signal -= np.mean(\n",
    "        signal\n",
    "    )  # make sure it's centered at 0 to avoid generated data all be in one class\n",
    "    signal /= np.std(signal)  # avoid the case if the data is too centered\n",
    "    signal += np.arctanh((1./3)**.5) # this is to make the data centered at the point with highest curvature to archive most nonlinearity\n",
    "\n",
    "    outcome = np.random.binomial(1, np.tanh(signal / 2) / 2 + .5) # logistic\n",
    "    # outcome = np.random.binomial(1,\n",
    "    #                              np.arcsin(np.sqrt(signal + np.min(signal))) /\n",
    "    #                              (np.pi / 2.))  # arcsin(sqrt(.))\n",
    "\n",
    "    abide[\"outcome\"] = outcome\n",
    "    abide = abide[[\"outcome\"] + abide_name]\n",
    "\n",
    "    print(\"The outcome is binary.\")\n",
    "\n",
    "    print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "    try:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"ISJ\")\n",
    "    except:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"silverman\")\n",
    "\n",
    "    print(\"Our developed binning MI calculation:\")\n",
    "\n",
    "    binning_mi_output = mi.binning_binary_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"sklearn MI calculation:\")\n",
    "\n",
    "    skmi_output = mi.binary_skMI_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        random_state=0,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "    pearson_output = mi.Pearson_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    mi_pseudo_prob = np.abs(mi_output) / np.max(np.abs(mi_output))\n",
    "    mi_auroc = roc_auc_score(true_attr_label, mi_pseudo_prob)\n",
    "    binning_mi_pseudo_prob = np.abs(binning_mi_output) / np.max(\n",
    "        np.abs(binning_mi_output))\n",
    "    binning_mi_auroc = roc_auc_score(true_attr_label, binning_mi_pseudo_prob)\n",
    "    skmi_pseudo_prob = np.abs(skmi_output) / np.max(np.abs(skmi_output))\n",
    "    skmi_auroc = roc_auc_score(true_attr_label, skmi_pseudo_prob)\n",
    "    pearson_pseudo_prob = np.abs(pearson_output) / np.max(\n",
    "        np.abs(pearson_output))\n",
    "    pearson_auroc = roc_auc_score(true_attr_label, pearson_pseudo_prob)\n",
    "\n",
    "    del mi_output, binning_mi_output, skmi_output, pearson_output, abide, abide_name, true_names, true_beta, sim_data, signal, outcome, mi_pseudo_prob, skmi_pseudo_prob, pearson_pseudo_prob\n",
    "\n",
    "    return np.array([mi_auroc, skmi_auroc, pearson_auroc, binning_mi_auroc])\n",
    "\n",
    "\n",
    "num_true_vars_list = [{_num_true_vars_iter}]\n",
    "seed_list = range(100)\n",
    "\n",
    "itrs = itertools.product(num_true_vars_list, seed_list)\n",
    "\n",
    "output_array = np.array(list(map(sim_based_on_abide_binary, tqdm(itrs))))\n",
    "output_array = output_array.reshape(1, 100, 4).squeeze()\n",
    "np.save(r\"./ABIDE_{_outcome}_{_num_true_vars_iter}\", output_array)\n",
    "\"\"\".format(_num_true_vars_iter=num_true_vars_iter, _outcome=outcome)\n",
    "\n",
    "    Path(r\"./ABIDE_simulations_linear/ABIDE_sim_\" + outcome +\n",
    "         r\"_{_num_true_vars_iter}\".format(\n",
    "             _num_true_vars_iter=num_true_vars_iter) + \".py\").touch()\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_simulations_linear/ABIDE_sim_\" + outcome +\n",
    "        r\"_{_num_true_vars_iter}\".format(\n",
    "            _num_true_vars_iter=num_true_vars_iter) + \".py\", \"w\")\n",
    "    py_script.write(py_1 + py_2)\n",
    "\n",
    "    Path(r\"./ABIDE_simulations_linear/ABIDE_sim_\" + outcome +\n",
    "         r\"_{_num_true_vars_iter}\".format(\n",
    "             _num_true_vars_iter=num_true_vars_iter) + \".sh\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_simulations_linear/ABIDE_sim_\" + outcome +\n",
    "        r\"_{_num_true_vars_iter}\".format(\n",
    "            _num_true_vars_iter=num_true_vars_iter) + \".sh\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-cgreenwo\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=32\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name={outcome}_{_num_true_vars_iter}\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_sim_{outcome}_{_num_true_vars_iter}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_sim_{outcome}_{_num_true_vars_iter}.py\n",
    "\"\"\".format(outcome=outcome, _num_true_vars_iter=num_true_vars_iter))\n",
    "\n",
    "\n",
    "num_true_vars_list = list(map(int, np.linspace(0, 200,\n",
    "                                               6)))[1:]  # we don't want 0 here\n",
    "\n",
    "for outcome in [\"continuous\", \"binary_original\", \"binary_translated\"]:\n",
    "    for num_true_vars_iter in num_true_vars_list:\n",
    "        job_generator(outcome=outcome, num_true_vars_iter=num_true_vars_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5dba2",
   "metadata": {},
   "source": [
    "## Plots for Simulation study\n",
    "### For simulated nonlinear outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e6222c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:14.419653Z",
     "start_time": "2023-12-23T21:19:13.762718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_continuous_40.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_continuous_80.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_continuous_120.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_continuous_160.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_continuous_200.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_original_40.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_original_80.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_original_120.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_original_160.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_original_200.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_translated_40.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_translated_80.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_translated_120.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_translated_160.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_nonlinear/ABIDE_binary_translated_200.npy, doesn't exist\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mean = np.zeros((len(num_true_vars_list), 4))\n",
    "plot_se = np.zeros((len(num_true_vars_list), 4))\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(5, 8), sharex=True)\n",
    "\n",
    "k = 0\n",
    "for outcome in [\"continuous\", \"binary_original\", \"binary_translated\"]:\n",
    "    j = 0\n",
    "    for num_true_vars_iter in num_true_vars_list:\n",
    "        try:\n",
    "            computing_results = np.load(\n",
    "                r\"./ABIDE_simulations_nonlinear/ABIDE_{_outcome}_{_num_true_vars_iter}.npy\"\n",
    "                .format(_outcome=outcome,\n",
    "                        _num_true_vars_iter=num_true_vars_iter))\n",
    "            plot_mean[j, :] = np.mean(computing_results, axis=0)\n",
    "            plot_se[j, :] = np.std(computing_results, axis=0)\n",
    "        except:\n",
    "            print(\n",
    "                r\"The data file, ./ABIDE_simulations_nonlinear/ABIDE_{_outcome}_{_num_true_vars_iter}.npy, doesn't exist\"\n",
    "                .format(_outcome=outcome,\n",
    "                        _num_true_vars_iter=num_true_vars_iter))\n",
    "            plot_mean[j, :] = np.nan\n",
    "            plot_se[j, :] = np.nan\n",
    "        j += 1\n",
    "\n",
    "    ax[k].plot(num_true_vars_list,\n",
    "               plot_mean[:, 0],\n",
    "               label=\"$\\widehat{MI}$ based on FFTKDE\",\n",
    "               linestyle=\"-\",\n",
    "               color=\"b\")\n",
    "    ax[k].fill_between(num_true_vars_list,\n",
    "                       (plot_mean[:, 0] + plot_se[:, 0] * norm.ppf(0.025)),\n",
    "                       (plot_mean[:, 0] + plot_se[:, 0] * norm.ppf(0.975)),\n",
    "                       color=\"b\",\n",
    "                       alpha=.1)\n",
    "\n",
    "    ax[k].plot(num_true_vars_list,\n",
    "               plot_mean[:, 1],\n",
    "               label=\"$\\widehat{MI}$ based on sklearn\",\n",
    "               linestyle=\"-.\",\n",
    "               color=\"y\")\n",
    "    ax[k].fill_between(num_true_vars_list,\n",
    "                       (plot_mean[:, 1] + plot_se[:, 1] * norm.ppf(0.025)),\n",
    "                       (plot_mean[:, 1] + plot_se[:, 1] * norm.ppf(0.975)),\n",
    "                       color=\"y\",\n",
    "                       alpha=.1)\n",
    "\n",
    "    ax[k].plot(num_true_vars_list,\n",
    "               plot_mean[:, 2],\n",
    "               label=\"Pearson's correlation\",\n",
    "               linestyle=\"--\",\n",
    "               color=\"g\")\n",
    "    ax[k].fill_between(num_true_vars_list,\n",
    "                       (plot_mean[:, 2] + plot_se[:, 2] * norm.ppf(0.025)),\n",
    "                       (plot_mean[:, 2] + plot_se[:, 2] * norm.ppf(0.975)),\n",
    "                       color=\"g\",\n",
    "                       alpha=.1)\n",
    "\n",
    "    ax[k].plot(num_true_vars_list,\n",
    "               plot_mean[:, 3],\n",
    "               label=\"$\\widehat{MI}$ based on binning\",\n",
    "               linestyle=\"-\",\n",
    "               color=\"r\")\n",
    "    ax[k].fill_between(num_true_vars_list,\n",
    "                       (plot_mean[:, 3] + plot_se[:, 3] * norm.ppf(0.025)),\n",
    "                       (plot_mean[:, 3] + plot_se[:, 3] * norm.ppf(0.975)),\n",
    "                       color=\"r\",\n",
    "                       alpha=.1)\n",
    "    \n",
    "    ax[k].set_title(r\"Simulation study for: \" + outcome)\n",
    "    ax[k].label_outer()\n",
    "    k += 1\n",
    "\n",
    "# Adjust the right margin to make room for the legend\n",
    "fig.subplots_adjust(right=0.85)\n",
    "\n",
    "# Set centralized labels and legend\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "fig.supxlabel(r'Number of \"True\" Covariates')\n",
    "fig.supylabel(r'Variable Selection AUROC')\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"./ABIDE_simulations_nonlinear/sim_nonlinear_combined.pdf\",\n",
    "            format=\"pdf\",\n",
    "            dpi=600,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b620c",
   "metadata": {},
   "source": [
    "### For simulated linear outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474bcbf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:14.890383Z",
     "start_time": "2023-12-23T21:19:14.420616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data file, ./ABIDE_simulations_linear/ABIDE_continuous_40.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_continuous_80.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_continuous_120.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_continuous_160.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_continuous_200.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_original_40.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_original_80.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_original_120.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_original_160.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_original_200.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_translated_40.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_translated_80.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_translated_120.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_translated_160.npy, doesn't exist\n",
      "The data file, ./ABIDE_simulations_linear/ABIDE_binary_translated_200.npy, doesn't exist\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mean = np.zeros((len(num_true_vars_list), 4))\n",
    "plot_se = np.zeros((len(num_true_vars_list), 4))\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(5, 8), sharex=True)\n",
    "\n",
    "k = 0\n",
    "for outcome in [\"continuous\", \"binary_original\", \"binary_translated\"]:\n",
    "    j = 0\n",
    "    for num_true_vars_iter in num_true_vars_list:\n",
    "        try:\n",
    "            computing_results = np.load(\n",
    "                r\"./ABIDE_simulations_linear/ABIDE_{_outcome}_{_num_true_vars_iter}.npy\"\n",
    "                .format(_outcome=outcome,\n",
    "                        _num_true_vars_iter=num_true_vars_iter))\n",
    "            plot_mean[j, :] = np.mean(computing_results, axis=0)\n",
    "            plot_se[j, :] = np.std(computing_results, axis=0)\n",
    "        except:\n",
    "            print(\n",
    "                r\"The data file, ./ABIDE_simulations_linear/ABIDE_{_outcome}_{_num_true_vars_iter}.npy, doesn't exist\"\n",
    "                .format(_outcome=outcome,\n",
    "                        _num_true_vars_iter=num_true_vars_iter))\n",
    "            plot_mean[j, :] = np.nan\n",
    "            plot_se[j, :] = np.nan\n",
    "        j += 1\n",
    "\n",
    "    ax[k].plot(num_true_vars_list,\n",
    "               plot_mean[:, 0],\n",
    "               label=\"$\\widehat{MI}$ based on FFTKDE\",\n",
    "               linestyle=\"-\",\n",
    "               color=\"b\")\n",
    "    ax[k].fill_between(num_true_vars_list,\n",
    "                       (plot_mean[:, 0] + plot_se[:, 0] * norm.ppf(0.025)),\n",
    "                       (plot_mean[:, 0] + plot_se[:, 0] * norm.ppf(0.975)),\n",
    "                       color=\"b\",\n",
    "                       alpha=.1)\n",
    "\n",
    "    ax[k].plot(num_true_vars_list,\n",
    "               plot_mean[:, 1],\n",
    "               label=\"$\\widehat{MI}$ based on sklearn\",\n",
    "               linestyle=\"-.\",\n",
    "               color=\"y\")\n",
    "    ax[k].fill_between(num_true_vars_list,\n",
    "                       (plot_mean[:, 1] + plot_se[:, 1] * norm.ppf(0.025)),\n",
    "                       (plot_mean[:, 1] + plot_se[:, 1] * norm.ppf(0.975)),\n",
    "                       color=\"y\",\n",
    "                       alpha=.1)\n",
    "\n",
    "    ax[k].plot(num_true_vars_list,\n",
    "               plot_mean[:, 2],\n",
    "               label=\"Pearson's correlation\",\n",
    "               linestyle=\"--\",\n",
    "               color=\"g\")\n",
    "    ax[k].fill_between(num_true_vars_list,\n",
    "                       (plot_mean[:, 2] + plot_se[:, 2] * norm.ppf(0.025)),\n",
    "                       (plot_mean[:, 2] + plot_se[:, 2] * norm.ppf(0.975)),\n",
    "                       color=\"g\",\n",
    "                       alpha=.1)\n",
    "\n",
    "    ax[k].plot(num_true_vars_list,\n",
    "               plot_mean[:, 3],\n",
    "               label=\"$\\widehat{MI}$ based on binning\",\n",
    "               linestyle=\"-\",\n",
    "               color=\"r\")\n",
    "    ax[k].fill_between(num_true_vars_list,\n",
    "                       (plot_mean[:, 3] + plot_se[:, 3] * norm.ppf(0.025)),\n",
    "                       (plot_mean[:, 3] + plot_se[:, 3] * norm.ppf(0.975)),\n",
    "                       color=\"r\",\n",
    "                       alpha=.1)\n",
    "    \n",
    "    ax[k].set_title(r\"Simulation study for: \" + outcome)\n",
    "    ax[k].label_outer()\n",
    "    k += 1\n",
    "\n",
    "# Adjust the right margin to make room for the legend\n",
    "fig.subplots_adjust(right=0.85)\n",
    "\n",
    "# Set centralized labels and legend\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "fig.supxlabel(r'Number of \"True\" Covariates')\n",
    "fig.supylabel(r'Variable Selection AUROC')\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"./ABIDE_simulations_linear/sim_linear_combined.pdf\",\n",
    "            format=\"pdf\",\n",
    "            dpi=600,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74af34a",
   "metadata": {},
   "source": [
    "# Calculate MI for ABIDE data age and diagnosis outcome\n",
    "## creating job submission scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75940522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:14.896729Z",
     "start_time": "2023-12-23T21:19:14.891428Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def engine_and_share_memory_status(mem_setting):\n",
    "    if mem_setting == \"high_mem\":\n",
    "        return \"c\", False\n",
    "    elif mem_setting == \"share_mem\":\n",
    "        return \"c\", True\n",
    "    elif mem_setting == \"dask\":\n",
    "        return \"dask\", False\n",
    "\n",
    "\n",
    "def job_generator(mem_setting, outcome):\n",
    "    py_1 = r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "    if outcome == \"age\":\n",
    "        py_2 = r\"\"\"\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv\"\n",
    "abide = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "# abide = dd.read_csv(csv_file, sample=1250000)\n",
    "\n",
    "_abide_name = abide.columns.tolist()[1:]\n",
    "# _abide_name = list(abide.columns)[1:]\n",
    "\n",
    "# print(_abide_name)\n",
    "\n",
    "# we don't inlcude covariates for adjustment in the screening since we choose to always include them in the model\n",
    "\n",
    "abide_name = [_abide_name[-3]] + _abide_name[1:-3]\n",
    "# so that the left first column is the outcome and the rest columns are areas\n",
    "\n",
    "np.save(r\"./ABIDE_columns\", _abide_name[1:-3])\n",
    "\n",
    "del _abide_name\n",
    "\n",
    "print(\"The outcome is age.\")\n",
    "print(\n",
    "    \"Now running using {_csv_engine} CSV engine with share_memory={_share_mem_status}.\"\n",
    ")\n",
    "print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        try:\n",
    "            mi_output = mi.continuous_screening_csv_parallel(\n",
    "                csv_file,\n",
    "                _usecols=abide_name.copy(),\n",
    "                csv_engine=\"{_csv_engine}\",\n",
    "                sample=1250000,\n",
    "                multp=10,\n",
    "                core_num=16,\n",
    "                share_memory={_share_mem_status},\n",
    "                kernel=_kernel,\n",
    "                bw=_bw,\n",
    "                norm=2)\n",
    "            if \"{mem_setting}\" == \"high_mem\":\n",
    "                np.save(\n",
    "                    r\"./ABIDE_age_MI_{{kernel}}_{{bw}}_output\".format(\n",
    "                        kernel=_kernel, bw=_bw), mi_output)\n",
    "\n",
    "            del mi_output\n",
    "\n",
    "        except:\n",
    "            print(\"This kernel-bw combination reports an error: \", _kernel,\n",
    "                  _bw)\n",
    "\n",
    "print(\"binning MI calculation:\")\n",
    "\n",
    "binning_output = mi.binning_continuous_screening_dataframe_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_age_binning_output\", binning_output)\n",
    "\n",
    "print(\"sklearn MI calculation:\")\n",
    "\n",
    "skmi_output = mi.continuous_skMI_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    random_state=0,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_age_skMI_output\", skmi_output)\n",
    "\n",
    "del skmi_output\n",
    "\n",
    "print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "pearson_output = mi.Pearson_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_age_Pearson_output\", pearson_output)\n",
    "\n",
    "del pearson_output\n",
    "\"\"\".format(_csv_engine=engine_and_share_memory_status(mem_setting)[0],\n",
    "           _share_mem_status=engine_and_share_memory_status(mem_setting)[1],\n",
    "           mem_setting=mem_setting)\n",
    "    elif outcome == \"diagnosis\":\n",
    "        py_2 = r\"\"\"\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "abide = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "# abide = dd.read_csv(csv_file, sample=1250000)\n",
    "\n",
    "_abide_name = abide.columns.tolist()[1:]\n",
    "# _abide_name = list(abide.columns)[1:]\n",
    "\n",
    "# print(_abide_name)\n",
    "\n",
    "# we don't inlcude covariates for adjustment in the screening since we choose to always include them in the model\n",
    "\n",
    "abide_name = [_abide_name[-1]] + _abide_name[1:-3]\n",
    "# so that the left first column is the outcome and the rest columns are areas\n",
    "\n",
    "del _abide_name\n",
    "\n",
    "print(\"The outcome is diagnosis.\")\n",
    "print(\n",
    "    \"Now running using {_csv_engine} CSV engine with share_memory={_share_mem_status}.\"\n",
    ")\n",
    "print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        try:\n",
    "            mi_output = mi.binary_screening_csv_parallel(\n",
    "                csv_file,\n",
    "                _usecols=abide_name.copy(),\n",
    "                csv_engine=\"{_csv_engine}\",\n",
    "                sample=1250000,\n",
    "                multp=10,\n",
    "                core_num=16,\n",
    "                share_memory={_share_mem_status},\n",
    "                kernel=_kernel,\n",
    "                bw=_bw)\n",
    "            if \"{mem_setting}\" == \"high_mem\":\n",
    "                np.save(\n",
    "                    r\"./ABIDE_diagnosis_MI_{{kernel}}_{{bw}}_output\".format(\n",
    "                        kernel=_kernel, bw=_bw), mi_output)\n",
    "\n",
    "            del mi_output\n",
    "\n",
    "        except:\n",
    "            print(\"This kernel-bw combination reports an error: \", _kernel,\n",
    "                  _bw)\n",
    "\n",
    "print(\"binning MI calculation:\")\n",
    "\n",
    "binning_output = mi.binning_binary_screening_dataframe_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_diagnosis_binning_output\", binning_output)\n",
    "\n",
    "print(\"sklearn MI calculation:\")\n",
    "\n",
    "skmi_output = mi.binary_skMI_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    random_state=0,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_diagnosis_skMI_output\", skmi_output)\n",
    "\n",
    "del skmi_output\n",
    "\n",
    "print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "pearson_output = mi.Pearson_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_diagnosis_Pearson_output\", pearson_output)\n",
    "\n",
    "del pearson_output\n",
    "\"\"\".format(_csv_engine=engine_and_share_memory_status(mem_setting)[0],\n",
    "           _share_mem_status=engine_and_share_memory_status(mem_setting)[1],\n",
    "           mem_setting=mem_setting)\n",
    "\n",
    "    Path(r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".py\").touch()\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".py\", \"w\")\n",
    "    py_script.write(py_1 + py_2)\n",
    "\n",
    "    Path(r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".sh\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".sh\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=20:00:00\n",
    "#SBATCH --job-name=ABIDE_screening_{outcome}_{mem_setting}\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_screening_{outcome}_{mem_setting}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_screening_{outcome}_{mem_setting}.py\n",
    "\"\"\".format(outcome=outcome, mem_setting=mem_setting))\n",
    "\n",
    "\n",
    "for mem_setting in [\"high_mem\", \"share_mem\", \"dask\"]:\n",
    "    for outcome in [\"age\", \"diagnosis\"]:\n",
    "        job_generator(mem_setting=mem_setting, outcome=outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770cd5c3",
   "metadata": {},
   "source": [
    "# Running Speed Comparison for MI Estimation -- I AM HERE TO ADD BINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464db6ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:14.922177Z",
     "start_time": "2023-12-23T21:19:14.897402Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def engine_and_share_memory_status(mem_setting):\n",
    "    if mem_setting == \"high_mem\":\n",
    "        return \"c\", False\n",
    "    elif mem_setting == \"share_mem\":\n",
    "        return \"c\", True\n",
    "    elif mem_setting == \"dask\":\n",
    "        return \"dask\", False\n",
    "\n",
    "\n",
    "def job_generator(mem_setting, outcome):\n",
    "    py_1 = r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "abide = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "# abide = dd.read_csv(csv_file, sample=1250000)\n",
    "\n",
    "_abide_name = abide.columns.tolist()[1:]\n",
    "# _abide_name = list(abide.columns)[1:]\n",
    "\n",
    "# print(_abide_name)\n",
    "\n",
    "# we don't inlcude age and sex in the screening since we choose to always include them in the model\n",
    "\"\"\"\n",
    "    if outcome == \"age\":\n",
    "        py_2 = r\"\"\"\n",
    "# age\n",
    "abide_name = [_abide_name[-3]] + _abide_name[1:-3]\n",
    "# so that the left first column is the outcome and the rest columns are areas\n",
    "del _abide_name\n",
    "\n",
    "num_input_vars_divide = 10\n",
    "prop_input_vars_list = np.linspace(0, 1, num_input_vars_divide)[1:]\n",
    "\n",
    "\n",
    "def _get_computing_time(prop_input_vars):\n",
    "    s = '''mi.continuous_screening_csv_parallel(csv_file, _usecols=abide_name.copy()[0:int(len(abide_name)*prop_input_vars)], csv_engine=\"{_csv_engine}\", sample=1250000, multp=10, core_num=16, share_memory={_share_mem_status}, kernel=\"epa\", bw=\"ISJ\", norm=2,verbose=0)'''\n",
    "    imports_and_vars = globals()\n",
    "    imports_and_vars.update(locals())\n",
    "    num_loops = timeit.Timer(stmt=s, globals=imports_and_vars).autorange()[0]\n",
    "    FFTKDE_MI_times = timeit.Timer(stmt=s, globals=imports_and_vars).repeat(\n",
    "        repeat=5, number=num_loops)\n",
    "\n",
    "    s = '''mi.continuous_skMI_screening_csv_parallel(csv_file, _usecols=abide_name.copy()[0:int(len(abide_name)*prop_input_vars)], csv_engine=\"{_csv_engine}\", sample=1250000, multp=10, core_num=16, random_state=0, share_memory={_share_mem_status},verbose=0)'''\n",
    "    imports_and_vars = globals()\n",
    "    imports_and_vars.update(locals())\n",
    "    num_loops = timeit.Timer(stmt=s, globals=imports_and_vars).autorange()[0]\n",
    "    sklearn_MI_times = timeit.Timer(stmt=s, globals=imports_and_vars).repeat(\n",
    "        repeat=5, number=num_loops)\n",
    "\n",
    "    s = '''pearson_output = mi.Pearson_screening_csv_parallel(csv_file, _usecols=abide_name.copy()[0:int(len(abide_name)*prop_input_vars)], csv_engine=\"{_csv_engine}\", sample=1250000, multp=10, core_num=16, share_memory={_share_mem_status},verbose=0)'''\n",
    "    imports_and_vars = globals()\n",
    "    imports_and_vars.update(locals())\n",
    "    num_loops = timeit.Timer(stmt=s, globals=imports_and_vars).autorange()[0]\n",
    "    Pearson_times = timeit.Timer(stmt=s, globals=imports_and_vars).repeat(\n",
    "        repeat=5, number=num_loops)\n",
    "\n",
    "    return np.vstack((FFTKDE_MI_times, sklearn_MI_times, Pearson_times))\n",
    "\n",
    "print(\"Running speed comparison when the outcome variable is age (continuous) and the memory setting is {mem_setting}... \")\n",
    "output_array = np.array(list(map(_get_computing_time, tqdm(prop_input_vars_list))))\n",
    "np.save(r\"./running_time_age_{mem_setting}\", output_array)\n",
    "\"\"\".format(_csv_engine=engine_and_share_memory_status(mem_setting)[0],\n",
    "           _share_mem_status=engine_and_share_memory_status(mem_setting)[1],\n",
    "           mem_setting=mem_setting)\n",
    "    elif outcome == \"diagnosis\":\n",
    "        py_2 = r\"\"\"\n",
    "# diagnosis\n",
    "abide_name = [_abide_name[-1]] + _abide_name[1:-3]\n",
    "# so that the left first column is the outcome and the rest columns are areas\n",
    "del _abide_name\n",
    "\n",
    "num_input_vars_divide = 10\n",
    "prop_input_vars_list = np.linspace(0, 1, num_input_vars_divide)[1:]\n",
    "\n",
    "\n",
    "def _get_computing_time(prop_input_vars):\n",
    "    s = '''mi.binary_screening_csv_parallel(csv_file,_usecols=abide_name.copy()[0:int(len(abide_name)*prop_input_vars)],csv_engine=\"{_csv_engine}\",sample=1250000,multp=10,core_num=16,share_memory={_share_mem_status},kernel=\"epa\",bw=\"ISJ\",verbose=0)'''\n",
    "    imports_and_vars = globals()\n",
    "    imports_and_vars.update(locals())\n",
    "    num_loops = timeit.Timer(stmt=s, globals=imports_and_vars).autorange()[0]\n",
    "    FFTKDE_MI_times = timeit.Timer(stmt=s, globals=imports_and_vars).repeat(\n",
    "        repeat=5, number=num_loops)\n",
    "\n",
    "    s = '''mi.binary_skMI_screening_csv_parallel(csv_file,_usecols=abide_name.copy()[0:int(len(abide_name)*prop_input_vars)],csv_engine=\"{_csv_engine}\",sample=1250000,multp=10,core_num=16,random_state=0,share_memory={_share_mem_status},verbose=0)'''\n",
    "    imports_and_vars = globals()\n",
    "    imports_and_vars.update(locals())\n",
    "    num_loops = timeit.Timer(stmt=s, globals=imports_and_vars).autorange()[0]\n",
    "    sklearn_MI_times = timeit.Timer(stmt=s, globals=imports_and_vars).repeat(\n",
    "        repeat=5, number=num_loops)\n",
    "\n",
    "    s = '''pearson_output = mi.Pearson_screening_csv_parallel( csv_file, _usecols=abide_name.copy()[0:int(len(abide_name)*prop_input_vars)], csv_engine=\"{_csv_engine}\", sample=1250000, multp=10, core_num=16, share_memory={_share_mem_status},verbose=0)'''\n",
    "    imports_and_vars = globals()\n",
    "    imports_and_vars.update(locals())\n",
    "    num_loops = timeit.Timer(stmt=s, globals=imports_and_vars).autorange()[0]\n",
    "    Pearson_times = timeit.Timer(stmt=s, globals=imports_and_vars).repeat(\n",
    "        repeat=5, number=num_loops)\n",
    "\n",
    "    return np.vstack((FFTKDE_MI_times, sklearn_MI_times, Pearson_times))\n",
    "\n",
    "print(\"Running speed comparison when the outcome variable is diagnosis (binary) and the memory setting is {mem_setting}... \")\n",
    "output_array = np.array(list(map(_get_computing_time, tqdm(prop_input_vars_list))))\n",
    "np.save(r\"./running_time_diagnosis_{mem_setting}\", output_array)\n",
    "\"\"\".format(_csv_engine=engine_and_share_memory_status(mem_setting)[0],\n",
    "           _share_mem_status=engine_and_share_memory_status(mem_setting)[1],\n",
    "           mem_setting=mem_setting)\n",
    "\n",
    "    Path(r\"./running_speed/speed_comparison_\" + outcome + \"_\" + mem_setting +\n",
    "         \".py\").touch()\n",
    "    py_script = open(\n",
    "        r\"./running_speed/speed_comparison_\" + outcome + \"_\" + mem_setting +\n",
    "        \".py\", \"w\")\n",
    "    py_script.write(py_1 + py_2)\n",
    "\n",
    "    Path(r\"./running_speed/speed_comparison_\" + outcome + \"_\" + mem_setting +\n",
    "         \".sh\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./running_speed/speed_comparison_\" + outcome + \"_\" + mem_setting +\n",
    "        \".sh\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=6-12:00:00\n",
    "#SBATCH --job-name=ABIDE_screening_{outcome}_{mem_setting}\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_screening_{outcome}_{mem_setting}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "\n",
    "python3 speed_comparison_{outcome}_{mem_setting}.py\n",
    "\"\"\".format(outcome=outcome, mem_setting=mem_setting))\n",
    "\n",
    "\n",
    "for mem_setting in [\"high_mem\", \"share_mem\"]:\n",
    "    for outcome in [\"age\", \"diagnosis\"]:\n",
    "        job_generator(mem_setting=mem_setting, outcome=outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd8080a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:14.943534Z",
     "start_time": "2023-12-23T21:19:14.922832Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_true_vars_list = prop_input_vars_list = np.linspace(0, 1, 10)[1:]\n",
    "\n",
    "# plot_mean = np.zeros((len(num_true_vars_list), 3))\n",
    "# plot_se = np.zeros((len(num_true_vars_list), 3))\n",
    "\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True)\n",
    "# ax = ax.flatten()\n",
    "\n",
    "# file_names = [\n",
    "#     \"running_time_age_high_mem.npy\",\n",
    "#     \"running_time_age_share_mem.npy\",\n",
    "#     \"running_time_diagnosis_high_mem.npy\",\n",
    "#     #     \"running_time_diagnosis_share_mem.npy\" # uncommnet this line once the results are back\n",
    "# ]\n",
    "\n",
    "# k = 0\n",
    "# for file_name in file_names:\n",
    "#     try:\n",
    "#         computing_results = np.load(f\"./running_speed/{file_name}\")\n",
    "#         plot_mean = np.mean(computing_results, axis=2)\n",
    "#         plot_se = np.std(computing_results, axis=2)\n",
    "#     except:\n",
    "#         print(f\"The data file, ./running_speed/{file_name}, doesn't exist\")\n",
    "#         plot_mean = np.nan\n",
    "#         plot_se = np.nan\n",
    "\n",
    "#     ax[k].plot(num_true_vars_list,\n",
    "#                plot_mean[:, 0],\n",
    "#                label=\"$\\widehat{MI}$ based on FFTKDE\",\n",
    "#                linestyle=\"-\",\n",
    "#                color=\"b\")\n",
    "#     ax[k].fill_between(num_true_vars_list,\n",
    "#                        (plot_mean[:, 0] + plot_se[:, 0] * norm.ppf(0.025)),\n",
    "#                        (plot_mean[:, 0] + plot_se[:, 0] * norm.ppf(0.975)),\n",
    "#                        color=\"b\",\n",
    "#                        alpha=.1)\n",
    "\n",
    "#     ax[k].plot(num_true_vars_list,\n",
    "#                plot_mean[:, 1],\n",
    "#                label=\"$\\widehat{MI}$ based on skLearn\",\n",
    "#                linestyle=\"-.\",\n",
    "#                color=\"y\")\n",
    "#     ax[k].fill_between(num_true_vars_list,\n",
    "#                        (plot_mean[:, 1] + plot_se[:, 1] * norm.ppf(0.025)),\n",
    "#                        (plot_mean[:, 1] + plot_se[:, 1] * norm.ppf(0.975)),\n",
    "#                        color=\"y\",\n",
    "#                        alpha=.1)\n",
    "\n",
    "#     ax[k].plot(num_true_vars_list,\n",
    "#                plot_mean[:, 2],\n",
    "#                label=\"Pearson's correlation\",\n",
    "#                linestyle=\"--\",\n",
    "#                color=\"g\")\n",
    "#     ax[k].fill_between(num_true_vars_list,\n",
    "#                        (plot_mean[:, 2] + plot_se[:, 2] * norm.ppf(0.025)),\n",
    "#                        (plot_mean[:, 2] + plot_se[:, 2] * norm.ppf(0.975)),\n",
    "#                        color=\"g\",\n",
    "#                        alpha=.1)\n",
    "\n",
    "#     ax[k].set_title(f\"{file_name.replace('.npy', '').replace('_', ' ')}\")\n",
    "#     ax[k].label_outer()\n",
    "#     k += 1\n",
    "\n",
    "# # Adjust the right margin to make room for the legend\n",
    "# fig.subplots_adjust(right=0.85)\n",
    "\n",
    "# # Set centralized labels and legend\n",
    "# handles, labels = ax[0].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# fig.supxlabel(r'Proportion of the covariates input to the screening step')\n",
    "# fig.supylabel(r'Time for screening (seconds)')\n",
    "\n",
    "# # Save the plot\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"./running_speed/running_speed_combined.pdf\",\n",
    "#             format=\"pdf\",\n",
    "#             dpi=600,\n",
    "#             bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea4ca1-abfd-4856-8f70-63658655173a",
   "metadata": {},
   "source": [
    "# Plots for age\n",
    "## Comparing two ranking with Kendall's $\\tau$\n",
    "\n",
    "**So in summary, the two ranking vary somehow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb054aa1-5485-4ea5-8f0b-5eefadf893ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:14.958453Z",
     "start_time": "2023-12-23T21:19:14.944429Z"
    }
   },
   "outputs": [],
   "source": [
    "# abide_mi = np.load(r\"./ABIDE_age_MI_output.npy\")\n",
    "# plt.hist(np.log(abide_mi), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_pearson = np.load(r\"./ABIDE_age_Pearson_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_skmi = np.load(r\"./ABIDE_age_skMI_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Kendall'stau for MI vs Pearson: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_pearson))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_pearson, s=10,\n",
    "#             alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT AGE\n",
    "\n",
    "# print(\"Kendall'stau for MI vs skMI: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_skmi))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_skmi, s=10, alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT AGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de0251",
   "metadata": {},
   "source": [
    "# Plots for diagnosis\n",
    "## Comparing two ranking with Kendall's $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5230b75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:14.973419Z",
     "start_time": "2023-12-23T21:19:14.959217Z"
    }
   },
   "outputs": [],
   "source": [
    "# abide_mi = np.load(r\"./ABIDE_diagnosis_MI_output.npy\")\n",
    "# plt.hist(np.log(abide_mi), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_pearson = np.load(r\"./ABIDE_diagnosis_Pearson_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_skmi = np.load(r\"./ABIDE_diagnosis_skMI_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Kendall'stau for MI vs Pearson: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_pearson))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_pearson, s=10,\n",
    "#             alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT diagnosis\n",
    "\n",
    "# print(\"Kendall'stau for MI vs skMI: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_skmi))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_skmi, s=10, alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ebdd3",
   "metadata": {},
   "source": [
    "# A scatter plot for age and diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfce6fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:14.984395Z",
     "start_time": "2023-12-23T21:19:14.974826Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator():\n",
    "    Path(r\"./ABIDE_scatterplot/scatter_plot_for_most_associated.sh\").touch()\n",
    "    Path(r\"./ABIDE_scatterplot/scatter_plot_for_most_associated.py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_scatterplot/scatter_plot_for_most_associated.sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_scatterplot/scatter_plot_for_most_associated.py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=2:00:00\n",
    "#SBATCH --job-name=scatter_plot_for_most_associated\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running scatter_plot_for_most_associated.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_MI_epa_ISJ_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_Pearson_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_skMI_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_MI_epa_ISJ_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_Pearson_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_skMI_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 scatter_plot_for_most_associated.py\n",
    "    \"\"\")\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "top_colnames_num = 5\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "\n",
    "for outcome in [\"diagnosis\", \"age\"]:\n",
    "    top_colnames = []\n",
    "    for dep_measure in [\"MI_epa_ISJ\", \"Pearson\", \"skMI\"]:\n",
    "        abide_dep = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_\" + outcome +\n",
    "                            r\"_\" + dep_measure + r\"_output.npy\")\n",
    "        abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "        top_colnames = np.hstack(\n",
    "            (top_colnames, columns[np.argsort(-abide_dep)][:top_colnames_num]))\n",
    "\n",
    "    top_colnames = list(set(top_colnames))\n",
    "    for colname in top_colnames:\n",
    "        if outcome == \"diagnosis\":\n",
    "            plt.scatter(original_df[\"DX_GROUP\"],\n",
    "                        original_df[colname],\n",
    "                        alpha=.2)\n",
    "        if outcome == \"age\":\n",
    "            plt.scatter(original_df[\"AGE_AT_SCAN\"],\n",
    "                        original_df[colname],\n",
    "                        alpha=.2)\n",
    "        plt.ylabel(outcome)\n",
    "        plt.xlabel(colname)\n",
    "        plt.title(r\"scatter plot for outcome vs the top associated covariates: \" + outcome +\n",
    "                  r\" and \" + colname)\n",
    "        plt.savefig(r\"scatter_\" + outcome + r\"_\" + colname + \".pdf\", format=\"pdf\", dpi=600)\n",
    "        plt.close()\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "job_creator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447fa79",
   "metadata": {},
   "source": [
    "# Try Fitting models to predict age, $5$-fold CV for hyper-parameter tuning\n",
    "## create job submission scripts for `ABIDE_predict_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10871140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:15.017536Z",
     "start_time": "2023-12-23T21:19:14.985285Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "         \".sh\").touch()\n",
    "    Path(r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "         \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "        \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "        \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name=age_{dep_measure}_{fun_name}\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_age_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_age_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(os.environ[\"SLURM_TMPDIR\"] +\n",
    "                    r\"/ABIDE_age_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def binning(var, num_bins, min_num=2):\n",
    "    bins = np.linspace(np.min(var) - 1e-8, np.max(var) + 1e-8, num_bins)\n",
    "    var_binned = np.digitize(var, bins)\n",
    "    category = np.sort(np.unique(var_binned))\n",
    "    while len([\n",
    "            x for x in category if np.count_nonzero(var_binned == x) < min_num\n",
    "    ]) != 0:\n",
    "        for j in range(len(category)):\n",
    "            if j < len(\n",
    "                    category\n",
    "            ):  # since category is always updated, we add this to avoid out of index error; alternatively, a while loop also works\n",
    "                if np.count_nonzero(\n",
    "                        var_binned == category[j]\n",
    "                ) < min_num:  # if the number of observations in a category is less than min_num\n",
    "                    if j == 0:  # if it's the first category, combine it with the second\n",
    "                        var_binned[var_binned == category[j]] = category[j + 1]\n",
    "                    else:  # if it's not the first category, combine it with the previous one\n",
    "                        var_binned[var_binned == category[j]] = category[j - 1]\n",
    "                    category = np.sort(np.unique(var_binned))\n",
    "    return var_binned\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((\n",
    "        outcome_name, \"SEX\", #\"DX_GROUP\", # comment out DX_GROUP as we are using cases only\n",
    "        columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor, LinearRegression\n",
    "        ]:\n",
    "            y_binned = binning(y, 30, min_num=2)\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [LinearRegression]:\n",
    "            fit = fun(n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LogisticRegression]:\n",
    "            fit = fun(penalty=None, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(map(int,\n",
    "                      np.around(np.linspace(0, 50, 10 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"AGE_AT_SCAN\",\n",
    "    num_rep=20)\n",
    "np.save(r\"./ABIDE_age_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LassoCV\", \"ElasticNetCV\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\",\n",
    "        \"MLPRegressor\", \"RandomForestRegressor\", \"LinearRegression\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df160684",
   "metadata": {},
   "source": [
    "## create job submission scripts for `ABIDE_poly3_predict_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da95d107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:15.038678Z",
     "start_time": "2023-12-23T21:19:15.018280Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-cgreenwo\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name=poly3_age_{dep_measure}_{fun_name}\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_poly3_age_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_poly3_age_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(os.environ[\"SLURM_TMPDIR\"] +\n",
    "                    r\"/ABIDE_age_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def binning(var, num_bins, min_num=2):\n",
    "    bins = np.linspace(np.min(var) - 1e-8, np.max(var) + 1e-8, num_bins)\n",
    "    var_binned = np.digitize(var, bins)\n",
    "    category = np.sort(np.unique(var_binned))\n",
    "    while len([\n",
    "            x for x in category if np.count_nonzero(var_binned == x) < min_num\n",
    "    ]) != 0:\n",
    "        for j in range(len(category)):\n",
    "            if j < len(\n",
    "                    category\n",
    "            ):  # since category is always updated, we add this to avoid out of index error; alternatively, a while loop also works\n",
    "                if np.count_nonzero(\n",
    "                        var_binned == category[j]\n",
    "                ) < min_num:  # if the number of observations in a category is less than min_num\n",
    "                    if j == 0:  # if it's the first category, combine it with the second\n",
    "                        var_binned[var_binned == category[j]] = category[j + 1]\n",
    "                    else:  # if it's not the first category, combine it with the previous one\n",
    "                        var_binned[var_binned == category[j]] = category[j - 1]\n",
    "                    category = np.sort(np.unique(var_binned))\n",
    "    return var_binned\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((\n",
    "        outcome_name, \"SEX\", #\"DX_GROUP\", # comment out DX_GROUP as we are using cases only\n",
    "        columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        X = SplineTransformer(n_knots=2,\n",
    "                              degree=3,\n",
    "                              extrapolation=\"continue\",\n",
    "                              include_bias=False).fit_transform(X)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor, LinearRegression\n",
    "        ]:\n",
    "            y_binned = binning(y, 30, min_num=2)\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [LinearRegression]:\n",
    "            fit = fun(n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LogisticRegression]:\n",
    "            fit = fun(penalty=None, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_poly3_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(map(int,\n",
    "                      np.around(np.linspace(0, 50, 10 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"AGE_AT_SCAN\",\n",
    "    num_rep=20)\n",
    "np.save(r\"./ABIDE_poly3_age_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LassoCV\", \"ElasticNetCV\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\",\n",
    "        \"MLPRegressor\", \"RandomForestRegressor\", \"LinearRegression\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777df55",
   "metadata": {},
   "source": [
    "# Comparison of Performance\n",
    "## Here is just to show the testing set $R^2$ using plots\n",
    "### using variables directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77de1868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:15.060470Z",
     "start_time": "2023-12-23T21:19:15.039451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_{dep_measure}_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)) and os.path.isfile(\n",
    "                r\"./ABIDE_predict_age/ABIDE_age_Pearson_{fun_name}.npy\".format(\n",
    "                    fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_age_MI_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_{dep_measure}_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_age_skMI_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_skMI_{fun_name}.npy\".format(\n",
    "                fun_name=fun_name))\n",
    "        ABIDE_age_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_Pearson_{fun_name}.npy\".format(\n",
    "                fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 50, 10 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_age_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_age_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_age_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_age_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_age_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_age_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  MI_fit_mean,\n",
    "                  label=dep_measure,\n",
    "                  linestyle=\"-\",\n",
    "                  color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  linestyle=\"-.\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  linestyle=\"--\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "        plt.ylabel(r'Testing Set $R^2$')\n",
    "        plt.xlabel(r'Number of Selected Covariates')\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPRegressor\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\", \"LassoCV\",\n",
    "            \"ElasticNetCV\", \"RandomForestRegressor\", \"LinearRegression\"\n",
    "    ]:\n",
    "        if dep_measure == \"MI_epa_ISJ\":\n",
    "            plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "            plt.savefig(r\"./ABIDE_predict_age/age_\" + fun_name + \"_\" +\n",
    "                        dep_measure + \".pdf\",\n",
    "                        format=\"pdf\",\n",
    "                        dpi=600)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ff14b",
   "metadata": {},
   "source": [
    "### using Bernstein polynomials of degree $3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e3ccaee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:15.081817Z",
     "start_time": "2023-12-23T21:19:15.061128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_age_MI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_age_skMI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name))\n",
    "        ABIDE_age_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 50, 10 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_age_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_age_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_age_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_age_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_age_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_age_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  MI_fit_mean,\n",
    "                  label=dep_measure,\n",
    "                  linestyle=\"-\",\n",
    "                  color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  linestyle=\"-.\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  linestyle=\"--\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "        plt.ylabel(r'Testing Set $R^2$')\n",
    "        plt.xlabel(r'Number of Selected Covariates')\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPRegressor\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\", \"LassoCV\",\n",
    "            \"ElasticNetCV\", \"RandomForestRegressor\", \"LinearRegression\"\n",
    "    ]:\n",
    "        if dep_measure == \"MI_epa_ISJ\":\n",
    "            plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "            plt.savefig(r\"./ABIDE_poly3_predict_age/poly3_age_\" + fun_name +\n",
    "                        \"_\" + dep_measure + \".pdf\",\n",
    "                        format=\"pdf\",\n",
    "                        dpi=600)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1a5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T21:28:21.063315Z",
     "start_time": "2023-02-16T21:28:20.629362Z"
    }
   },
   "source": [
    "# Try Fitting models to predict diagnosis, $5$-fold CV\n",
    "## create job submission scripts for `ABIDE_predict_diagnosis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6939ef62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:15.101808Z",
     "start_time": "2023-12-23T21:19:15.082432Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name=diagnosis_{dep_measure}_{fun_name}\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_diagnosis_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_diagnosis_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(\n",
    "    os.environ[\"SLURM_TMPDIR\"] +\n",
    "    r\"/ABIDE_diagnosis_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def binning(var, num_bins, min_num=2):\n",
    "    bins = np.linspace(np.min(var) - 1e-8, np.max(var) + 1e-8, num_bins)\n",
    "    var_binned = np.digitize(var, bins)\n",
    "    category = np.sort(np.unique(var_binned))\n",
    "    while len([\n",
    "            x for x in category if np.count_nonzero(var_binned == x) < min_num\n",
    "    ]) != 0:\n",
    "        for j in range(len(category)):\n",
    "            if j < len(\n",
    "                    category\n",
    "            ):  # since category is always updated, we add this to avoid out of index error; alternatively, a while loop also works\n",
    "                if np.count_nonzero(\n",
    "                        var_binned == category[j]\n",
    "                ) < min_num:  # if the number of observations in a category is less than min_num\n",
    "                    if j == 0:  # if it's the first category, combine it with the second\n",
    "                        var_binned[var_binned == category[j]] = category[j + 1]\n",
    "                    else:  # if it's not the first category, combine it with the previous one\n",
    "                        var_binned[var_binned == category[j]] = category[j - 1]\n",
    "                    category = np.sort(np.unique(var_binned))\n",
    "    return var_binned\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((\n",
    "        outcome_name, \"SEX\", \"AGE_AT_SCAN\",\n",
    "        columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor, LinearRegression\n",
    "        ]:\n",
    "            y_binned = binning(y, 30, min_num=2)\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [LinearRegression]:\n",
    "            fit = fun(n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LogisticRegression]:\n",
    "            fit = fun(penalty=None, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(map(int,\n",
    "                      np.around(np.linspace(0, 50, 10 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"DX_GROUP\",\n",
    "    num_rep=20)\n",
    "np.save(r\"./ABIDE_diagnosis_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_l2\",\n",
    "        \"LogisticRegressionCV_ElasticNet\", \"MLPClassifier\",\n",
    "        \"RandomForestClassifier\", \"LogisticRegression\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49c3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T21:28:21.063315Z",
     "start_time": "2023-02-16T21:28:20.629362Z"
    }
   },
   "source": [
    "## create job submission scripts for `ABIDE_poly3_predict_diagnosis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1bc6195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:15.122742Z",
     "start_time": "2023-12-23T21:19:15.102559Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "         dep_measure + \"_\" + fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "         dep_measure + \"_\" + fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "        dep_measure + \"_\" + fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "        dep_measure + \"_\" + fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-cgreenwo\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name=poly3_diagnosis_{dep_measure}_{fun_name}\n",
    "\n",
    "module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load arch/avx2 gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.5\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.5 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.25.6\n",
    "# pip install fastHDMI==1.25.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.5+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.25.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp /home/kyang/projects/def-cgreenwo/kyang/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX_CasesOnly.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "# from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(\n",
    "    os.environ[\"SLURM_TMPDIR\"] +\n",
    "    r\"/ABIDE_diagnosis_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def binning(var, num_bins, min_num=2):\n",
    "    bins = np.linspace(np.min(var) - 1e-8, np.max(var) + 1e-8, num_bins)\n",
    "    var_binned = np.digitize(var, bins)\n",
    "    category = np.sort(np.unique(var_binned))\n",
    "    while len([\n",
    "            x for x in category if np.count_nonzero(var_binned == x) < min_num\n",
    "    ]) != 0:\n",
    "        for j in range(len(category)):\n",
    "            if j < len(\n",
    "                    category\n",
    "            ):  # since category is always updated, we add this to avoid out of index error; alternatively, a while loop also works\n",
    "                if np.count_nonzero(\n",
    "                        var_binned == category[j]\n",
    "                ) < min_num:  # if the number of observations in a category is less than min_num\n",
    "                    if j == 0:  # if it's the first category, combine it with the second\n",
    "                        var_binned[var_binned == category[j]] = category[j + 1]\n",
    "                    else:  # if it's not the first category, combine it with the previous one\n",
    "                        var_binned[var_binned == category[j]] = category[j - 1]\n",
    "                    category = np.sort(np.unique(var_binned))\n",
    "    return var_binned\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((\n",
    "        outcome_name, \"SEX\", \"AGE_AT_SCAN\",\n",
    "        columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        X = SplineTransformer(n_knots=2,\n",
    "                              degree=3,\n",
    "                              extrapolation=\"continue\",\n",
    "                              include_bias=False).fit_transform(X)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor, LinearRegression\n",
    "        ]:\n",
    "            y_binned = binning(y, 30, min_num=2)\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [LinearRegression]:\n",
    "            fit = fun(n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LogisticRegression]:\n",
    "            fit = fun(penalty=None, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_poly3_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(map(int,\n",
    "                      np.around(np.linspace(0, 50, 10 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"DX_GROUP\",\n",
    "    num_rep=20)\n",
    "np.save(r\"./ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_l2\",\n",
    "        \"LogisticRegressionCV_ElasticNet\", \"MLPClassifier\",\n",
    "        \"RandomForestClassifier\", \"LogisticRegression\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5658d",
   "metadata": {},
   "source": [
    "# Comparison of Performance\n",
    "## Here is just to show the testing set ROC\n",
    "### using variables directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6920631b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:15.144450Z",
     "start_time": "2023-12-23T21:19:15.123393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_diagnosis_MI_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_diagnosis_skMI_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name))\n",
    "        ABIDE_diagnosis_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 50, 10 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_diagnosis_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_diagnosis_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  MI_fit_mean,\n",
    "                  label=dep_measure,\n",
    "                  linestyle=\"-\",\n",
    "                  color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  linestyle=\"-.\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  linestyle=\"--\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "        plt.ylabel(r'Testing Set AUROC')\n",
    "        plt.xlabel(r'Number of Selected Covariates')\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPClassifier\", \"LogisticRegressionCV_l2\",\n",
    "            \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_ElasticNet\",\n",
    "            \"RandomForestClassifier\", \"LogisticRegression\"\n",
    "    ]:\n",
    "        if dep_measure == \"MI_epa_ISJ\":\n",
    "            plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "            plt.savefig(r\"./ABIDE_predict_diagnosis/diagnosis_\" + fun_name +\n",
    "                        \"_\" + dep_measure + \".pdf\",\n",
    "                        format=\"pdf\",\n",
    "                        dpi=600)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cafeb18",
   "metadata": {},
   "source": [
    "### using Bernstein polynomials of degree $3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e899df18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:19:15.167595Z",
     "start_time": "2023-12-23T21:19:15.145080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_skMI_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_diagnosis_MI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_diagnosis_skMI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_skMI_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        ABIDE_diagnosis_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 50, 10 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_diagnosis_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_diagnosis_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  MI_fit_mean,\n",
    "                  label=dep_measure,\n",
    "                  linestyle=\"-\",\n",
    "                  color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  linestyle=\"-.\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  linestyle=\"--\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPClassifier\", \"LogisticRegressionCV_l2\",\n",
    "            \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_ElasticNet\",\n",
    "            \"RandomForestClassifier\", \"LogisticRegression\"\n",
    "    ]:\n",
    "        if dep_measure == \"MI_epa_ISJ\":\n",
    "            plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "            plt.savefig(r\"./ABIDE_poly3_predict_diagnosis/poly3_diagnosis_\" +\n",
    "                        fun_name + \"_\" + dep_measure + \".pdf\",\n",
    "                        format=\"pdf\",\n",
    "                        dpi=600)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75a9b3a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T21:23:29.882366Z",
     "start_time": "2023-12-23T21:19:15.168114Z"
    }
   },
   "outputs": [],
   "source": [
    "# scripts formatting\n",
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889857c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
