{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39eea284-aeec-427b-b3fc-2a35d72a5825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:47.613912Z",
     "start_time": "2023-04-24T20:45:36.840869Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "# import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f64a8",
   "metadata": {},
   "source": [
    "# Simulation study for continuous and binary outcome based on ABIDE data, and testing the screening performance for all three methods\n",
    "\n",
    "## creating job submission scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0697560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:47.719572Z",
     "start_time": "2023-04-24T20:45:47.619197Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_generator(outcome, num_true_vars_iter):\n",
    "    py_1 = r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# read the data\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "\n",
    "abide_original = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "_abide_name = abide_original.columns.tolist()[1:]\n",
    "\n",
    "# print(_abide_name)\n",
    "\n",
    "abide_name_original = _abide_name[1:-3]\n",
    "\n",
    "# preserve only the neuro-imaging data\n",
    "abide_original = abide_original[abide_name_original]\n",
    "\n",
    "def convert2list(a):\n",
    "    b = np.asarray(a)\n",
    "    return b.tolist()\n",
    "\"\"\"\n",
    "    if outcome == \"continuous\":\n",
    "        py_2 = r\"\"\"\n",
    "def sim_based_on_abide_continuous(pair):\n",
    "    abide, abide_name = abide_original.copy(), abide_name_original.copy()\n",
    "    _num_true_vars, _seed = pair\n",
    "    SNR = 9.\n",
    "    num_true_vars = _num_true_vars\n",
    "    seed = _seed\n",
    "    assert num_true_vars < len(abide_name)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    true_names = np.random.choice(abide_name, num_true_vars, replace=False)\n",
    "    true_names = convert2list(true_names)\n",
    "\n",
    "    true_beta = np.random.uniform(low=5.0, high=6.0,\n",
    "                                  size=num_true_vars) * np.random.choice(\n",
    "                                      [1., -1.], num_true_vars, replace=True)\n",
    "\n",
    "    sim_data = abide[true_names].to_numpy(copy=True)\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    sim_data = sim_data**2\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "\n",
    "    X_cov = np.corrcoef(sim_data, rowvar=False)\n",
    "    true_sigma_sim = np.sqrt(true_beta.T @ X_cov @ true_beta / SNR)\n",
    "\n",
    "    outcome = sim_data @ true_beta + np.random.normal(0, true_sigma_sim,\n",
    "                                                      sim_data.shape[0])\n",
    "\n",
    "    abide[\"outcome\"] = outcome\n",
    "    abide = abide[[\"outcome\"] + abide_name]\n",
    "\n",
    "    print(\"The outcome is continuous.\")\n",
    "\n",
    "    print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "    try:\n",
    "        mi_output = mi.continuous_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"ISJ\",\n",
    "            norm=2)\n",
    "    except:\n",
    "        mi_output = mi.continuous_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"silverman\",\n",
    "            norm=2)\n",
    "\n",
    "    print(\"sklearn MI calculation:\")\n",
    "\n",
    "    skmi_output = mi.continuous_skMI_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        random_state=0,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "    pearson_output = mi.Pearson_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    mi_selection = np.asarray(abide_name)[np.argsort(\n",
    "        -mi_output)][:num_true_vars]\n",
    "    mi_selection = convert2list(mi_selection)\n",
    "    skmi_selection = np.asarray(abide_name)[np.argsort(\n",
    "        -skmi_output)][:num_true_vars]\n",
    "    skmi_selection = convert2list(skmi_selection)\n",
    "    pearson_selection = np.asarray(abide_name)[np.argsort(\n",
    "        -pearson_output)][:num_true_vars]\n",
    "    pearson_selection = convert2list(pearson_selection)\n",
    "\n",
    "    mi_sensitivity = len(set(mi_selection)) + len(set(true_names)) - len(\n",
    "        set(mi_selection + true_names))\n",
    "    mi_sensitivity = mi_sensitivity / len(true_names)\n",
    "    skmi_sensitivity = len(set(skmi_selection)) + len(set(true_names)) - len(\n",
    "        set(skmi_selection + true_names))\n",
    "    skmi_sensitivity = skmi_sensitivity / len(true_names)\n",
    "    pearson_sensitivity = len(set(pearson_selection)) + len(\n",
    "        set(true_names)) - len(set(pearson_selection + true_names))\n",
    "    pearson_sensitivity = pearson_sensitivity / len(true_names)\n",
    "\n",
    "    del mi_output, skmi_output, pearson_output, abide, abide_name, true_names, true_beta, sim_data, X_cov, true_sigma_sim, outcome, mi_selection, skmi_selection, pearson_selection\n",
    "\n",
    "    return np.array([mi_sensitivity, skmi_sensitivity, pearson_sensitivity])\n",
    "\n",
    "\n",
    "num_true_vars_list = [{_num_true_vars_iter}]\n",
    "seed_list = range(100)\n",
    "\n",
    "itrs = itertools.product(num_true_vars_list, seed_list)\n",
    "\n",
    "output_array = np.array(list(map(sim_based_on_abide_continuous, tqdm(itrs))))\n",
    "output_array = output_array.reshape(1, 100, 3).squeeze()\n",
    "np.save(r\"./ABIDE_sim_continuous_{_num_true_vars_iter}\", output_array)\n",
    "\"\"\".format(_num_true_vars_iter=num_true_vars_iter)\n",
    "    elif outcome == \"binary\":\n",
    "        py_2 = r\"\"\"\n",
    "def sim_based_on_abide_binary(pair):\n",
    "    abide, abide_name = abide_original.copy(), abide_name_original.copy()\n",
    "    _num_true_vars, _seed = pair\n",
    "    SNR = 3.\n",
    "    num_true_vars = _num_true_vars\n",
    "    seed = _seed\n",
    "    assert num_true_vars < len(abide_name)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    true_names = np.random.choice(abide_name, num_true_vars, replace=False)\n",
    "    true_names = convert2list(true_names)\n",
    "\n",
    "    true_beta = np.random.uniform(low=5.0, high=6.0,\n",
    "                                  size=num_true_vars) * np.random.choice(\n",
    "                                      [1., -1.], num_true_vars, replace=True)\n",
    "\n",
    "    sim_data = abide[true_names].to_numpy(copy=True)\n",
    "    sim_data = StandardScaler(copy=False).fit_transform(sim_data)\n",
    "    signal = sim_data @ true_beta\n",
    "    signal -= np.mean(\n",
    "        signal\n",
    "    )  # make sure it's centered at 0 to avoid generated data all be in one class\n",
    "    signal /= np.std(signal)  # avoid the case if the data is too centered\n",
    "\n",
    "    outcome = np.random.binomial(1, np.tanh(signal / 2) / 2 + .5)\n",
    "\n",
    "    abide[\"outcome\"] = outcome\n",
    "    abide = abide[[\"outcome\"] + abide_name]\n",
    "\n",
    "    print(\"The outcome is binary.\")\n",
    "\n",
    "    print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "    try:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"ISJ\")\n",
    "    except:\n",
    "        mi_output = mi.binary_screening_dataframe_parallel(\n",
    "            dataframe=abide,\n",
    "            _usecols=[\"outcome\"] + abide_name,\n",
    "            multp=10,\n",
    "            core_num=32,\n",
    "            share_memory=False,\n",
    "            kernel=\"epa\",\n",
    "            bw=\"silverman\")\n",
    "\n",
    "    print(\"sklearn MI calculation:\")\n",
    "\n",
    "    skmi_output = mi.binary_skMI_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        random_state=0,\n",
    "        share_memory=False)\n",
    "\n",
    "    print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "    pearson_output = mi.Pearson_screening_dataframe_parallel(\n",
    "        dataframe=abide,\n",
    "        _usecols=[\"outcome\"] + abide_name,\n",
    "        multp=10,\n",
    "        core_num=32,\n",
    "        share_memory=False)\n",
    "\n",
    "    mi_selection = np.asarray(abide_name)[np.argsort(\n",
    "        -mi_output)][:num_true_vars]\n",
    "    mi_selection = convert2list(mi_selection)\n",
    "    skmi_selection = np.asarray(abide_name)[np.argsort(\n",
    "        -skmi_output)][:num_true_vars]\n",
    "    skmi_selection = convert2list(skmi_selection)\n",
    "    pearson_selection = np.asarray(abide_name)[np.argsort(\n",
    "        -pearson_output)][:num_true_vars]\n",
    "    pearson_selection = convert2list(pearson_selection)\n",
    "\n",
    "    mi_sensitivity = len(set(mi_selection)) + len(set(true_names)) - len(\n",
    "        set(mi_selection + true_names))\n",
    "    mi_sensitivity = mi_sensitivity / len(true_names)\n",
    "    skmi_sensitivity = len(set(skmi_selection)) + len(set(true_names)) - len(\n",
    "        set(skmi_selection + true_names))\n",
    "    skmi_sensitivity = skmi_sensitivity / len(true_names)\n",
    "    pearson_sensitivity = len(set(pearson_selection)) + len(\n",
    "        set(true_names)) - len(set(pearson_selection + true_names))\n",
    "    pearson_sensitivity = pearson_sensitivity / len(true_names)\n",
    "\n",
    "    del mi_output, skmi_output, pearson_output, abide, abide_name, true_names, true_beta, sim_data, signal, outcome, mi_selection, skmi_selection, pearson_selection\n",
    "\n",
    "    return np.array([mi_sensitivity, skmi_sensitivity, pearson_sensitivity])\n",
    "\n",
    "\n",
    "num_true_vars_list = [{_num_true_vars_iter}]\n",
    "seed_list = range(100)\n",
    "\n",
    "itrs = itertools.product(num_true_vars_list, seed_list)\n",
    "\n",
    "output_array = np.array(list(map(sim_based_on_abide_binary, tqdm(itrs))))\n",
    "output_array = output_array.reshape(1, 100, 3).squeeze()\n",
    "np.save(r\"./ABIDE_sim_binary_{_num_true_vars_iter}\", output_array)\n",
    "\"\"\".format(_num_true_vars_iter=num_true_vars_iter)\n",
    "\n",
    "    Path(r\"./ABIDE_simulations/ABIDE_sim_\" + outcome +\n",
    "         r\"_{_num_true_vars_iter}\".format(\n",
    "             _num_true_vars_iter=num_true_vars_iter) + \".py\").touch()\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_simulations/ABIDE_sim_\" + outcome +\n",
    "        r\"_{_num_true_vars_iter}\".format(\n",
    "            _num_true_vars_iter=num_true_vars_iter) + \".py\", \"w\")\n",
    "    py_script.write(py_1 + py_2)\n",
    "\n",
    "    Path(r\"./ABIDE_simulations/ABIDE_sim_\" + outcome +\n",
    "         r\"_{_num_true_vars_iter}\".format(\n",
    "             _num_true_vars_iter=num_true_vars_iter) + \".sh\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_simulations/ABIDE_sim_\" + outcome +\n",
    "        r\"_{_num_true_vars_iter}\".format(\n",
    "            _num_true_vars_iter=num_true_vars_iter) + \".sh\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=32\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name={outcome}_{_num_true_vars_iter}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.1\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.1 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.23.6\n",
    "# pip install fastHDMI==1.23.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.1+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.23.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_sim_{outcome}_{_num_true_vars_iter}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_sim_{outcome}_{_num_true_vars_iter}.py\n",
    "\"\"\".format(outcome=outcome, _num_true_vars_iter=num_true_vars_iter))\n",
    "\n",
    "\n",
    "num_true_vars_list = list(map(int, np.linspace(0, 50000,\n",
    "                                               6)))[1:]  # we don't want 0 here\n",
    "\n",
    "for outcome in [\"continuous\", \"binary\"]:\n",
    "    for num_true_vars_iter in num_true_vars_list:\n",
    "        job_generator(outcome=outcome, num_true_vars_iter=num_true_vars_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5dba2",
   "metadata": {},
   "source": [
    "## Plots for Simulation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e6222c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:47.985656Z",
     "start_time": "2023-04-24T20:45:47.723057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data file pointed to doesn't exist\n",
      "the data file pointed to doesn't exist\n",
      "the data file pointed to doesn't exist\n",
      "the data file pointed to doesn't exist\n",
      "the data file pointed to doesn't exist\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data file pointed to doesn't exist\n",
      "the data file pointed to doesn't exist\n",
      "the data file pointed to doesn't exist\n",
      "the data file pointed to doesn't exist\n",
      "the data file pointed to doesn't exist\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mean = np.zeros((len(num_true_vars_list), 3))\n",
    "plot_se = np.zeros((len(num_true_vars_list), 3))\n",
    "\n",
    "for outcome in [\"continuous\", \"binary\"]:\n",
    "    j = 0\n",
    "    for num_true_vars_iter in num_true_vars_list:\n",
    "        try:\n",
    "            computing_results = np.load(\n",
    "                r\"./ABIDE_simulations/ABIDE_sim_{_outcome}_{_num_true_vars_iter}.npy\"\n",
    "                .format(_outcome=outcome,\n",
    "                        _num_true_vars_iter=num_true_vars_iter))\n",
    "            plot_mean[j, :] = np.mean(computing_results, axis=0)\n",
    "            plot_se[j, :] = np.std(computing_results, axis=0)\n",
    "        except:\n",
    "            print(\"the data file pointed to doesn't exist\")\n",
    "            plot_mean[j, :] = np.nan\n",
    "            plot_se[j, :] = np.nan\n",
    "        j += 1\n",
    "\n",
    "    plt.plot(num_true_vars_list,\n",
    "             plot_mean[:, 0],\n",
    "             label=\"MI based on FFTKDE\",\n",
    "             color=\"b\")\n",
    "    plt.fill_between(num_true_vars_list,\n",
    "                     (plot_mean[:, 0] + plot_se[:, 0] * norm.ppf(0.025)),\n",
    "                     (plot_mean[:, 0] + plot_se[:, 0] * norm.ppf(0.975)),\n",
    "                     color=\"b\",\n",
    "                     alpha=.1)\n",
    "\n",
    "    plt.plot(num_true_vars_list,\n",
    "             plot_mean[:, 1],\n",
    "             label=\"MI based on sklearn\",\n",
    "             color=\"y\")\n",
    "    plt.fill_between(num_true_vars_list,\n",
    "                     (plot_mean[:, 1] + plot_se[:, 1] * norm.ppf(0.025)),\n",
    "                     (plot_mean[:, 1] + plot_se[:, 1] * norm.ppf(0.975)),\n",
    "                     color=\"y\",\n",
    "                     alpha=.1)\n",
    "\n",
    "    plt.plot(num_true_vars_list,\n",
    "             plot_mean[:, 2],\n",
    "             label=\"Pearson's correlation\",\n",
    "             color=\"g\")\n",
    "    plt.fill_between(num_true_vars_list,\n",
    "                     (plot_mean[:, 2] + plot_se[:, 2] * norm.ppf(0.025)),\n",
    "                     (plot_mean[:, 2] + plot_se[:, 2] * norm.ppf(0.975)),\n",
    "                     color=\"g\",\n",
    "                     alpha=.1)\n",
    "\n",
    "    plt.title(r\"Simulation study for: \" + outcome)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74af34a",
   "metadata": {},
   "source": [
    "# Calculate MI for ABIDE data age and diagnosis outcome\n",
    "## creating job submission scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75940522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:48.017285Z",
     "start_time": "2023-04-24T20:45:47.986404Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def engine_and_share_memory_status(mem_setting):\n",
    "    if mem_setting == \"high_mem\":\n",
    "        return \"c\", False\n",
    "    elif mem_setting == \"share_mem\":\n",
    "        return \"c\", True\n",
    "    elif mem_setting == \"dask\":\n",
    "        return \"dask\", False\n",
    "\n",
    "\n",
    "def job_generator(mem_setting, outcome):\n",
    "    py_1 = r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "# abide = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "abide = dd.read_csv(csv_file, sample=1250000)\n",
    "\n",
    "# _abide_name = abide.columns.tolist()[1:]\n",
    "_abide_name = list(abide.columns)[1:]\n",
    "\n",
    "# print(_abide_name)\n",
    "\n",
    "# we don't inlcude age and sex in the screening since we choose to always include them in the model\n",
    "\"\"\"\n",
    "    if outcome == \"age\":\n",
    "        py_2 = r\"\"\"\n",
    "abide_name = [_abide_name[-3]] + _abide_name[1:-3]\n",
    "# so that the left first column is the outcome and the rest columns are areas\n",
    "\n",
    "np.save(r\"./ABIDE_columns\", _abide_name[1:-3])\n",
    "\n",
    "del _abide_name\n",
    "\n",
    "print(\"The outcome is age.\")\n",
    "print(\n",
    "    \"Now running using {_csv_engine} CSV engine with share_memory={_share_mem_status}.\"\n",
    ")\n",
    "print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        try:\n",
    "            mi_output = mi.continuous_screening_csv_parallel(\n",
    "                csv_file,\n",
    "                _usecols=abide_name.copy(),\n",
    "                csv_engine=\"{_csv_engine}\",\n",
    "                sample=1250000,\n",
    "                multp=10,\n",
    "                core_num=16,\n",
    "                share_memory={_share_mem_status},\n",
    "                kernel=_kernel,\n",
    "                bw=_bw,\n",
    "                norm=2)\n",
    "            if \"{mem_setting}\" == \"high_mem\":\n",
    "                np.save(\n",
    "                    r\"./ABIDE_age_MI_{{kernel}}_{{bw}}_output\".format(\n",
    "                        kernel=_kernel, bw=_bw), mi_output)\n",
    "\n",
    "            del mi_output\n",
    "\n",
    "        except:\n",
    "            print(\"This kernel-bw combination reports an error: \", _kernel,\n",
    "                  _bw)\n",
    "\n",
    "print(\"sklearn MI calculation:\")\n",
    "\n",
    "skmi_output = mi.continuous_skMI_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    random_state=0,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_age_skMI_output\", skmi_output)\n",
    "\n",
    "del skmi_output\n",
    "\n",
    "print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "pearson_output = mi.Pearson_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_age_Pearson_output\", pearson_output)\n",
    "\n",
    "del pearson_output\n",
    "\"\"\".format(_csv_engine=engine_and_share_memory_status(mem_setting)[0],\n",
    "           _share_mem_status=engine_and_share_memory_status(mem_setting)[1],\n",
    "           mem_setting=mem_setting)\n",
    "    elif outcome == \"diagnosis\":\n",
    "        py_2 = r\"\"\"\n",
    "abide_name = [_abide_name[-1]] + _abide_name[1:-3]\n",
    "# so that the left first column is the outcome and the rest columns are areas\n",
    "\n",
    "del _abide_name\n",
    "\n",
    "print(\"The outcome is diagnosis.\")\n",
    "print(\n",
    "    \"Now running using {_csv_engine} CSV engine with share_memory={_share_mem_status}.\"\n",
    ")\n",
    "print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        try:\n",
    "            mi_output = mi.binary_screening_csv_parallel(\n",
    "                csv_file,\n",
    "                _usecols=abide_name.copy(),\n",
    "                csv_engine=\"{_csv_engine}\",\n",
    "                sample=1250000,\n",
    "                multp=10,\n",
    "                core_num=16,\n",
    "                share_memory={_share_mem_status},\n",
    "                kernel=_kernel,\n",
    "                bw=_bw)\n",
    "            if \"{mem_setting}\" == \"high_mem\":\n",
    "                np.save(\n",
    "                    r\"./ABIDE_diagnosis_MI_{{kernel}}_{{bw}}_output\".format(\n",
    "                        kernel=_kernel, bw=_bw), mi_output)\n",
    "\n",
    "            del mi_output\n",
    "\n",
    "        except:\n",
    "            print(\"This kernel-bw combination reports an error: \", _kernel,\n",
    "                  _bw)\n",
    "\n",
    "print(\"sklearn MI calculation:\")\n",
    "\n",
    "skmi_output = mi.binary_skMI_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    random_state=0,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_diagnosis_skMI_output\", skmi_output)\n",
    "\n",
    "del skmi_output\n",
    "\n",
    "print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "pearson_output = mi.Pearson_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=16,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_diagnosis_Pearson_output\", pearson_output)\n",
    "\n",
    "del pearson_output\n",
    "\"\"\".format(_csv_engine=engine_and_share_memory_status(mem_setting)[0],\n",
    "           _share_mem_status=engine_and_share_memory_status(mem_setting)[1],\n",
    "           mem_setting=mem_setting)\n",
    "\n",
    "    Path(r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".py\").touch()\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".py\", \"w\")\n",
    "    py_script.write(py_1 + py_2)\n",
    "\n",
    "    Path(r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".sh\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".sh\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=20:00:00\n",
    "#SBATCH --job-name=ABIDE_screening_{outcome}_{mem_setting}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.1\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.1 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.23.6\n",
    "# pip install fastHDMI==1.23.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.1+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.23.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_screening_{outcome}_{mem_setting}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_screening_{outcome}_{mem_setting}.py\n",
    "\"\"\".format(outcome=outcome, mem_setting=mem_setting))\n",
    "\n",
    "\n",
    "for mem_setting in [\"high_mem\", \"share_mem\", \"dask\"]:\n",
    "    for outcome in [\"age\", \"diagnosis\"]:\n",
    "        job_generator(mem_setting=mem_setting, outcome=outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525e566f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:48.019476Z",
     "start_time": "2023-04-24T20:45:48.017873Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea4ca1-abfd-4856-8f70-63658655173a",
   "metadata": {},
   "source": [
    "# Plots for age\n",
    "## Comparing two ranking with Kendall's $\\tau$\n",
    "\n",
    "**So in summary, the two ranking vary somehow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb054aa1-5485-4ea5-8f0b-5eefadf893ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:48.021788Z",
     "start_time": "2023-04-24T20:45:48.020099Z"
    }
   },
   "outputs": [],
   "source": [
    "# abide_mi = np.load(r\"./ABIDE_age_MI_output.npy\")\n",
    "# plt.hist(np.log(abide_mi), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_pearson = np.load(r\"./ABIDE_age_Pearson_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_skmi = np.load(r\"./ABIDE_age_skMI_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Kendall'stau for MI vs Pearson: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_pearson))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_pearson, s=10,\n",
    "#             alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT AGE\n",
    "\n",
    "# print(\"Kendall'stau for MI vs skMI: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_skmi))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_skmi, s=10, alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT AGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de0251",
   "metadata": {},
   "source": [
    "# Plots for diagnosis\n",
    "## Comparing two ranking with Kendall's $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5230b75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:48.024114Z",
     "start_time": "2023-04-24T20:45:48.022470Z"
    }
   },
   "outputs": [],
   "source": [
    "# abide_mi = np.load(r\"./ABIDE_diagnosis_MI_output.npy\")\n",
    "# plt.hist(np.log(abide_mi), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_pearson = np.load(r\"./ABIDE_diagnosis_Pearson_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_skmi = np.load(r\"./ABIDE_diagnosis_skMI_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Kendall'stau for MI vs Pearson: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_pearson))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_pearson, s=10,\n",
    "#             alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT diagnosis\n",
    "\n",
    "# print(\"Kendall'stau for MI vs skMI: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_skmi))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_skmi, s=10, alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ebdd3",
   "metadata": {},
   "source": [
    "# A scatter plot for age and diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfce6fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:48.035361Z",
     "start_time": "2023-04-24T20:45:48.024751Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator():\n",
    "    Path(r\"./ABIDE_scatterplot/scatter_plot_for_most_associated.sh\").touch()\n",
    "    Path(r\"./ABIDE_scatterplot/scatter_plot_for_most_associated.py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_scatterplot/scatter_plot_for_most_associated.sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_scatterplot/scatter_plot_for_most_associated.py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=2:00:00\n",
    "#SBATCH --job-name=scatter_plot_for_most_associated\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.1\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.1 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.23.6\n",
    "# pip install fastHDMI==1.23.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.1+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.23.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running scatter_plot_for_most_associated.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_MI_epa_ISJ_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_Pearson_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_skMI_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_MI_epa_ISJ_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_Pearson_output.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_skMI_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 scatter_plot_for_most_associated.py\n",
    "    \"\"\")\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "top_colnames_num = 5\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "\n",
    "for outcome in [\"diagnosis\", \"age\"]:\n",
    "    top_colnames = []\n",
    "    for dep_measure in [\"MI_epa_ISJ\", \"Pearson\", \"skMI\"]:\n",
    "        abide_dep = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_\" + outcome +\n",
    "                            r\"_\" + dep_measure + r\"_output.npy\")\n",
    "        abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "        top_colnames = np.hstack(\n",
    "            (top_colnames, columns[np.argsort(-abide_dep)][:top_colnames_num]))\n",
    "\n",
    "    top_colnames = list(set(top_colnames))\n",
    "    for colname in top_colnames:\n",
    "        if outcome == \"diagnosis\":\n",
    "            plt.scatter(original_df[\"DX_GROUP\"],\n",
    "                        original_df[colname],\n",
    "                        alpha=.2)\n",
    "        if outcome == \"age\":\n",
    "            plt.scatter(original_df[\"AGE_AT_SCAN\"],\n",
    "                        original_df[colname],\n",
    "                        alpha=.2)\n",
    "        plt.ylabel(outcome)\n",
    "        plt.xlabel(colname)\n",
    "        plt.title(r\"scatter plot for outcome vs the top associated covariates: \" + outcome +\n",
    "                  r\" and \" + colname)\n",
    "        plt.savefig(r\"scatter_\" + outcome + r\"_\" + colname)\n",
    "        plt.close()\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "job_creator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447fa79",
   "metadata": {},
   "source": [
    "# Try Fitting models to predict age, $5$-fold CV for hyper-parameter tuning\n",
    "## create job submission scripts for `ABIDE_predict_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10871140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:49.415724Z",
     "start_time": "2023-04-24T20:45:48.036110Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "         \".sh\").touch()\n",
    "    Path(r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "         \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "        \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "        \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name=age_{dep_measure}_{fun_name}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.1\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.1 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.23.6\n",
    "# pip install fastHDMI==1.23.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.1+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.23.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_age_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_age_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(os.environ[\"SLURM_TMPDIR\"] +\n",
    "                    r\"/ABIDE_age_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def binning(var, num_bins, min_num=2):\n",
    "    bins = np.linspace(np.min(var) - 1e-8, np.max(var) + 1e-8, num_bins)\n",
    "    var_binned = np.digitize(var, bins)\n",
    "    category = np.sort(np.unique(var_binned))\n",
    "    while len([\n",
    "            x for x in category if np.count_nonzero(var_binned == x) < min_num\n",
    "    ]) != 0:\n",
    "        for j in range(len(category)):\n",
    "            if j < len(\n",
    "                    category\n",
    "            ):  # since category is always updated, we add this to avoid out of index error; alternatively, a while loop also works\n",
    "                if np.count_nonzero(\n",
    "                        var_binned == category[j]\n",
    "                ) < min_num:  # if the number of observations in a category is less than min_num\n",
    "                    if j == 0:  # if it's the first category, combine it with the second\n",
    "                        var_binned[var_binned == category[j]] = category[j + 1]\n",
    "                    else:  # if it's not the first category, combine it with the previous one\n",
    "                        var_binned[var_binned == category[j]] = category[j - 1]\n",
    "                    category = np.sort(np.unique(var_binned))\n",
    "    return var_binned\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((\n",
    "        outcome_name,  # \"SEX\", \"DX_GROUP\",\n",
    "        columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor, LinearRegression\n",
    "        ]:\n",
    "            y_binned = binning(y, 30, min_num=2)\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [LinearRegression]:\n",
    "            fit = fun(n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LogisticRegression]:\n",
    "            fit = fun(penalty=None, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(map(int,\n",
    "                      np.around(np.linspace(0, 50, 10 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"AGE_AT_SCAN\",\n",
    "    num_rep=20)\n",
    "np.save(r\"./ABIDE_age_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LassoCV\", \"ElasticNetCV\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\",\n",
    "        \"MLPRegressor\", \"RandomForestRegressor\", \"LinearRegression\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee471054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:49.423335Z",
     "start_time": "2023-04-24T20:45:49.420944Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df160684",
   "metadata": {},
   "source": [
    "## create job submission scripts for `ABIDE_poly3_predict_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da95d107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:50.778847Z",
     "start_time": "2023-04-24T20:45:49.426786Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-cgreenwo\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name=poly3_age_{dep_measure}_{fun_name}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.1\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.1 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.23.6\n",
    "# pip install fastHDMI==1.23.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.1+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.23.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_poly3_age_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_poly3_age_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(os.environ[\"SLURM_TMPDIR\"] +\n",
    "                    r\"/ABIDE_age_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def binning(var, num_bins, min_num=2):\n",
    "    bins = np.linspace(np.min(var) - 1e-8, np.max(var) + 1e-8, num_bins)\n",
    "    var_binned = np.digitize(var, bins)\n",
    "    category = np.sort(np.unique(var_binned))\n",
    "    while len([\n",
    "            x for x in category if np.count_nonzero(var_binned == x) < min_num\n",
    "    ]) != 0:\n",
    "        for j in range(len(category)):\n",
    "            if j < len(\n",
    "                    category\n",
    "            ):  # since category is always updated, we add this to avoid out of index error; alternatively, a while loop also works\n",
    "                if np.count_nonzero(\n",
    "                        var_binned == category[j]\n",
    "                ) < min_num:  # if the number of observations in a category is less than min_num\n",
    "                    if j == 0:  # if it's the first category, combine it with the second\n",
    "                        var_binned[var_binned == category[j]] = category[j + 1]\n",
    "                    else:  # if it's not the first category, combine it with the previous one\n",
    "                        var_binned[var_binned == category[j]] = category[j - 1]\n",
    "                    category = np.sort(np.unique(var_binned))\n",
    "    return var_binned\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((\n",
    "        outcome_name,  # \"SEX\", \"DX_GROUP\",\n",
    "        columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        X = SplineTransformer(n_knots=2,\n",
    "                              degree=3,\n",
    "                              extrapolation=\"continue\",\n",
    "                              include_bias=False).fit_transform(X)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor, LinearRegression\n",
    "        ]:\n",
    "            y_binned = binning(y, 30, min_num=2)\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [LinearRegression]:\n",
    "            fit = fun(n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LogisticRegression]:\n",
    "            fit = fun(penalty=None, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_poly3_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(map(int,\n",
    "                      np.around(np.linspace(0, 50, 10 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"AGE_AT_SCAN\",\n",
    "    num_rep=20)\n",
    "np.save(r\"./ABIDE_poly3_age_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LassoCV\", \"ElasticNetCV\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\",\n",
    "        \"MLPRegressor\", \"RandomForestRegressor\", \"LinearRegression\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47f58409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:50.786357Z",
     "start_time": "2023-04-24T20:45:50.782701Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777df55",
   "metadata": {},
   "source": [
    "# Comparison of Performance\n",
    "## Here is just to show the testing set $R^2$ using plots\n",
    "### using variables directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77de1868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:50.905257Z",
     "start_time": "2023-04-24T20:45:50.789208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_{dep_measure}_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)) and os.path.isfile(\n",
    "                r\"./ABIDE_predict_age/ABIDE_age_Pearson_{fun_name}.npy\".format(\n",
    "                    fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_age_MI_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_{dep_measure}_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_age_skMI_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_skMI_{fun_name}.npy\".format(\n",
    "                fun_name=fun_name))\n",
    "        ABIDE_age_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_Pearson_{fun_name}.npy\".format(\n",
    "                fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 50, 10 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_age_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_age_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_age_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_age_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_age_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_age_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr, MI_fit_mean, label=dep_measure, color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPRegressor\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\", \"LassoCV\",\n",
    "            \"ElasticNetCV\", \"RandomForestRegressor\", \"LinearRegression\"\n",
    "    ]:\n",
    "        if dep_measure == \"MI_epa_ISJ\":\n",
    "            plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "            plt.savefig(r\"./ABIDE_predict_age/\" + fun_name + dep_measure)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ff14b",
   "metadata": {},
   "source": [
    "### using Bernstein polynomials of degree $3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e3ccaee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:50.998558Z",
     "start_time": "2023-04-24T20:45:50.906141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_age_MI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_age_skMI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name))\n",
    "        ABIDE_age_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 50, 10 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_age_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_age_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_age_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_age_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_age_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_age_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr, MI_fit_mean, label=dep_measure, color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPRegressor\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\", \"LassoCV\",\n",
    "            \"ElasticNetCV\", \"RandomForestRegressor\", \"LinearRegression\"\n",
    "    ]:\n",
    "        if dep_measure == \"MI_epa_ISJ\":\n",
    "            plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "            plt.savefig(r\"./ABIDE_poly3_predict_age/\" + fun_name + dep_measure)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1a5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T21:28:21.063315Z",
     "start_time": "2023-02-16T21:28:20.629362Z"
    }
   },
   "source": [
    "# Try Fitting models to predict diagnosis, $5$-fold CV\n",
    "## create job submission scripts for `ABIDE_predict_diagnosis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6939ef62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:52.072516Z",
     "start_time": "2023-04-24T20:45:50.999447Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name=diagnosis_{dep_measure}_{fun_name}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.1\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.1 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.23.6\n",
    "# pip install fastHDMI==1.23.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.1+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.23.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_diagnosis_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_diagnosis_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(\n",
    "    os.environ[\"SLURM_TMPDIR\"] +\n",
    "    r\"/ABIDE_diagnosis_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def binning(var, num_bins, min_num=2):\n",
    "    bins = np.linspace(np.min(var) - 1e-8, np.max(var) + 1e-8, num_bins)\n",
    "    var_binned = np.digitize(var, bins)\n",
    "    category = np.sort(np.unique(var_binned))\n",
    "    while len([\n",
    "            x for x in category if np.count_nonzero(var_binned == x) < min_num\n",
    "    ]) != 0:\n",
    "        for j in range(len(category)):\n",
    "            if j < len(\n",
    "                    category\n",
    "            ):  # since category is always updated, we add this to avoid out of index error; alternatively, a while loop also works\n",
    "                if np.count_nonzero(\n",
    "                        var_binned == category[j]\n",
    "                ) < min_num:  # if the number of observations in a category is less than min_num\n",
    "                    if j == 0:  # if it's the first category, combine it with the second\n",
    "                        var_binned[var_binned == category[j]] = category[j + 1]\n",
    "                    else:  # if it's not the first category, combine it with the previous one\n",
    "                        var_binned[var_binned == category[j]] = category[j - 1]\n",
    "                    category = np.sort(np.unique(var_binned))\n",
    "    return var_binned\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((\n",
    "        outcome_name,  # \"SEX\", \"AGE_AT_SCAN\",\n",
    "        columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor, LinearRegression\n",
    "        ]:\n",
    "            y_binned = binning(y, 30, min_num=2)\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [LinearRegression]:\n",
    "            fit = fun(n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LogisticRegression]:\n",
    "            fit = fun(penalty=None, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(map(int,\n",
    "                      np.around(np.linspace(0, 50, 10 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"DX_GROUP\",\n",
    "    num_rep=20)\n",
    "np.save(r\"./ABIDE_diagnosis_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_l2\",\n",
    "        \"LogisticRegressionCV_ElasticNet\", \"MLPClassifier\",\n",
    "        \"RandomForestClassifier\", \"LogisticRegression\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd017b70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:52.077397Z",
     "start_time": "2023-04-24T20:45:52.074768Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49c3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T21:28:21.063315Z",
     "start_time": "2023-02-16T21:28:20.629362Z"
    }
   },
   "source": [
    "## create job submission scripts for `ABIDE_poly3_predict_diagnosis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1bc6195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:45:52.987012Z",
     "start_time": "2023-04-24T20:45:52.080095Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "         dep_measure + \"_\" + fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "         dep_measure + \"_\" + fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "        dep_measure + \"_\" + fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "        dep_measure + \"_\" + fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-cgreenwo\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=3-12:00:00\n",
    "#SBATCH --job-name=poly3_diagnosis_{dep_measure}_{fun_name}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip Cython\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "# ### upgrading the tools\n",
    "# pip install --upgrade pip setuptools wheel\n",
    "# ### remove all old wheels\n",
    "# rm *.whl\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.1\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.1 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.23.6\n",
    "# pip install fastHDMI==1.23.6 --no-cache-dir\n",
    "# pip wheel fastHDMI --no-deps\n",
    "\n",
    "# # Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2 pandas dask Cython\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.1+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.23.6-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV, LinearRegression, LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(\n",
    "    os.environ[\"SLURM_TMPDIR\"] +\n",
    "    r\"/ABIDE_diagnosis_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def binning(var, num_bins, min_num=2):\n",
    "    bins = np.linspace(np.min(var) - 1e-8, np.max(var) + 1e-8, num_bins)\n",
    "    var_binned = np.digitize(var, bins)\n",
    "    category = np.sort(np.unique(var_binned))\n",
    "    while len([\n",
    "            x for x in category if np.count_nonzero(var_binned == x) < min_num\n",
    "    ]) != 0:\n",
    "        for j in range(len(category)):\n",
    "            if j < len(\n",
    "                    category\n",
    "            ):  # since category is always updated, we add this to avoid out of index error; alternatively, a while loop also works\n",
    "                if np.count_nonzero(\n",
    "                        var_binned == category[j]\n",
    "                ) < min_num:  # if the number of observations in a category is less than min_num\n",
    "                    if j == 0:  # if it's the first category, combine it with the second\n",
    "                        var_binned[var_binned == category[j]] = category[j + 1]\n",
    "                    else:  # if it's not the first category, combine it with the previous one\n",
    "                        var_binned[var_binned == category[j]] = category[j - 1]\n",
    "                    category = np.sort(np.unique(var_binned))\n",
    "    return var_binned\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((\n",
    "        outcome_name,  # \"SEX\", \"AGE_AT_SCAN\",\n",
    "        columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        X = SplineTransformer(n_knots=2,\n",
    "                              degree=3,\n",
    "                              extrapolation=\"continue\",\n",
    "                              include_bias=False).fit_transform(X)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor, LinearRegression\n",
    "        ]:\n",
    "            y_binned = binning(y, 30, min_num=2)\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=16, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=16,\n",
    "                      n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [LinearRegression]:\n",
    "            fit = fun(n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LogisticRegression]:\n",
    "            fit = fun(penalty=None, n_jobs=16).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_poly3_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(map(int,\n",
    "                      np.around(np.linspace(0, 50, 10 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"DX_GROUP\",\n",
    "    num_rep=20)\n",
    "np.save(r\"./ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_l2\",\n",
    "        \"LogisticRegressionCV_ElasticNet\", \"MLPClassifier\",\n",
    "        \"RandomForestClassifier\", \"LogisticRegression\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75a9b3a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:51:38.461781Z",
     "start_time": "2023-04-24T20:45:52.988890Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5658d",
   "metadata": {},
   "source": [
    "# Comparison of Performance\n",
    "## Here is just to show the testing set ROC\n",
    "### using variables directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6920631b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:51:38.549366Z",
     "start_time": "2023-04-24T20:51:38.464261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_diagnosis_MI_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_diagnosis_skMI_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name))\n",
    "        ABIDE_diagnosis_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 50, 10 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_diagnosis_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_diagnosis_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr, MI_fit_mean, label=dep_measure, color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPClassifier\", \"LogisticRegressionCV_l2\",\n",
    "            \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_ElasticNet\",\n",
    "            \"RandomForestClassifier\", \"LogisticRegression\"\n",
    "    ]:\n",
    "        if dep_measure == \"MI_epa_ISJ\":\n",
    "            plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "            plt.savefig(r\"./ABIDE_predict_diagnosis/\" + fun_name + dep_measure)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cafeb18",
   "metadata": {},
   "source": [
    "### using Bernstein polynomials of degree $3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e899df18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:51:38.624991Z",
     "start_time": "2023-04-24T20:51:38.550350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_skMI_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_diagnosis_MI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_diagnosis_skMI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_skMI_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        ABIDE_diagnosis_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 50, 10 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_diagnosis_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_diagnosis_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr, MI_fit_mean, label=dep_measure, color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPClassifier\", \"LogisticRegressionCV_l2\",\n",
    "            \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_ElasticNet\",\n",
    "            \"RandomForestClassifier\", \"LogisticRegression\"\n",
    "    ]:\n",
    "        if dep_measure == \"MI_epa_ISJ\":\n",
    "            plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "            plt.savefig(r\"./ABIDE_poly3_predict_diagnosis/\" + fun_name +\n",
    "                        dep_measure)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889857c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
