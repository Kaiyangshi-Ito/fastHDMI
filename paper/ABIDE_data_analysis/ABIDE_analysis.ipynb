{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39eea284-aeec-427b-b3fc-2a35d72a5825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:12.658308Z",
     "start_time": "2023-03-03T21:19:11.213943Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "# import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74af34a",
   "metadata": {},
   "source": [
    "# Calculate MI for ABIDE data age and diagnosis outcome\n",
    "## this block is only to be run on Compute Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75940522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:12.694126Z",
     "start_time": "2023-03-03T21:19:12.659481Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def engine_and_share_memory_status(mem_setting):\n",
    "    if mem_setting == \"high_mem\":\n",
    "        return \"c\", False\n",
    "    elif mem_setting == \"share_mem\":\n",
    "        return \"c\", True\n",
    "    elif mem_setting == \"dask\":\n",
    "        return \"dask\", False\n",
    "\n",
    "\n",
    "def job_generator(mem_setting, outcome):\n",
    "    py_1 = r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "# abide = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "abide = dd.read_csv(csv_file, sample=1250000)\n",
    "\n",
    "# _abide_name = abide.columns.tolist()[1:]\n",
    "_abide_name = list(abide.columns)[1:]\n",
    "\n",
    "# print(_abide_name)\n",
    "\n",
    "# we don't inlcude age and sex in the screening since we choose to always include them in the model\n",
    "\"\"\"\n",
    "    if outcome == \"age\":\n",
    "        py_2 = r\"\"\"\n",
    "abide_name = [_abide_name[-3]] + _abide_name[1:-3]\n",
    "# so that the left first column is the outcome and the rest columns are areas\n",
    "\n",
    "np.save(r\"./ABIDE_columns\", _abide_name[1:-3])\n",
    "\n",
    "del _abide_name\n",
    "\n",
    "print(\"The outcome is age.\")\n",
    "print(\n",
    "    \"Now running using {_csv_engine} CSV engine with share_memory={_share_mem_status}.\"\n",
    ")\n",
    "print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        try:\n",
    "            mi_output = mi.continuous_screening_csv_parallel(\n",
    "                csv_file,\n",
    "                _usecols=abide_name.copy(),\n",
    "                csv_engine=\"{_csv_engine}\",\n",
    "                sample=1250000,\n",
    "                multp=10,\n",
    "                core_num=10,\n",
    "                share_memory={_share_mem_status},\n",
    "                kernel=_kernel,\n",
    "                bw=_bw,\n",
    "                norm=2)\n",
    "            if \"{mem_setting}\" == \"high_mem\":\n",
    "                np.save(\n",
    "                    r\"./ABIDE_age_MI_{{kernel}}_{{bw}}_output\".format(\n",
    "                        kernel=_kernel, bw=_bw), mi_output)\n",
    "\n",
    "            del mi_output\n",
    "\n",
    "        except:\n",
    "            print(\"This kernel-bw combination reports an error: \", _kernel,\n",
    "                  _bw)\n",
    "\n",
    "print(\"sklearn MI calculation:\")\n",
    "\n",
    "skmi_output = mi.continuous_skMI_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=10,\n",
    "    random_state=0,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_age_skMI_output\", skmi_output)\n",
    "\n",
    "del skmi_output\n",
    "\n",
    "print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "pearson_output = mi.Pearson_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=10,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_age_Pearson_output\", pearson_output)\n",
    "\n",
    "del pearson_output\n",
    "\"\"\".format(_csv_engine=engine_and_share_memory_status(mem_setting)[0],\n",
    "           _share_mem_status=engine_and_share_memory_status(mem_setting)[1],\n",
    "           mem_setting=mem_setting)\n",
    "    elif outcome == \"diagnosis\":\n",
    "        py_2 = r\"\"\"\n",
    "abide_name = [_abide_name[-1]] + _abide_name[1:-3]\n",
    "# so that the left first column is the outcome and the rest columns are areas\n",
    "\n",
    "del _abide_name\n",
    "\n",
    "print(\"The outcome is diagnosis.\")\n",
    "print(\n",
    "    \"Now running using {_csv_engine} CSV engine with share_memory={_share_mem_status}.\"\n",
    ")\n",
    "print(\"Our developed FFT-based MI calculation:\")\n",
    "\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        try:\n",
    "            mi_output = mi.binary_screening_csv_parallel(\n",
    "                csv_file,\n",
    "                _usecols=abide_name.copy(),\n",
    "                csv_engine=\"{_csv_engine}\",\n",
    "                sample=1250000,\n",
    "                multp=10,\n",
    "                core_num=10,\n",
    "                share_memory={_share_mem_status},\n",
    "                kernel=_kernel,\n",
    "                bw=_bw)\n",
    "            if \"{mem_setting}\" == \"high_mem\":\n",
    "                np.save(\n",
    "                    r\"./ABIDE_diagnosis_MI_{{kernel}}_{{bw}}_output\".format(\n",
    "                        kernel=_kernel, bw=_bw), mi_output)\n",
    "\n",
    "            del mi_output\n",
    "\n",
    "        except:\n",
    "            print(\"This kernel-bw combination reports an error: \", _kernel,\n",
    "                  _bw)\n",
    "\n",
    "print(\"sklearn MI calculation:\")\n",
    "\n",
    "skmi_output = mi.binary_skMI_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=10,\n",
    "    random_state=0,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_diagnosis_skMI_output\", skmi_output)\n",
    "\n",
    "del skmi_output\n",
    "\n",
    "print(\"Pearson's correlation calculation:\")\n",
    "\n",
    "pearson_output = mi.Pearson_screening_csv_parallel(\n",
    "    csv_file,\n",
    "    _usecols=abide_name.copy(),\n",
    "    csv_engine=\"{_csv_engine}\",\n",
    "    sample=1250000,\n",
    "    multp=10,\n",
    "    core_num=10,\n",
    "    share_memory={_share_mem_status})\n",
    "if \"{mem_setting}\" == \"high_mem\":\n",
    "    np.save(r\"./ABIDE_diagnosis_Pearson_output\", pearson_output)\n",
    "\n",
    "del pearson_output\n",
    "\"\"\".format(_csv_engine=engine_and_share_memory_status(mem_setting)[0],\n",
    "           _share_mem_status=engine_and_share_memory_status(mem_setting)[1],\n",
    "           mem_setting=mem_setting)\n",
    "\n",
    "    Path(r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".py\").touch()\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".py\", \"w\")\n",
    "    py_script.write(py_1 + py_2)\n",
    "\n",
    "    Path(r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".sh\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_screening_\" + outcome + \"_\" + mem_setting + \".sh\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-cgreenwo\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=20:00:00\n",
    "#SBATCH --job-name=ABIDE_screening_{outcome}_{mem_setting}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.0\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.0 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.18.20\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package fastHDMI --version 1.18.20 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "\n",
    "# Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.0+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.18.20+computecanada-py3-none-any.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_screening_{outcome}_{mem_setting}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_screening_{outcome}_{mem_setting}.py\n",
    "\"\"\".format(outcome=outcome, mem_setting=mem_setting))\n",
    "\n",
    "\n",
    "for mem_setting in [\"high_mem\", \"share_mem\", \"dask\"]:\n",
    "    for outcome in [\"age\", \"diagnosis\"]:\n",
    "        job_generator(mem_setting=mem_setting, outcome=outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525e566f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:13.134542Z",
     "start_time": "2023-03-03T21:19:13.130899Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea4ca1-abfd-4856-8f70-63658655173a",
   "metadata": {},
   "source": [
    "# Plots for age\n",
    "## Comparing two ranking with Kendall's$\\tau$\n",
    "\n",
    "The results show that the two ranking by mutual information and Pearson's correlation vary greatly by Kendall'stau -- I also tried the Pearson's correlation between two ranking (not that I should do this) and the correlation is also very small.\n",
    "\n",
    "**So in summary, the two ranking vary somehow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb054aa1-5485-4ea5-8f0b-5eefadf893ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:13.913783Z",
     "start_time": "2023-03-03T21:19:13.909674Z"
    }
   },
   "outputs": [],
   "source": [
    "# abide_mi = np.load(r\"./ABIDE_age_MI_output.npy\")\n",
    "# plt.hist(np.log(abide_mi), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_pearson = np.load(r\"./ABIDE_age_Pearson_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_skmi = np.load(r\"./ABIDE_age_skMI_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Kendall'stau for MI vs Pearson: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_pearson))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_pearson, s=10,\n",
    "#             alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT AGE\n",
    "\n",
    "# print(\"Kendall'stau for MI vs skMI: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_skmi))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_skmi, s=10, alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT AGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de0251",
   "metadata": {},
   "source": [
    "# Plots for diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5230b75d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:16.514522Z",
     "start_time": "2023-03-03T21:19:16.510667Z"
    }
   },
   "outputs": [],
   "source": [
    "# abide_mi = np.load(r\"./ABIDE_diagnosis_MI_output.npy\")\n",
    "# plt.hist(np.log(abide_mi), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_pearson = np.load(r\"./ABIDE_diagnosis_Pearson_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# abide_skmi = np.load(r\"./ABIDE_diagnosis_skMI_output.npy\")\n",
    "# plt.hist(np.log(np.abs(abide_pearson)), 500)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Kendall'stau for MI vs Pearson: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_pearson))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_pearson, s=10,\n",
    "#             alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT diagnosis\n",
    "\n",
    "# print(\"Kendall'stau for MI vs skMI: \\n\",\n",
    "#       kendalltau(rankdata(-abide_mi), rankdata(-np.abs(abide_skmi))))\n",
    "\n",
    "# plt.scatter(np.log(abide_mi), abide_skmi, s=10, alpha=.2)  # s is the dot size\n",
    "# plt.show()\n",
    "# # keep this, add different selections\n",
    "# # PREDICT diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447fa79",
   "metadata": {},
   "source": [
    "# Try Fitting models to predict age, $5$-fold CV\n",
    "## this block of code only means to be run on Compute Canada\n",
    "### `ABIDE_predict_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10871140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:18.936194Z",
     "start_time": "2023-03-03T21:19:17.871913Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "         \".sh\").touch()\n",
    "    Path(r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "         \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "        \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_predict_age/ABIDE_age_\" + dep_measure + \"_\" + fun_name +\n",
    "        \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-cgreenwo\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=6-12:00:00\n",
    "#SBATCH --job-name=age_{dep_measure}_{fun_name}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.0\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.0 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.18.20\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package fastHDMI --version 1.18.20 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "\n",
    "# Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.0+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.18.20+computecanada-py3-none-any.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_age_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_age_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(os.environ[\"SLURM_TMPDIR\"] +\n",
    "                    r\"/ABIDE_age_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((outcome_name, \"SEX\", \"DX_GROUP\",\n",
    "                          columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor\n",
    "        ]:\n",
    "            bins = np.linspace(np.min(y) - 1e-8,\n",
    "                               np.max(y) + 1e-8, 30)  # choose to use 30 bins\n",
    "            y_binned = np.digitize(y, bins)\n",
    "            y_binned[y_binned >= 20] = 20\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=10, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=10, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=10, n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=10, n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(\n",
    "        map(int,\n",
    "            np.around(np.linspace(0, 1000, 20 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"AGE_AT_SCAN\",\n",
    "    num_rep=30)\n",
    "np.save(r\"./ABIDE_age_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LassoCV\", \"ElasticNetCV\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\",\n",
    "        \"MLPRegressor\", \"RandomForestRegressor\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee471054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:18.944051Z",
     "start_time": "2023-03-03T21:19:18.940548Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df160684",
   "metadata": {},
   "source": [
    "### `ABIDE_poly3_predict_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da95d107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:20.670594Z",
     "start_time": "2023-03-03T21:19:19.648927Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=6-12:00:00\n",
    "#SBATCH --job-name=poly3_age_{dep_measure}_{fun_name}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.0\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.0 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.18.20\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package fastHDMI --version 1.18.20 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "\n",
    "# Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.0+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.18.20+computecanada-py3-none-any.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_poly3_age_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_age_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_poly3_age_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(os.environ[\"SLURM_TMPDIR\"] +\n",
    "                    r\"/ABIDE_age_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((outcome_name, \"SEX\", \"DX_GROUP\",\n",
    "                          columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        X = SplineTransformer(n_knots=2,\n",
    "                              degree=3,\n",
    "                              extrapolation=\"continue\",\n",
    "                              include_bias=False).fit_transform(X)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor\n",
    "        ]:\n",
    "            bins = np.linspace(np.min(y) - 1e-8,\n",
    "                               np.max(y) + 1e-8, 30)  # choose to use 30 bins\n",
    "            y_binned = np.digitize(y, bins)\n",
    "            y_binned[y_binned >= 20] = 20\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=10, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=10, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=10, n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=10, n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_poly3_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(\n",
    "        map(int,\n",
    "            np.around(np.linspace(0, 1000, 20 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"AGE_AT_SCAN\",\n",
    "    num_rep=30)\n",
    "np.save(r\"./ABIDE_poly3_age_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LassoCV\", \"ElasticNetCV\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\",\n",
    "        \"MLPRegressor\", \"RandomForestRegressor\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f58409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:20.679338Z",
     "start_time": "2023-03-03T21:19:20.674875Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777df55",
   "metadata": {},
   "source": [
    "# Comparison of Performance\n",
    "## Here is just to show the testing set $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de1868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:10:51.444234Z",
     "start_time": "2023-03-03T21:10:51.249683Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_{dep_measure}_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)) and os.path.isfile(\n",
    "                r\"./ABIDE_predict_age/ABIDE_age_Pearson_{fun_name}.npy\".format(\n",
    "                    fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_age_MI_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_{dep_measure}_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_age_skMI_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_skMI_{fun_name}.npy\".format(\n",
    "                fun_name=fun_name))\n",
    "        ABIDE_age_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_predict_age/ABIDE_age_Pearson_{fun_name}.npy\".format(\n",
    "                fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 1000, 20 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_age_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_age_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_age_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_age_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_age_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_age_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr, MI_fit_mean, label=dep_measure, color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPRegressor\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\", \"LassoCV\",\n",
    "            \"ElasticNetCV\", \"RandomForestRegressor\"\n",
    "    ]:\n",
    "        plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "        plt.savefig(r\"./ABIDE_predict_age/\" + fun_name + dep_measure)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3ccaee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:10:51.445499Z",
     "start_time": "2023-03-03T21:10:51.445493Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_age_MI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_age_skMI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name))\n",
    "        ABIDE_age_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_age/ABIDE_poly3_age_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 1000, 20 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_age_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_age_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_age_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_age_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_age_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_age_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr, MI_fit_mean, label=dep_measure, color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPRegressor\", \"RidgeCV\", \"LarsCV\", \"LassoLarsCV\", \"LassoCV\",\n",
    "            \"ElasticNetCV\", \"RandomForestRegressor\"\n",
    "    ]:\n",
    "        plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "        plt.savefig(r\"./ABIDE_poly3_predict_age/\" + fun_name + dep_measure)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1a5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T21:28:21.063315Z",
     "start_time": "2023-02-16T21:28:20.629362Z"
    }
   },
   "source": [
    "# Try Fitting models to predict diagnosis, $5$-fold CV\n",
    "## this block of code only means to be run on Compute Canada\n",
    "### `ABIDE_predict_diagnosis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6939ef62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:25.718409Z",
     "start_time": "2023-03-03T21:19:25.091700Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "         fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_\" + dep_measure + \"_\" +\n",
    "        fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-cgreenwo\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=6-12:00:00\n",
    "#SBATCH --job-name=diagnosis_{dep_measure}_{fun_name}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.0\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.0 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.18.20\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package fastHDMI --version 1.18.20 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "\n",
    "# Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.0+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.18.20+computecanada-py3-none-any.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_diagnosis_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_diagnosis_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(\n",
    "    os.environ[\"SLURM_TMPDIR\"] +\n",
    "    r\"/ABIDE_diagnosis_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((outcome_name, \"SEX\", \"AGE_AT_SCAN\",\n",
    "                          columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor\n",
    "        ]:\n",
    "            bins = np.linspace(np.min(y) - 1e-8,\n",
    "                               np.max(y) + 1e-8, 30)  # choose to use 30 bins\n",
    "            y_binned = np.digitize(y, bins)\n",
    "            y_binned[y_binned >= 20] = 20\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=10, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=10, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=10, n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=10, n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(\n",
    "        map(int,\n",
    "            np.around(np.linspace(0, 1000, 20 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"DX_GROUP\",\n",
    "    num_rep=30)\n",
    "np.save(r\"./ABIDE_diagnosis_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_l2\",\n",
    "        \"LogisticRegressionCV_ElasticNet\", \"MLPClassifier\",\n",
    "        \"RandomForestClassifier\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd017b70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:25.724026Z",
     "start_time": "2023-03-03T21:19:25.721803Z"
    }
   },
   "outputs": [],
   "source": [
    "#!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "# !find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49c3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T21:28:21.063315Z",
     "start_time": "2023-02-16T21:28:20.629362Z"
    }
   },
   "source": [
    "### `ABIDE_poly3_predict_diagnosis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1bc6195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:19:27.253037Z",
     "start_time": "2023-03-03T21:19:26.445776Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def job_creator(dep_measure, fun_name):\n",
    "    Path(r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "         dep_measure + \"_\" + fun_name + \".sh\").touch()\n",
    "    Path(r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "         dep_measure + \"_\" + fun_name + \".py\").touch()\n",
    "    bash_script = open(\n",
    "        r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "        dep_measure + \"_\" + fun_name + \".sh\", \"w\")\n",
    "    py_script = open(\n",
    "        r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_\" +\n",
    "        dep_measure + \"_\" + fun_name + \".py\", \"w\")\n",
    "    bash_script.write(r\"\"\"#!/bin/bash\n",
    "#SBATCH --account=def-masd\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=80G\n",
    "#SBATCH --time=6-12:00:00\n",
    "#SBATCH --job-name=poly3_diagnosis_{dep_measure}_{fun_name}\n",
    "\n",
    "module load gcc llvm rust arrow cuda nodejs python/3.8.10 r/4.0.2 python-build-bundle\n",
    "\n",
    "virtualenv --no-download $SLURM_TMPDIR/env\n",
    "source $SLURM_TMPDIR/env/bin/activate\n",
    "pip install --no-index --upgrade pip\n",
    "\n",
    "# ### run this block at the login node to build wheels\n",
    "# ### get wheels builder\n",
    "# git clone https://github.com/ComputeCanada/wheels_builder\n",
    "# export PATH=$PATH:${{HOME}}/wheels_builder\n",
    "# ### build KDEpy 1.1.0\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package KDEpy --version 1.1.0 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built nonconvexAG 1.0.6\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package nonconvexAG --version 1.0.6 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "# ### built fastHDMI 1.18.20\n",
    "# ${{HOME}}/wheels_builder/unmanylinuxize.sh --package fastHDMI --version 1.18.20 --python 3.8,3.9,3.10 --find_links https://files.pythonhosted.org/packages/\n",
    "\n",
    "# Here basically to build the packages at login node and install them in slurm job submission locally\n",
    "pip install --no-index bed-reader numpy sklearn matplotlib scipy numba multiprocess scikit-learn cupy rpy2\n",
    "pip install --no-index /home/kyang/KDEpy-1.1.0+computecanada-cp38-cp38-linux_x86_64.whl\n",
    "pip install --no-index /home/kyang/nonconvexAG-1.0.6+computecanada-py3-none-any.whl\n",
    "pip install --no-index /home/kyang/fastHDMI-1.18.20+computecanada-py3-none-any.whl\n",
    "\n",
    "nvidia-smi\n",
    "lscpu\n",
    "\n",
    "echo \"running ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.py\"\n",
    "\n",
    "cp /home/kyang/projects/def-cgreenwo/abide_data/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv $SLURM_TMPDIR/\n",
    "cp ../ABIDE_columns.npy $SLURM_TMPDIR/\n",
    "cp ../ABIDE_diagnosis_{dep_measure}_output.npy $SLURM_TMPDIR/\n",
    "\n",
    "python3 ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.py\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "    py_script.write(r\"\"\"import numpy as np\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, rankdata, norm\n",
    "import fastHDMI as mi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, SplineTransformer\n",
    "from sklearn.linear_model import LassoCV, ElasticNetCV, RidgeCV, LarsCV, LassoLarsCV, LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "csv_file = os.environ[\"SLURM_TMPDIR\"] + \\\n",
    "    r\"/abide_fs60_vout_fwhm0_lh_SubjectIDFormatted_N1050_nonzero_withSEX.csv\"\n",
    "original_df = pd.read_csv(csv_file, encoding=\"unicode_escape\", engine=\"c\")\n",
    "\n",
    "columns = np.load(os.environ[\"SLURM_TMPDIR\"] + r\"/ABIDE_columns.npy\")\n",
    "abide_dep = np.load(\n",
    "    os.environ[\"SLURM_TMPDIR\"] +\n",
    "    r\"/ABIDE_diagnosis_{dep_measure}_output.npy\")  # dep_measure\n",
    "abide_dep = np.absolute(abide_dep)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l1(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l1\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_l2(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def LogisticRegressionCV_ElasticNet(**arg):\n",
    "    return LogisticRegressionCV(penalty=\"elasticnet\",\n",
    "                                solver=\"saga\",\n",
    "                                multi_class=\"ovr\",\n",
    "                                l1_ratios=np.linspace(0, 1, 12)[1:-1],\n",
    "                                **arg)\n",
    "\n",
    "\n",
    "def testing_error(num_covariates=20,\n",
    "                  training_proportion=.8,\n",
    "                  fun=ElasticNetCV,\n",
    "                  outcome_name=\"AGE_AT_SCAN\",\n",
    "                  seed=1):\n",
    "    np.random.seed(seed)\n",
    "    _usecols = np.hstack((outcome_name, \"SEX\", \"AGE_AT_SCAN\",\n",
    "                          columns[np.argsort(-abide_dep)][:num_covariates]))\n",
    "    df = original_df[_usecols].dropna(inplace=False).sample(\n",
    "        frac=1, random_state=seed, replace=False).reset_index(drop=True,\n",
    "                                                              inplace=False)\n",
    "    if df.shape[0] > 20:\n",
    "        X, y = df.iloc[:,\n",
    "                       1:].to_numpy(copy=True), df.iloc[:,\n",
    "                                                        0].to_numpy(copy=True)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        X = SplineTransformer(n_knots=2,\n",
    "                              degree=3,\n",
    "                              extrapolation=\"continue\",\n",
    "                              include_bias=False).fit_transform(X)\n",
    "        X = StandardScaler(copy=False).fit_transform(X)\n",
    "        # if the outcome is continuous, we have to use binning\n",
    "        if fun in [\n",
    "                ElasticNetCV, LassoCV, RidgeCV, LarsCV, LassoLarsCV,\n",
    "                MLPRegressor, RandomForestRegressor\n",
    "        ]:\n",
    "            bins = np.linspace(np.min(y) - 1e-8,\n",
    "                               np.max(y) + 1e-8, 30)  # choose to use 30 bins\n",
    "            y_binned = np.digitize(y, bins)\n",
    "            y_binned[y_binned >= 20] = 20\n",
    "        else:\n",
    "            y_binned = y.copy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=training_proportion,\n",
    "            random_state=seed,\n",
    "            stratify=y_binned)\n",
    "        if fun in [ElasticNetCV, LassoCV]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RidgeCV]:  # RidgeCV doesn't have seed setting and n_jobs\n",
    "            fit = fun(cv=5).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [LarsCV, LassoLarsCV\n",
    "                     ]:  # LarsCV doesn't have seed setting but have n_jobs\n",
    "            fit = fun(cv=5, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPRegressor]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=10, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [MLPClassifier]:\n",
    "            mlp_gs = fun(random_state=seed, max_iter=500)\n",
    "            parameter_space = {{\n",
    "                \"hidden_layer_sizes\": [(15, 15, 15, 15, 15, 15), (30, 20, 20),\n",
    "                                       (500, )],\n",
    "                \"activation\": [\"tanh\", \"relu\"],\n",
    "                \"solver\": [\"sgd\", \"adam\"],\n",
    "                \"alpha\": [0.0001, 0.05],\n",
    "                \"learning_rate\": [\"constant\", \"adaptive\"]\n",
    "            }}\n",
    "            clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=10, cv=5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [\n",
    "                LogisticRegressionCV_l1, LogisticRegressionCV_l2,\n",
    "                LogisticRegressionCV_ElasticNet\n",
    "        ]:\n",
    "            fit = fun(cv=5, random_state=seed, n_jobs=10).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestRegressor]:\n",
    "            fit = fun(random_state=seed, n_jobs=10, n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict(X_test)\n",
    "            out = r2_score(y_test, y_pred)\n",
    "        elif fun in [RandomForestClassifier]:\n",
    "            fit = fun(random_state=seed, n_jobs=10, n_estimators=500).fit(X_train, y_train)\n",
    "            y_pred = fit.predict_proba(\n",
    "                X_test)[:, 1]  # predict probability to calculate ROC\n",
    "            out = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def testing_error_rep(num_covariates=20,\n",
    "                      training_proportion=.8,\n",
    "                      fun=ElasticNetCV,\n",
    "                      outcome_name=\"AGE_AT_SCAN\",\n",
    "                      num_rep=10):\n",
    "    def _testing_error(seed):\n",
    "        return testing_error(num_covariates=num_covariates,\n",
    "                             training_proportion=training_proportion,\n",
    "                             fun=fun,\n",
    "                             outcome_name=outcome_name,\n",
    "                             seed=seed)\n",
    "\n",
    "    seeds = np.arange(num_rep)\n",
    "    return np.array(list(map(_testing_error, seeds)))\n",
    "\n",
    "\n",
    "def testing_error_num_attr(num_attr,\n",
    "                           training_proportion=.8,\n",
    "                           fun=ElasticNetCV,\n",
    "                           outcome_name=\"AGE_AT_SCAN\",\n",
    "                           num_rep=10):\n",
    "    def _testing_error_rep(_num_attr):\n",
    "        return testing_error_rep(num_covariates=_num_attr,\n",
    "                                 training_proportion=training_proportion,\n",
    "                                 fun=fun,\n",
    "                                 outcome_name=outcome_name,\n",
    "                                 num_rep=num_rep)\n",
    "\n",
    "    return np.array(list(map(_testing_error_rep, tqdm(num_attr))))\n",
    "\n",
    "\n",
    "print(r\"ABIDE_poly3_age_{dep_measure}_{fun_name}\")  # dep_measure, fun_name\n",
    "output = testing_error_num_attr(\n",
    "    num_attr=list(\n",
    "        map(int,\n",
    "            np.around(np.linspace(0, 1000, 20 + 1)[1:]).tolist())),\n",
    "    training_proportion=.8,  # 80/20 training+validation/testing division\n",
    "    fun={fun_name},  # fun_name\n",
    "    outcome_name=\"DX_GROUP\",\n",
    "    num_rep=30)\n",
    "np.save(r\"./ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}\",\n",
    "        output)  # dep_measure, fun_name\n",
    "    \"\"\".format(dep_measure=dep_measure, fun_name=fun_name))\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for fun_name in [\n",
    "        \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_l2\",\n",
    "        \"LogisticRegressionCV_ElasticNet\", \"MLPClassifier\",\n",
    "        \"RandomForestClassifier\"\n",
    "]:\n",
    "    for dep_measure in [*dep_measure_list, \"Pearson\", \"skMI\"]:\n",
    "        job_creator(dep_measure, fun_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a9b3a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:21:57.242152Z",
     "start_time": "2023-03-03T21:19:27.628684Z"
    }
   },
   "outputs": [],
   "source": [
    "# #!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "#!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;\n",
    "!find . -name \"*.py\" -exec yapf --in-place \"{}\" \\;\n",
    "!find . -name \"*.py\" -exec autopep8 --in-place \"{}\" \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5658d",
   "metadata": {},
   "source": [
    "# Comparison of Performance\n",
    "## Here is just to show the testing set ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920631b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:10:51.452663Z",
     "start_time": "2023-03-03T21:10:51.452658Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_diagnosis_MI_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_diagnosis_skMI_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_skMI_{fun_name}.npy\".\n",
    "            format(fun_name=fun_name))\n",
    "        ABIDE_diagnosis_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_predict_diagnosis/ABIDE_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 1000, 20 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_diagnosis_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_diagnosis_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr, MI_fit_mean, label=dep_measure, color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPClassifier\", \"LogisticRegressionCV_l2\",\n",
    "            \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_ElasticNet\",\n",
    "            \"RandomForestClassifier\"\n",
    "    ]:\n",
    "        plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "        plt.savefig(r\"./ABIDE_predict_diagnosis/\" + fun_name + dep_measure)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899df18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T21:10:51.454552Z",
     "start_time": "2023-03-03T21:10:51.454531Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(_plt, fun_name, dep_measure):\n",
    "    if os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_skMI_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)\n",
    "    ) and os.path.isfile(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name)):\n",
    "        columns = np.load(r\"./ABIDE_columns.npy\")\n",
    "        ABIDE_diagnosis_MI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_{dep_measure}_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name, dep_measure=dep_measure))\n",
    "        ABIDE_diagnosis_skMI_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_skMI_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        ABIDE_diagnosis_Pearson_foo = np.load(\n",
    "            r\"./ABIDE_poly3_predict_diagnosis/ABIDE_poly3_diagnosis_Pearson_{fun_name}.npy\"\n",
    "            .format(fun_name=fun_name))\n",
    "        num_attr = list(\n",
    "            map(int,\n",
    "                np.around(np.linspace(\n",
    "                    0, 1000, 20 +\n",
    "                    1)[1:]).tolist()))  # ADJUST this based on actual settings\n",
    "\n",
    "        MI_fit_mean = np.mean(ABIDE_diagnosis_MI_foo, 1)\n",
    "        MI_fit_std = np.std(ABIDE_diagnosis_MI_foo, 1)\n",
    "        skMI_fit_mean = np.mean(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        skMI_fit_std = np.std(ABIDE_diagnosis_skMI_foo, 1)\n",
    "        Pearson_fit_mean = np.mean(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "        Pearson_fit_std = np.std(ABIDE_diagnosis_Pearson_foo, 1)\n",
    "\n",
    "        _plt.plot(num_attr, MI_fit_mean, label=dep_measure, color=\"b\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.025)),\n",
    "                          (MI_fit_mean + MI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"b\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  skMI_fit_mean,\n",
    "                  label=\"Mutual Information by skLearn\",\n",
    "                  color=\"y\")\n",
    "        _plt.fill_between(num_attr,\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.025)),\n",
    "                          (skMI_fit_mean + skMI_fit_std * norm.ppf(0.975)),\n",
    "                          color=\"y\",\n",
    "                          alpha=.1)\n",
    "\n",
    "        _plt.plot(num_attr,\n",
    "                  Pearson_fit_mean,\n",
    "                  label=\"Pearson Correlation\",\n",
    "                  color=\"g\")\n",
    "        _plt.fill_between(\n",
    "            num_attr, (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.025)),\n",
    "            (Pearson_fit_mean + Pearson_fit_std * norm.ppf(0.975)),\n",
    "            color=\"g\",\n",
    "            alpha=.1)\n",
    "        _plt.title(fun_name)\n",
    "        _plt.legend()\n",
    "\n",
    "\n",
    "dep_measure_list = []\n",
    "for _kernel in [\n",
    "        'gaussian', 'exponential', 'box', 'tri', 'epa', 'biweight',\n",
    "        'triweight', 'tricube', 'cosine'\n",
    "]:\n",
    "    for _bw in ['silverman', 'scott', 'ISJ']:\n",
    "        dep_measure_list += [\"MI_{kernel}_{bw}\".format(kernel=_kernel, bw=_bw)]\n",
    "\n",
    "for dep_measure in dep_measure_list:\n",
    "    for fun_name in [\n",
    "            \"MLPClassifier\", \"LogisticRegressionCV_l2\",\n",
    "            \"LogisticRegressionCV_l1\", \"LogisticRegressionCV_ElasticNet\",\n",
    "            \"RandomForestClassifier\"\n",
    "    ]:\n",
    "        plot_results(plt, fun_name, dep_measure=dep_measure)\n",
    "        plt.savefig(r\"./ABIDE_poly3_predict_diagnosis/\" + fun_name +\n",
    "                    dep_measure)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889857c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
