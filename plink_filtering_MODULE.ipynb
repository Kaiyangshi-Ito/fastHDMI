{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cc105c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T22:54:01.325723Z",
     "start_time": "2022-08-09T22:54:00.624970Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as _np\n",
    "#from bgen_reader import open_bgen\n",
    "#from os.path import join\n",
    "#from pandas_plink import read_plink1_bin\n",
    "#from pandas_plink import get_data_folder\n",
    "# import matplotlib.pyplot as plt\n",
    "#from bgen_reader import open_bgen\n",
    "#from bed_reader import open_bed, sample_file\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# from pysnptools.distreader import Bgen, DistMemMap\n",
    "# from pathlib import Path\n",
    "from bed_reader import open_bed as _open_bed\n",
    "# from pysnptools.snpreader import SnpData, SnpMemMap\n",
    "# from pysnptools.util import log_in_place\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import gaussian_kde\n",
    "from KDEpy import FFTKDE as _FFTKDE\n",
    "# from pybgen import PyBGEN\n",
    "import multiprocess as _mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce8b66d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T22:54:01.360585Z",
     "start_time": "2022-08-09T22:54:01.327731Z"
    }
   },
   "outputs": [],
   "source": [
    "def _MI_continuous(a, b, a_min, a_max, N=500):\n",
    "    \"\"\"\n",
    "    calculate mutual information between continuous outcome and an SNP variable of 0,1,2\n",
    "    assume no missing data\n",
    "    \"\"\"\n",
    "    # first estimate the pmf\n",
    "    p0 = _np.sum(b == 0) / len(b)\n",
    "    p1 = _np.sum(b == 1) / len(b)\n",
    "    p2 = 1. - p0 - p1\n",
    "    # estimate cond density\n",
    "    _b0 = (b == 0)\n",
    "    if _np.sum(\n",
    "            _b0\n",
    "    ) > 2:  # here proceed to kde only if there are more than 5 data points\n",
    "        y_cond_p0 = _FFTKDE(kernel=\"gaussian\", bw=\"silverman\").fit(data=a[_b0])\n",
    "#         y_cond_p0 = gaussian_kde(a[_b0])\n",
    "    else:\n",
    "        y_cond_p0 = _np.zeros_like\n",
    "    _b1 = (b == 1)\n",
    "    if _np.sum(_b1) > 2:\n",
    "        y_cond_p1 = _FFTKDE(kernel=\"gaussian\", bw=\"silverman\").fit(data=a[_b1])\n",
    "#         y_cond_p1 = gaussian_kde(a[_b1]) # this thing uses Scott's rule instead of Silverman defaulted by FFTKDE and R density\n",
    "    else:\n",
    "        y_cond_p1 = _np.zeros_like\n",
    "    _b2 = (b == 2)\n",
    "    if _np.sum(_b2) > 2:\n",
    "        y_cond_p2 = _FFTKDE(kernel=\"gaussian\", bw=\"silverman\").fit(data=a[_b2])\n",
    "\n",
    "\n",
    "#         y_cond_p2 = gaussian_kde(a[_b2])\n",
    "    else:\n",
    "        y_cond_p2 = _np.zeros_like\n",
    "    joint = _np.empty((N, 3))\n",
    "    a_temp = _np.linspace(a_min, a_max, num=N)\n",
    "    joint[:, 0] = y_cond_p0(a_temp) * p0\n",
    "    joint[:, 1] = y_cond_p1(a_temp) * p1\n",
    "    joint[:, 2] = y_cond_p2(a_temp) * p2\n",
    "    joint[joint < 1e-20] = 1e-20  # set a threshold to avoid numerical errors\n",
    "    forward_euler_step = a_temp[1] - a_temp[0]\n",
    "    #     print(\"total measure:\", _np.sum(joint)*forward_euler_step)\n",
    "    temp_log = _np.log(joint)\n",
    "    #     temp_log = _np.nan_to_num(temp_log, nan = 0)\n",
    "    temp1 = _np.log(_np.sum(joint, 1))\n",
    "    #     temp1 = _np.nan_to_num(temp1, nan = 0)\n",
    "    temp_log = temp_log - temp1.reshape(-1, 1)\n",
    "    temp2 = _np.log(_np.sum(joint, 0) * forward_euler_step)\n",
    "    #     temp2 = _np.nan_to_num(temp2, nan = 0)\n",
    "    temp_log = temp_log - temp2.reshape(1, -1)\n",
    "    # print(fhat_mat * temp_log)\n",
    "    temp_mat = joint * temp_log\n",
    "    #     temp_mat = _np.nan_to_num(temp_mat, nan=0.) # numerical fix\n",
    "    mi_temp = _np.sum(temp_mat) * forward_euler_step\n",
    "    return mi_temp\n",
    "\n",
    "\n",
    "def _MI_binary(a, b):\n",
    "    \"\"\"\n",
    "    calculate mutual information between binary outcome and an SNP variable of 0,1,2\n",
    "    assume no missing data\n",
    "    \"\"\"\n",
    "    # first estimate the pmf of SNP\n",
    "    p0 = _np.sum(b == 0) / len(b)\n",
    "    p1 = _np.sum(b == 1) / len(b)\n",
    "    p2 = 1. - p0 - p1\n",
    "    b_marginal = _np.array([p0, p1, p2])\n",
    "    # estimate pmf of the binary outcome\n",
    "    a_p0 = _np.sum(a == 0) / len(a)\n",
    "    a_p1 = _np.sum(a == 1) / len(a)\n",
    "    a_marginal = _np.array([a_p0, a_p1]).reshape(-1, 1)\n",
    "    # estimate the cond density\n",
    "    joint = _np.zeros((2, 3))\n",
    "    _b0 = (b == 0)\n",
    "    joint[0, 0] = _np.sum(a[_b0] == 0) / len(a)\n",
    "    joint[1, 0] = _np.sum(a[_b0] == 1) / len(a)\n",
    "    _b1 = (b == 1)\n",
    "    joint[0, 1] = _np.sum(a[_b1] == 0) / len(a)\n",
    "    joint[1, 1] = _np.sum(a[_b1] == 1) / len(a)\n",
    "    _b2 = (b == 2)\n",
    "    joint[0, 2] = _np.sum(a[_b2] == 0) / len(a)\n",
    "    joint[1, 2] = _np.sum(a[_b2] == 1) / len(a)\n",
    "\n",
    "    _ = a_marginal * b_marginal\n",
    "    _ = joint / _\n",
    "    __ = joint * _np.log(_)\n",
    "    __ = _np.nan_to_num(__, nan=0.0)  # for possible nuemrical issues\n",
    "\n",
    "    mi_temp = _np.sum(__)\n",
    "\n",
    "    return mi_temp\n",
    "\n",
    "\n",
    "# outcome_iid should be a  list of strings for identifiers\n",
    "def continuous_filter(bed_file,\n",
    "                      bim_file,\n",
    "                      fam_file,\n",
    "                      outcome,\n",
    "                      outcome_iid,\n",
    "                      a_min=1.2345654321,\n",
    "                      a_max=2.34565432,\n",
    "                      N=500):\n",
    "    \"\"\"\n",
    "    (Single Core version) take plink files to calculate the mutual information between the continuous outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    gene_iid = _np.array(list(bed1.iid))\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    outcome = outcome[_np.intersect1d(outcome_iid,\n",
    "                                      gene_iid,\n",
    "                                      assume_unique=True,\n",
    "                                      return_indices=True)[1]]\n",
    "    if a_min == 1.2345654321:\n",
    "        a_min = _np.min(outcome) - _np.std(outcome)\n",
    "    if a_max == 2.34565432:\n",
    "        a_max = _np.max(outcome) + _np.std(outcome)\n",
    "    # get genetic indices\n",
    "    gene_ind = _np.intersect1d(gene_iid,\n",
    "                               outcome_iid,\n",
    "                               assume_unique=True,\n",
    "                               return_indices=True)[1]\n",
    "    MI_UKBB = _np.zeros(len(bed1_sid))\n",
    "    for j in range(len(MI_UKBB)):\n",
    "        _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "        _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "        _outcome = outcome[_SNP != -127]  # remove missing SNP in outcome\n",
    "        _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "        MI_UKBB[j] = _MI_continuous(a=_outcome,\n",
    "                                    b=_SNP,\n",
    "                                    a_min=a_min,\n",
    "                                    a_max=a_max,\n",
    "                                    N=N)\n",
    "    return MI_UKBB\n",
    "\n",
    "\n",
    "def binary_filter(bed_file, bim_file, fam_file, outcome, outcome_iid):\n",
    "    \"\"\"\n",
    "    (Single Core version) take plink files to calculate the mutual information between the binary outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    gene_iid = _np.array(list(bed1.iid))\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    outcome = outcome[_np.intersect1d(outcome_iid,\n",
    "                                      gene_iid,\n",
    "                                      assume_unique=True,\n",
    "                                      return_indices=True)[1]]\n",
    "    # get genetic indices\n",
    "    gene_ind = _np.intersect1d(gene_iid,\n",
    "                               outcome_iid,\n",
    "                               assume_unique=True,\n",
    "                               return_indices=True)[1]\n",
    "    MI_UKBB = _np.zeros(len(bed1_sid))\n",
    "    print(outcome)\n",
    "    for j in range(len(MI_UKBB)):\n",
    "        _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "        _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "        _outcome = outcome[_SNP != -127]  # remove missing SNP in outcome\n",
    "        _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "        MI_UKBB[j] = _MI_binary(a=_outcome, b=_SNP)\n",
    "    return MI_UKBB\n",
    "\n",
    "\n",
    "def continuous_filter_parallel(bed_file,\n",
    "                               bim_file,\n",
    "                               fam_file,\n",
    "                               outcome,\n",
    "                               outcome_iid,\n",
    "                               a_min=1.2345654321,\n",
    "                               a_max=2.34565432,\n",
    "                               N=500,\n",
    "                               chunck_size=60000):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) take plink files to calculate the mutual information between the continuous outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    gene_iid = _np.array(list(bed1.iid))\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    outcome = outcome[_np.intersect1d(outcome_iid,\n",
    "                                      gene_iid,\n",
    "                                      assume_unique=True,\n",
    "                                      return_indices=True)[1]]\n",
    "    if a_min == 1.2345654321:\n",
    "        a_min = _np.min(outcome) - _np.std(outcome)\n",
    "    if a_max == 2.34565432:\n",
    "        a_max = _np.max(outcome) + _np.std(outcome)\n",
    "    # get genetic indices\n",
    "    gene_ind = _np.intersect1d(gene_iid,\n",
    "                               outcome_iid,\n",
    "                               assume_unique=True,\n",
    "                               return_indices=True)[1]\n",
    "\n",
    "    def _continuous_filter_slice(_slice):\n",
    "        _MI_slice = _np.zeros(len(_slice))\n",
    "        k = 0\n",
    "        for j in _slice:\n",
    "            _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "            _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "            _outcome = outcome[_SNP != -127]  # remove missing SNP in outcome\n",
    "            _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "            _MI_slice[k] = _MI_continuous(a=_outcome,\n",
    "                                          b=_SNP,\n",
    "                                          a_min=a_min,\n",
    "                                          a_max=a_max,\n",
    "                                          N=N)\n",
    "            k += 1\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(len(bed1_sid))\n",
    "    n_slices = _np.ceil(len(ind) / chunck_size)\n",
    "    with _mp.Pool(_mp.cpu_count()) as pl:\n",
    "        MI_UKBB = pl.map(_continuous_filter_slice,\n",
    "                         _np.array_split(ind, n_slices))\n",
    "    MI_UKBB = _np.hstack(MI_UKBB)\n",
    "    return MI_UKBB\n",
    "\n",
    "\n",
    "def binary_filter_parallel(bed_file,\n",
    "                           bim_file,\n",
    "                           fam_file,\n",
    "                           outcome,\n",
    "                           outcome_iid,\n",
    "                           chunck_size=60000):\n",
    "    \"\"\"\n",
    "    (Multiprocessing version) take plink files to calculate the mutual information between the binary outcome and many SNP variables.\n",
    "    \"\"\"\n",
    "    bed1 = _open_bed(filepath=bed_file,\n",
    "                     fam_filepath=fam_file,\n",
    "                     bim_filepath=bim_file)\n",
    "    gene_iid = _np.array(list(bed1.iid))\n",
    "    bed1_sid = _np.array(list(bed1.sid))\n",
    "    outcome = outcome[_np.intersect1d(outcome_iid,\n",
    "                                      gene_iid,\n",
    "                                      assume_unique=True,\n",
    "                                      return_indices=True)[1]]\n",
    "    # get genetic indices\n",
    "    gene_ind = _np.intersect1d(gene_iid,\n",
    "                               outcome_iid,\n",
    "                               assume_unique=True,\n",
    "                               return_indices=True)[1]\n",
    "\n",
    "    def _binary_filter_slice(_slice):\n",
    "        _MI_slice = _np.zeros(len(_slice))\n",
    "        k = 0\n",
    "        for j in _slice:\n",
    "            _SNP = bed1.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "            _SNP = _SNP[gene_ind]  # get gene iid also in outcome iid\n",
    "            _outcome = outcome[_SNP != -127]  # remove missing SNP in outcome\n",
    "            _SNP = _SNP[_SNP != -127]  # remove missing SNP\n",
    "            _MI_slice[k] = _MI_binary(a=_outcome, b=_SNP)\n",
    "            k += 1\n",
    "        return _MI_slice\n",
    "\n",
    "    # multiprocessing starts here\n",
    "    ind = _np.arange(len(bed1_sid))\n",
    "    n_slices = _np.ceil(len(ind) / chunck_size)\n",
    "    with _mp.Pool(_mp.cpu_count()) as pl:\n",
    "        MI_UKBB = pl.map(_binary_filter_slice, _np.array_split(ind, n_slices))\n",
    "    MI_UKBB = _np.hstack(MI_UKBB)\n",
    "    return MI_UKBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a032b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T22:54:01.370508Z",
     "start_time": "2022-08-09T22:54:01.361981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014053215327510242\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.binomial(2, .3, 200)\n",
    "b = np.random.binomial(2, .3, 200)\n",
    "print(_MI_binary(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b189ee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T22:54:25.334516Z",
     "start_time": "2022-08-09T22:54:01.372477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. ... 2. 1. 1.]\n",
      "[1. 2. 0. ... 0. 2. 1.]\n",
      "[2. 1. 2. ... 2. 2. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.47783271, 0.12487406, 0.13425855, 0.00094485, 0.00209743,\n",
       "       0.00114863, 0.00096992, 0.00167731, 0.00123907, 0.00122713,\n",
       "       0.0016312 , 0.00139877, 0.00155391, 0.0016081 , 0.00166292,\n",
       "       0.00180814, 0.00140251, 0.00176672, 0.00185609, 0.00107367])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bed_reader import open_bed\n",
    "\n",
    "bed_file = r\"./MI_AG/tests/sim/sim1.bed\"\n",
    "bim_file = r\"./MI_AG/tests/sim/sim1.bim\"\n",
    "fam_file = r\"./MI_AG/tests/sim/sim1.fam\"\n",
    "\n",
    "_bed = open_bed(filepath=bed_file,\n",
    "                fam_filepath=fam_file,\n",
    "                bim_filepath=bim_file)\n",
    "outcome = np.random.rand(_bed.iid_count)\n",
    "outcome_iid = _bed.iid\n",
    "\n",
    "true_beta = np.array([4.2, -2.5, 2.6])\n",
    "for j in np.arange(3):\n",
    "    outcome += true_beta[j] * _bed.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "    print(_bed.read(_np.s_[:, j], dtype=_np.float64).flatten())\n",
    "\n",
    "iid_ind = np.random.permutation(np.arange(_bed.iid_count))\n",
    "outcome = outcome[iid_ind]\n",
    "outcome_iid = outcome_iid[iid_ind]\n",
    "\n",
    "MI_continuous = continuous_filter_parallel(bed_file=bed_file,\n",
    "                                           bim_file=bim_file,\n",
    "                                           fam_file=fam_file,\n",
    "                                           a_min=np.min(outcome) - 10,\n",
    "                                           a_max=np.max(outcome) + 10,\n",
    "                                           outcome=outcome,\n",
    "                                           outcome_iid=outcome_iid,\n",
    "                                           chunck_size=1000)\n",
    "\n",
    "MI_continuous[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2875be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-09T22:54:31.988099Z",
     "start_time": "2022-08-09T22:54:25.337036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. ... 2. 1. 1.]\n",
      "[1. 2. 0. ... 0. 2. 1.]\n",
      "[2. 1. 2. ... 2. 2. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.12072034e-01, 3.73770418e-02, 4.64183131e-02, 1.10101854e-05,\n",
       "       3.55559156e-04, 2.82179431e-04, 3.96116739e-04, 1.37266940e-04,\n",
       "       1.48862765e-04, 3.07838542e-04, 1.27638487e-04, 2.00971493e-04,\n",
       "       6.67553629e-04, 1.25686193e-04, 1.23008505e-05, 2.31152029e-05,\n",
       "       5.19983996e-05, 5.48756269e-04, 5.60977307e-04, 5.17228214e-04])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bed_file = r\"./MI_AG/tests/sim/sim1.bed\"\n",
    "bim_file = r\"./MI_AG/tests/sim/sim1.bim\"\n",
    "fam_file = r\"./MI_AG/tests/sim/sim1.fam\"\n",
    "\n",
    "_bed = open_bed(filepath=bed_file,\n",
    "                fam_filepath=fam_file,\n",
    "                bim_filepath=bim_file)\n",
    "outcome = np.random.rand(_bed.iid_count)\n",
    "outcome_iid = _bed.iid\n",
    "\n",
    "true_beta = np.array([4.2, -2.5, 2.6])\n",
    "for j in np.arange(3):\n",
    "    outcome += true_beta[j] * _bed.read(_np.s_[:, j], dtype=_np.int8).flatten()\n",
    "    print(_bed.read(_np.s_[:, j], dtype=_np.float64).flatten())\n",
    "\n",
    "outcome = np.random.binomial(1, np.tanh(outcome / 2) / 2 + .5)\n",
    "\n",
    "iid_ind = np.random.permutation(np.arange(_bed.iid_count))\n",
    "outcome = outcome[iid_ind]\n",
    "outcome_iid = outcome_iid[iid_ind]\n",
    "\n",
    "MI_binary = binary_filter_parallel(bed_file=bed_file,\n",
    "                                   bim_file=bim_file,\n",
    "                                   fam_file=fam_file,\n",
    "                                   outcome=outcome,\n",
    "                                   outcome_iid=outcome_iid,\n",
    "                                   chunck_size=1000)\n",
    "\n",
    "MI_binary[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764c527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
